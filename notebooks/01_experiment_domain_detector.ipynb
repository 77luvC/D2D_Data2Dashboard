{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Preperation: OpenAI API KEY"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "import json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from dotenv import load_dotenv\n",
        "import os\n",
        "\n",
        "load_dotenv()\n",
        "print(os.getenv(\"OPENAI_API_KEY\"))  # should show your key\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Agent1: Domain Detector"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: langchain-core in /Users/zhangran/Library/Python/3.9/lib/python/site-packages (0.3.56)\n",
            "Requirement already satisfied: langchain-openai in /Users/zhangran/Library/Python/3.9/lib/python/site-packages (0.3.14)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.125 in /Users/zhangran/Library/Python/3.9/lib/python/site-packages (from langchain-core) (0.3.33)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /Users/zhangran/Library/Python/3.9/lib/python/site-packages (from langchain-core) (9.1.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /Users/zhangran/Library/Python/3.9/lib/python/site-packages (from langchain-core) (1.33)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /Users/zhangran/Library/Python/3.9/lib/python/site-packages (from langchain-core) (6.0.2)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /Users/zhangran/Library/Python/3.9/lib/python/site-packages (from langchain-core) (24.1)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /Users/zhangran/Library/Python/3.9/lib/python/site-packages (from langchain-core) (4.12.2)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.5.2 in /Users/zhangran/Library/Python/3.9/lib/python/site-packages (from langchain-core) (2.11.3)\n",
            "Requirement already satisfied: openai<2.0.0,>=1.68.2 in /Users/zhangran/Library/Python/3.9/lib/python/site-packages (from langchain-openai) (1.76.0)\n",
            "Requirement already satisfied: tiktoken<1,>=0.7 in /Users/zhangran/Library/Python/3.9/lib/python/site-packages (from langchain-openai) (0.9.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /Users/zhangran/Library/Python/3.9/lib/python/site-packages (from jsonpatch<2.0,>=1.33->langchain-core) (3.0.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /Users/zhangran/Library/Python/3.9/lib/python/site-packages (from langsmith<0.4,>=0.1.125->langchain-core) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /Users/zhangran/Library/Python/3.9/lib/python/site-packages (from langsmith<0.4,>=0.1.125->langchain-core) (3.10.16)\n",
            "Requirement already satisfied: requests<3,>=2 in /Users/zhangran/Library/Python/3.9/lib/python/site-packages (from langsmith<0.4,>=0.1.125->langchain-core) (2.32.3)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /Users/zhangran/Library/Python/3.9/lib/python/site-packages (from langsmith<0.4,>=0.1.125->langchain-core) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /Users/zhangran/Library/Python/3.9/lib/python/site-packages (from langsmith<0.4,>=0.1.125->langchain-core) (0.23.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /Users/zhangran/Library/Python/3.9/lib/python/site-packages (from openai<2.0.0,>=1.68.2->langchain-openai) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /Users/zhangran/Library/Python/3.9/lib/python/site-packages (from openai<2.0.0,>=1.68.2->langchain-openai) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /Users/zhangran/Library/Python/3.9/lib/python/site-packages (from openai<2.0.0,>=1.68.2->langchain-openai) (0.9.0)\n",
            "Requirement already satisfied: sniffio in /Users/zhangran/Library/Python/3.9/lib/python/site-packages (from openai<2.0.0,>=1.68.2->langchain-openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /Users/zhangran/Library/Python/3.9/lib/python/site-packages (from openai<2.0.0,>=1.68.2->langchain-openai) (4.67.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /Users/zhangran/Library/Python/3.9/lib/python/site-packages (from pydantic<3.0.0,>=2.5.2->langchain-core) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.1 in /Users/zhangran/Library/Python/3.9/lib/python/site-packages (from pydantic<3.0.0,>=2.5.2->langchain-core) (2.33.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /Users/zhangran/Library/Python/3.9/lib/python/site-packages (from pydantic<3.0.0,>=2.5.2->langchain-core) (0.4.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /Users/zhangran/Library/Python/3.9/lib/python/site-packages (from tiktoken<1,>=0.7->langchain-openai) (2024.11.6)\n",
            "Requirement already satisfied: exceptiongroup>=1.0.2 in /Users/zhangran/Library/Python/3.9/lib/python/site-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.68.2->langchain-openai) (1.2.2)\n",
            "Requirement already satisfied: idna>=2.8 in /Users/zhangran/Library/Python/3.9/lib/python/site-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.68.2->langchain-openai) (3.10)\n",
            "Requirement already satisfied: certifi in /Users/zhangran/Library/Python/3.9/lib/python/site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in /Users/zhangran/Library/Python/3.9/lib/python/site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core) (1.0.8)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /Users/zhangran/Library/Python/3.9/lib/python/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core) (0.14.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/zhangran/Library/Python/3.9/lib/python/site-packages (from requests<3,>=2->langsmith<0.4,>=0.1.125->langchain-core) (3.4.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/zhangran/Library/Python/3.9/lib/python/site-packages (from requests<3,>=2->langsmith<0.4,>=0.1.125->langchain-core) (2.2.3)\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49m/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!pip install -U langchain-core langchain-openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install -U langgraph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install langchain-openai langchain-core langgraph"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### TBF-Test 0 for Agent_D: with a fixed knowledge database"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "ename": "SyntaxError",
          "evalue": "unexpected character after line continuation character (1981263389.py, line 77)",
          "output_type": "error",
          "traceback": [
            "\u001b[0;36m  Cell \u001b[0;32mIn[14], line 77\u001b[0;36m\u001b[0m\n\u001b[0;31m    match = re.search(r\\\"\\\\[.*?\\\\]\\\", raw, re.S)\u001b[0m\n\u001b[0m                                               ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unexpected character after line continuation character\n"
          ]
        }
      ],
      "source": [
        "# ---------- imports ----------\n",
        "from langchain_openai import OpenAI\n",
        "from langchain.chains import LLMChain\n",
        "from langchain_core.prompts import PromptTemplate\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.runnables import RunnablePassthrough\n",
        "from langgraph.graph import StateGraph, END\n",
        "\n",
        "import json, re\n",
        "from typing import List, Dict, Any, Optional\n",
        "\n",
        "# ---------- state ----------\n",
        "class DomainDetectorState(dict):\n",
        "    def __init__(\n",
        "        self,\n",
        "        columns: List[str],\n",
        "        column_types: Dict[str, str],\n",
        "        domains_found: List[Dict[str, Any]] = None,\n",
        "        current_domain: Optional[str] = None,\n",
        "        jargon_terms: List[str] = None,\n",
        "        remaining_columns: List[str] = None,\n",
        "        iteration: int = 0,\n",
        "        messages: List[str] = None,\n",
        "    ):\n",
        "        super().__init__(\n",
        "            columns=columns,\n",
        "            column_types=column_types,\n",
        "            domains_found=domains_found or [],\n",
        "            current_domain=current_domain,\n",
        "            jargon_terms=jargon_terms or [],\n",
        "            remaining_columns=remaining_columns or list(columns),\n",
        "            iteration=iteration,\n",
        "            messages=messages or [],\n",
        "        )\n",
        "\n",
        "# ---------- LLM ----------\n",
        "llm = OpenAI(temperature=0)\n",
        "# llm = OpenAI(model_name=\"gpt-4o-mini\", temperature=0)\n",
        "\n",
        "# ---------- think ----------\n",
        "def think(state: DomainDetectorState) -> DomainDetectorState:\n",
        "    if len(state[\"domains_found\"]) >= 5 or not state[\"remaining_columns\"]:\n",
        "        return state\n",
        "\n",
        "    prompt = PromptTemplate.from_template(\n",
        "        \"\"\"\n",
        "        You are a domain expert.\n",
        "        Remaining columns: {remaining_columns}\n",
        "        Column types: {column_types}\n",
        "        Domains already found: {domains_found}\n",
        "        Identify ONE new domain (single word / short phrase).\n",
        "        \"\"\"\n",
        "    )\n",
        "    name = LLMChain(llm=llm, prompt=prompt).run(\n",
        "        remaining_columns=state[\"remaining_columns\"],\n",
        "        column_types=state[\"column_types\"],\n",
        "        domains_found=[d[\"domain\"] for d in state[\"domains_found\"]],\n",
        "    ).strip()\n",
        "\n",
        "    new = state.copy()\n",
        "    new[\"current_domain\"] = name\n",
        "    new[\"messages\"].append(f\"Think → {name}\")\n",
        "    return new\n",
        "\n",
        "# ---------- helper ----------\n",
        "def search_examples(domain: str, n: int = 5) -> List[str]:\n",
        "    raw = (prompt | llm | StrOutputParser()).invoke({\"domain\": domain, \"n\": n})\n",
        "\n",
        "    # ① Strict JSON path\n",
        "    try:\n",
        "        terms = json.loads(raw)\n",
        "        if isinstance(terms, list) and len(terms) >= 3:\n",
        "            return terms[:n]\n",
        "    except Exception:\n",
        "        pass\n",
        "    \n",
        "    match = re.search(r\"\\[(.*?)\\]\", raw_response, re.S)\n",
        "    if match:\n",
        "        rough = re.split(r\"[\\\"',\\[\\]]+\", match.group(1))\n",
        "        cleaned = [t.strip() for t in rough if t.strip()]\n",
        "        if cleaned:\n",
        "            return cleaned[:n_terms]\n",
        "\n",
        "    # 5️⃣  Final generic fallback\n",
        "    return [\"metric\", \"indicator\", \"analysis\", \"benchmark\", \"trend\"][:n_terms]\n",
        "\n",
        "# ---------- act ----------\n",
        "def act(state: DomainDetectorState) -> DomainDetectorState:\n",
        "    if not state[\"current_domain\"]:\n",
        "        new = state.copy(); new[\"iteration\"] += 1; return new\n",
        "\n",
        "    examples = search_examples(state[\"current_domain\"])\n",
        "\n",
        "    prompt = PromptTemplate.from_template(\n",
        "        \"\"\"\n",
        "        Domain: {domain}\n",
        "        Columns: {columns}\n",
        "        Example jargon: {examples}\n",
        "        Produce ≥5 NEW jargon terms (JSON array).\n",
        "        \"\"\"\n",
        "    )\n",
        "    jargon_response = LLMChain(llm=llm, prompt=prompt).run(\n",
        "        domain=state[\"current_domain\"],\n",
        "        columns=state[\"columns\"],\n",
        "        examples=examples,\n",
        "    )\n",
        "    try:\n",
        "        array_txt = re.search(r\\\"\\\\[.*?\\\\]\\\", jargon_response, re.S).group(0)\n",
        "        jargon_terms = json.loads(array_txt)\n",
        "    except Exception:\n",
        "        jargon_terms = []\n",
        "\n",
        "    new = state.copy()\n",
        "    new[\\\"jargon_terms\\\"] = jargon_terms        # <- store the *parsed* list\n",
        "    new[\\\"messages\\\"].append(f\\\"Act → {jargon_terms}\\\")\n",
        "    new[\\\"iteration\\\"] += 1\n",
        "    return new\n",
        "\n",
        "# ---------- reflect ----------\n",
        "def reflect(state: DomainDetectorState) -> DomainDetectorState:\n",
        "    if not state[\"current_domain\"] or not state[\"jargon_terms\"]:\n",
        "        new_state = state.copy()\n",
        "        new_state[\\\"iteration\\\"] += 1\n",
        "        return new_state\n",
        "\n",
        "    cols_lower = {c.lower() for c in state[\"columns\"]}\n",
        "    valid = [t for t in state[\"jargon_terms\"] if t.lower() not in cols_lower]\n",
        "\n",
        "    new = state.copy()\n",
        "    if len(valid) >= 3:\n",
        "        new[\"domains_found\"].append(\n",
        "            {\"domain\": state[\"current_domain\"], \"jargon_terms\": valid[:5]}\n",
        "        )\n",
        "        new[\"messages\"].append(f\"Reflect ✔ {state['current_domain']}\")\n",
        "        if new[\"remaining_columns\"]:\n",
        "            new[\"remaining_columns\"].pop(0)\n",
        "    else:\n",
        "        new[\"messages\"].append(f\"Reflect ✖ {state['current_domain']}\")\n",
        "\n",
        "    new[\"current_domain\"] = None\n",
        "    new[\"jargon_terms\"] = []\n",
        "    new[\"iteration\"] += 1\n",
        "    return new\n",
        "\n",
        "# ---------- stop rule ----------\n",
        "def should_end(state: DomainDetectorState) -> str:\n",
        "    if len(state[\"domains_found\"]) >= 5 or not state[\"remaining_columns\"] or state[\"iteration\"] >= 10:\n",
        "        return \"end\"\n",
        "    return \"continue\"\n",
        "\n",
        "# ---------- graph ----------\n",
        "def build_graph():\n",
        "    g = StateGraph(DomainDetectorState)\n",
        "    g.add_node(\"think\", think)\n",
        "    g.add_node(\"act\", act)\n",
        "    g.add_node(\"reflect\", reflect)\n",
        "    g.add_edge(\"think\", \"act\")\n",
        "    g.add_edge(\"act\", \"reflect\")\n",
        "    g.add_conditional_edges(\"reflect\", should_end, {\"continue\": \"think\", \"end\": END})\n",
        "    g.set_entry_point(\"think\")\n",
        "    return g.compile()\n",
        "\n",
        "# ---------- run ----------\n",
        "def run_domain_detector(columns, column_types=None):\n",
        "    column_types = column_types or {c: \"text\" for c in columns}\n",
        "    state0 = DomainDetectorState(columns=columns, column_types=column_types)\n",
        "    return build_graph().invoke(state0, config={\"recursion_limit\": 50})[\"domains_found\"]\n",
        "\n",
        "# ---- quick test ----\n",
        "if __name__ == \"__main__\":\n",
        "    cols = [\"Quarter\", \"number_Customers\", \"Total_Transactions\", \"Revenue\", \"Profit\"]\n",
        "    print(json.dumps(run_domain_detector(cols), indent=2))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[\n",
            "  {\n",
            "    \"domain\": \"Business Analytics\",\n",
            "    \"jargon_terms\": [\n",
            "      \"KPI\",\n",
            "      \"ROI\",\n",
            "      \"Forecasting\",\n",
            "      \"Segmentation\",\n",
            "      \"Data Mining\"\n",
            "    ]\n",
            "  },\n",
            "  {\n",
            "    \"domain\": \"Business Finance\",\n",
            "    \"jargon_terms\": [\n",
            "      \"ROI\",\n",
            "      \"EBITDA\",\n",
            "      \"Liquidity\",\n",
            "      \"Cash Flow\",\n",
            "      \"Capital Expenditure\"\n",
            "    ]\n",
            "  },\n",
            "  {\n",
            "    \"domain\": \"Business Economics\",\n",
            "    \"jargon_terms\": [\n",
            "      \"demand_curve\",\n",
            "      \"elasticity\",\n",
            "      \"marginal_cost\",\n",
            "      \"opportunity_cost\",\n",
            "      \"market_share\"\n",
            "    ]\n",
            "  },\n",
            "  {\n",
            "    \"domain\": \"Business Accounting\",\n",
            "    \"jargon_terms\": [\n",
            "      \"ledger\",\n",
            "      \"depreciation\",\n",
            "      \"amortization\",\n",
            "      \"accrual\",\n",
            "      \"cash flow\"\n",
            "    ]\n",
            "  },\n",
            "  {\n",
            "    \"domain\": \"Business Management\",\n",
            "    \"jargon_terms\": [\n",
            "      \"KPI\",\n",
            "      \"ROI\",\n",
            "      \"SWOT\",\n",
            "      \"P&L\",\n",
            "      \"Forecast\"\n",
            "    ]\n",
            "  }\n",
            "]\n"
          ]
        }
      ],
      "source": [
        "from langchain_openai import OpenAI\n",
        "from langchain.chains import LLMChain\n",
        "from langchain_core.prompts import PromptTemplate\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "import json\n",
        "import re\n",
        "from typing import List, Dict, Any, Optional\n",
        "from langgraph.graph import StateGraph, END\n",
        "\n",
        "# Define the state schema\n",
        "class DomainDetectorState(dict):\n",
        "    \"\"\"State for the domain detector agent.\"\"\"\n",
        "    def __init__(self, \n",
        "                 columns: List[str],\n",
        "                 column_types: Dict[str, str],\n",
        "                 domains_found: List[Dict[str, Any]] = None,\n",
        "                 current_domain: Optional[str] = None,\n",
        "                 jargon_terms: List[str] = None,\n",
        "                 remaining_columns: List[str] = None,\n",
        "                 iteration: int = 0,\n",
        "                 messages: List[str] = None):\n",
        "        \n",
        "        self.columns = columns\n",
        "        self.column_types = column_types\n",
        "        self.domains_found = domains_found or []\n",
        "        self.current_domain = current_domain\n",
        "        self.jargon_terms = jargon_terms or []\n",
        "        self.remaining_columns = remaining_columns or list(columns)\n",
        "        self.iteration = iteration\n",
        "        self.messages = messages or []\n",
        "        \n",
        "        super().__init__(\n",
        "            columns=self.columns,\n",
        "            column_types=self.column_types,\n",
        "            domains_found=self.domains_found,\n",
        "            current_domain=self.current_domain,\n",
        "            jargon_terms=self.jargon_terms,\n",
        "            remaining_columns=self.remaining_columns,\n",
        "            iteration=self.iteration,\n",
        "            messages=self.messages\n",
        "        )\n",
        "\n",
        "# Initialize LLM\n",
        "llm = OpenAI(temperature=0)\n",
        "\n",
        "# Define the \"Think\" node - Identify a potential domain\n",
        "def think(state: DomainDetectorState) -> DomainDetectorState:\n",
        "    \"\"\"Identify a potential domain based on remaining columns.\"\"\"\n",
        "    \n",
        "    # Skip if we already have 5 domains or no columns remain\n",
        "    if len(state[\"domains_found\"]) >= 5 or not state[\"remaining_columns\"]:\n",
        "        return state\n",
        "    \n",
        "    think_template = \"\"\"\n",
        "    You are a domain expert tasked with identifying knowledge domains from a set of data columns.\n",
        "    \n",
        "    Current columns to analyze: {remaining_columns}\n",
        "    Column types: {column_types}\n",
        "    \n",
        "    Domains already identified: {domains_found}\n",
        "    \n",
        "    Based on the remaining columns, identify ONE new knowledge domain that best represents them.\n",
        "    Consider business, scientific, or technical domains that would use such terminology.\n",
        "    \n",
        "    Return only the domain name as a single word or short phrase.\n",
        "    \"\"\"\n",
        "    \n",
        "    think_prompt = PromptTemplate(\n",
        "        template=think_template,\n",
        "        input_variables=[\"remaining_columns\", \"column_types\", \"domains_found\"]\n",
        "    )\n",
        "    \n",
        "    think_chain = LLMChain(llm=llm, prompt=think_prompt)\n",
        "    \n",
        "    domain = think_chain.run({\n",
        "        \"remaining_columns\": state[\"remaining_columns\"],\n",
        "        \"column_types\": state[\"column_types\"],\n",
        "        \"domains_found\": [d[\"domain\"] for d in state[\"domains_found\"]]\n",
        "    }).strip()\n",
        "    \n",
        "    new_state = state.copy()\n",
        "    new_state[\"current_domain\"] = domain\n",
        "    new_state[\"messages\"].append(f\"Identified potential domain: {domain}\")\n",
        "    \n",
        "    return new_state\n",
        "\n",
        "# Mock function for search_examples\n",
        "def search_examples(domain: str) -> List[str]:\n",
        "    \"\"\"Mock function to simulate fetching jargon hints for a domain.\"\"\"\n",
        "    # In a real implementation, this would call an external API or database\n",
        "    domain_examples = {\n",
        "        \"Finance\": [\"ROI\", \"EBITDA\", \"liquidity\", \"amortization\", \"depreciation\"],\n",
        "        \"Retail\": [\"SKU\", \"inventory turnover\", \"markdown\", \"POS\", \"shrinkage\"],\n",
        "        \"E-commerce\": [\"conversion rate\", \"cart abandonment\", \"AOV\", \"CPC\", \"CTR\"],\n",
        "        \"Sales\": [\"pipeline\", \"lead generation\", \"churn rate\", \"upselling\", \"quota\"],\n",
        "        \"Marketing\": [\"CAC\", \"LTV\", \"engagement rate\", \"attribution\", \"funnel\"],\n",
        "        \"Business Intelligence\": [\"KPI\", \"dashboard\", \"data warehouse\", \"ETL\", \"OLAP\"]\n",
        "    }\n",
        "    \n",
        "    # Default examples for domains not in our mock database\n",
        "    default_examples = [\"metric\", \"indicator\", \"analysis\", \"benchmark\", \"trend\"]\n",
        "    \n",
        "    return domain_examples.get(domain, default_examples)\n",
        "\n",
        "# Define the \"Act\" node - Get jargon terms\n",
        "def act(state: DomainDetectorState) -> DomainDetectorState:\n",
        "    \n",
        "    \"\"\"Generate jargon terms for the current domain.\"\"\"\n",
        "\n",
        "    # Skip only if there is *no* domain to work on\n",
        "    if not state[\"current_domain\"]:\n",
        "        new_state = state.copy()\n",
        "        new_state[\"iteration\"] += 1\n",
        "        return new_state\n",
        "    \n",
        "    # Get example jargon terms\n",
        "    example_terms = search_examples(state[\"current_domain\"])\n",
        "    \n",
        "    act_template = \"\"\"\n",
        "    You are a domain expert in {domain}.\n",
        "    \n",
        "    Your task is to generate at least 5 jargon terms that are commonly used in the {domain} domain \n",
        "    but do NOT appear verbatim in the following column names: {columns}.\n",
        "    \n",
        "    Here are some example jargon terms for this domain: {examples}\n",
        "    \n",
        "    Return a JSON array of strings containing ONLY the jargon terms.\n",
        "    Example: [\"term1\", \"term2\", \"term3\", \"term4\", \"term5\"]\n",
        "    \"\"\"\n",
        "    \n",
        "    act_prompt = PromptTemplate(\n",
        "        template=act_template,\n",
        "        input_variables=[\"domain\", \"columns\", \"examples\"]\n",
        "    )\n",
        "    \n",
        "    act_chain = LLMChain(llm=llm, prompt=act_prompt)\n",
        "    \n",
        "    jargon_response = act_chain.run({\n",
        "        \"domain\": state[\"current_domain\"],\n",
        "        \"columns\": state[\"columns\"],\n",
        "        \"examples\": example_terms\n",
        "    })\n",
        "    \n",
        "    # Extract the JSON array from the response\n",
        "    try:\n",
        "        # Find anything that looks like a JSON array\n",
        "        match = re.search(r'\\[.*\\]', jargon_response, re.DOTALL)\n",
        "        if match:\n",
        "            jargon_terms = json.loads(match.group(0))\n",
        "        else:\n",
        "            jargon_terms = []\n",
        "    except Exception:\n",
        "        jargon_terms = []\n",
        "    \n",
        "    new_state = state.copy()\n",
        "    new_state[\"jargon_terms\"] = jargon_terms\n",
        "    new_state[\"messages\"].append(f\"Generated jargon terms: {jargon_terms}\")\n",
        "    new_state[\"iteration\"] += 1\n",
        "    return new_state\n",
        "\n",
        "# Define the \"Reflect\" node - Validate jargon terms\n",
        "def reflect(state: DomainDetectorState) -> DomainDetectorState:\n",
        "    \"\"\"Validate jargon terms and update domains found.\"\"\"\n",
        "    \n",
        "    if not state[\"current_domain\"] or not state[\"jargon_terms\"]:\n",
        "        return state\n",
        "    \n",
        "    # Convert column names to lowercase for case-insensitive comparison\n",
        "    columns_lower = [col.lower() for col in state[\"columns\"]]\n",
        "    \n",
        "    # Filter out jargon terms that appear in column names\n",
        "    valid_terms = []\n",
        "    for term in state[\"jargon_terms\"]:\n",
        "        if term.lower() not in columns_lower:\n",
        "            valid_terms.append(term)\n",
        "    \n",
        "    # If we have at least 3 valid terms, add the domain to our list\n",
        "    new_state = state.copy()\n",
        "    if len(valid_terms) >= 3:\n",
        "        domain_entry = {\n",
        "            \"domain\": state[\"current_domain\"],\n",
        "            \"jargon_terms\": valid_terms[:5]  # Limit to 5 terms\n",
        "        }\n",
        "        new_state[\"domains_found\"].append(domain_entry)\n",
        "        new_state[\"messages\"].append(f\"Added domain: {state['current_domain']} with terms: {valid_terms[:5]}\")\n",
        "        \n",
        "        # Remove columns that were used for this domain (optional)\n",
        "        # This is a simplified approach - in a real implementation, you might want\n",
        "        # to use the LLM to determine which columns were used for this domain\n",
        "        if len(new_state[\"remaining_columns\"]) > 0:\n",
        "            new_state[\"remaining_columns\"].pop(0)\n",
        "    else:\n",
        "        new_state[\"messages\"].append(f\"Rejected domain: {state['current_domain']} - not enough valid jargon terms\")\n",
        "    \n",
        "    # Reset current domain and jargon terms\n",
        "    new_state[\"current_domain\"] = None\n",
        "    new_state[\"jargon_terms\"] = []\n",
        "    new_state[\"iteration\"] += 1\n",
        "    \n",
        "    return new_state\n",
        "\n",
        "# Define the condition to end the graph\n",
        "def should_end(state: DomainDetectorState) -> str:\n",
        "    \"\"\"Determine if the graph should end.\"\"\"\n",
        "    if len(state[\"domains_found\"]) >= 5:\n",
        "        return \"end\"\n",
        "    if not state[\"remaining_columns\"]:\n",
        "        return \"end\"\n",
        "    if state[\"iteration\"] >= 10:  # Safety limit\n",
        "        return \"end\"\n",
        "    return \"continue\"\n",
        "\n",
        "# Build the graph\n",
        "def build_domain_detector_graph():\n",
        "    \"\"\"Build and return the domain detector graph.\"\"\"\n",
        "    workflow = StateGraph(DomainDetectorState)\n",
        "    \n",
        "    # Add nodes\n",
        "    workflow.add_node(\"think\", think)\n",
        "    workflow.add_node(\"act\", act)\n",
        "    workflow.add_node(\"reflect\", reflect)\n",
        "    \n",
        "    # Add edges\n",
        "    workflow.add_edge(\"think\", \"act\")\n",
        "    workflow.add_edge(\"act\", \"reflect\")\n",
        "    \n",
        "    # Add conditional edge\n",
        "    workflow.add_conditional_edges(\n",
        "        \"reflect\",\n",
        "        should_end,\n",
        "        {\n",
        "            \"continue\": \"think\",\n",
        "            \"end\": END\n",
        "        }\n",
        "    )\n",
        "    \n",
        "    # Set the entry point\n",
        "    workflow.set_entry_point(\"think\")\n",
        "    \n",
        "    return workflow.compile()\n",
        "\n",
        "# Function to run the domain detector\n",
        "def run_domain_detector(columns, column_types=None):\n",
        "    \"\"\"\n",
        "    Run the domain detector on the given columns.\n",
        "    \n",
        "    Args:\n",
        "        columns (list): List of column names\n",
        "        column_types (dict, optional): Dictionary mapping column names to their data types\n",
        "    \n",
        "    Returns:\n",
        "        list: List of domains with their jargon terms\n",
        "    \"\"\"\n",
        "    if column_types is None:\n",
        "        column_types = {col: \"text\" for col in columns}\n",
        "    \n",
        "    # Initialize the state\n",
        "    initial_state = DomainDetectorState(\n",
        "        columns=columns,\n",
        "        column_types=column_types\n",
        "    )\n",
        "    \n",
        "    # Build and run the graph\n",
        "    graph = build_domain_detector_graph()\n",
        "    final_state = graph.invoke(initial_state)\n",
        "    \n",
        "    return final_state[\"domains_found\"]\n",
        "\n",
        "# Example usage\n",
        "if __name__ == \"__main__\":\n",
        "    columns = [\"Quarter\", \"number_Customers\", \"Total_Transactions\", \"Revenue\", \"Profit\"]\n",
        "    column_types = {\n",
        "        \"Quarter\": \"object\",\n",
        "        \"number_Customers\": \"int\",\n",
        "        \"Total_Transactions\": \"float\",\n",
        "        \"Revenue\": \"float\",\n",
        "        \"Profit\": \"float\"\n",
        "    }\n",
        "    \n",
        "    domains = run_domain_detector(columns, column_types)\n",
        "    print(json.dumps(domains, indent=2))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### - Visualization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "git: 'filter-repo' is not a git command. See 'git --help'.\n",
            "Enumerating objects: 19, done.\n",
            "Counting objects: 100% (19/19), done.\n",
            "Delta compression using up to 8 threads\n",
            "Compressing objects: 100% (14/14), done.\n",
            "Writing objects: 100% (16/16), 14.48 KiB | 7.24 MiB/s, done.\n",
            "Total 16 (delta 5), reused 0 (delta 0), pack-reused 0\n",
            "remote: Resolving deltas: 100% (5/5), completed with 1 local object.\u001b[K\n",
            "remote: \u001b[1;31merror\u001b[m: GH013: Repository rule violations found for refs/heads/main.\u001b[K\n",
            "remote: \n",
            "remote: - GITHUB PUSH PROTECTION\u001b[K\n",
            "remote:   —————————————————————————————————————————\u001b[K\n",
            "remote:     Resolve the following violations before pushing again\u001b[K\n",
            "remote: \n",
            "remote:     - Push cannot contain secrets\u001b[K\n",
            "remote: \n",
            "remote:     \u001b[K\n",
            "remote:      (?) Learn how to resolve a blocked push\u001b[K\n",
            "remote:      https://docs.github.com/code-security/secret-scanning/working-with-secret-scanning-and-push-protection/working-with-push-protection-from-the-command-line#resolving-a-blocked-push\u001b[K\n",
            "remote:     \u001b[K\n",
            "remote:     \u001b[K\n",
            "remote:       —— OpenAI API Key ————————————————————————————————————\u001b[K\n",
            "remote:        locations:\u001b[K\n",
            "remote:          - commit: 233c8bbf62758132e46ef01f8bc8ffbee5ed2acf\u001b[K\n",
            "remote:            path: .env:1\u001b[K\n",
            "remote:     \u001b[K\n",
            "remote:        (?) To push, remove secret from commit(s) or follow this URL to allow the secret.\u001b[K\n",
            "remote:        https://github.com/77luvC/D2D_Data2Dashboard/security/secret-scanning/unblock-secret/2wPsUzOm5Or3WaUS97MUN2fU3OC\u001b[K\n",
            "remote:     \u001b[K\n",
            "remote: \n",
            "remote: \n",
            "To https://github.com/77luvC/D2D_Data2Dashboard.git\n",
            " \u001b[31m! [remote rejected]\u001b[m main -> main (push declined due to repository rule violations)\n",
            "\u001b[31merror: failed to push some refs to 'https://github.com/77luvC/D2D_Data2Dashboard.git'\n",
            "\u001b[m"
          ]
        }
      ],
      "source": [
        "!git filter-repo --path .env --invert-paths\n",
        "!git push origin main --force\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "zsh:1: command not found: brew\n"
          ]
        }
      ],
      "source": [
        "!brew install git-filter-repo\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Collecting git-filter-repo\n",
            "  Downloading git_filter_repo-2.47.0-py3-none-any.whl.metadata (31 kB)\n",
            "Downloading git_filter_repo-2.47.0-py3-none-any.whl (76 kB)\n",
            "Installing collected packages: git-filter-repo\n",
            "Successfully installed git-filter-repo-2.47.0\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49m/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!pip install git-filter-repo  # May not work on all setups\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Aborting: Refusing to destructively overwrite repo history since\n",
            "this does not look like a fresh clone.\n",
            "  (expected freshly packed repo)\n",
            "Please operate on a fresh clone instead.  If you want to proceed\n",
            "anyway, use --force.\n"
          ]
        }
      ],
      "source": [
        "!git filter-repo --path .env --invert-paths\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enumerating objects: 19, done.\n",
            "Counting objects: 100% (19/19), done.\n",
            "Delta compression using up to 8 threads\n",
            "Compressing objects: 100% (14/14), done.\n",
            "Writing objects: 100% (16/16), 14.48 KiB | 7.24 MiB/s, done.\n",
            "Total 16 (delta 5), reused 0 (delta 0), pack-reused 0\n",
            "remote: Resolving deltas: 100% (5/5), completed with 1 local object.\u001b[K\n",
            "remote: \u001b[1;31merror\u001b[m: GH013: Repository rule violations found for refs/heads/main.\u001b[K\n",
            "remote: \n",
            "remote: - GITHUB PUSH PROTECTION\u001b[K\n",
            "remote:   —————————————————————————————————————————\u001b[K\n",
            "remote:     Resolve the following violations before pushing again\u001b[K\n",
            "remote: \n",
            "remote:     - Push cannot contain secrets\u001b[K\n",
            "remote: \n",
            "remote:     \u001b[K\n",
            "remote:      (?) Learn how to resolve a blocked push\u001b[K\n",
            "remote:      https://docs.github.com/code-security/secret-scanning/working-with-secret-scanning-and-push-protection/working-with-push-protection-from-the-command-line#resolving-a-blocked-push\u001b[K\n",
            "remote:     \u001b[K\n",
            "remote:     \u001b[K\n",
            "remote:       —— OpenAI API Key ————————————————————————————————————\u001b[K\n",
            "remote:        locations:\u001b[K\n",
            "remote:          - commit: 233c8bbf62758132e46ef01f8bc8ffbee5ed2acf\u001b[K\n",
            "remote:            path: .env:1\u001b[K\n",
            "remote:     \u001b[K\n",
            "remote:        (?) To push, remove secret from commit(s) or follow this URL to allow the secret.\u001b[K\n",
            "remote:        https://github.com/77luvC/D2D_Data2Dashboard/security/secret-scanning/unblock-secret/2wPsUzOm5Or3WaUS97MUN2fU3OC\u001b[K\n",
            "remote:     \u001b[K\n",
            "remote: \n",
            "remote: \n",
            "To https://github.com/77luvC/D2D_Data2Dashboard.git\n",
            " \u001b[31m! [remote rejected]\u001b[m main -> main (push declined due to repository rule violations)\n",
            "\u001b[31merror: failed to push some refs to 'https://github.com/77luvC/D2D_Data2Dashboard.git'\n",
            "\u001b[m"
          ]
        }
      ],
      "source": [
        "!git push origin main --force\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "NOTICE: Removing 'origin' remote; see 'Why is my origin removed?'\n",
            "        in the manual if you want to push back there.\n",
            "        (was https://github.com/77luvC/D2D_Data2Dashboard.git)\n",
            "Parsed 10 commits\n",
            "New history written in 0.06 seconds; now repacking/cleaning...\n",
            "Repacking your repo and cleaning out old unneeded objects\n",
            "HEAD is now at 22fed46 agentize domain detector\n",
            "Enumerating objects: 32, done.\n",
            "Counting objects: 100% (32/32), done.\n",
            "Delta compression using up to 8 threads\n",
            "Compressing objects: 100% (29/29), done.\n",
            "Writing objects: 100% (32/32), done.\n",
            "Total 32 (delta 10), reused 1 (delta 0), pack-reused 0\n",
            "Completely finished after 0.14 seconds.\n"
          ]
        }
      ],
      "source": [
        "!git filter-repo --path .env --invert-paths --force\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "fatal: 'origin' does not appear to be a git repository\n",
            "fatal: Could not read from remote repository.\n",
            "\n",
            "Please make sure you have the correct access rights\n",
            "and the repository exists.\n"
          ]
        }
      ],
      "source": [
        "!git push origin main --force\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {},
      "outputs": [],
      "source": [
        "!git remote add origin https://github.com/77luvC/D2D_Data2Dashboard.git\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enumerating objects: 32, done.\n",
            "Counting objects: 100% (32/32), done.\n",
            "Delta compression using up to 8 threads\n",
            "Compressing objects: 100% (19/19), done.\n",
            "Writing objects: 100% (32/32), 39.08 KiB | 39.08 MiB/s, done.\n",
            "Total 32 (delta 10), reused 32 (delta 10), pack-reused 0\n",
            "remote: Resolving deltas: 100% (10/10), done.\u001b[K\n",
            "To https://github.com/77luvC/D2D_Data2Dashboard.git\n",
            " + e96d856...22fed46 main -> main (forced update)\n"
          ]
        }
      ],
      "source": [
        "!git push origin main --force\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Test 1 for Agent_D: Dynamic LLM-powered jargon fetcher"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[\n",
            "  {\n",
            "    \"domain\": \"Business Analytics\",\n",
            "    \"jargon_terms\": [\n",
            "      \"Data Mining\",\n",
            "      \"Predictive Modeling\",\n",
            "      \"Data Visualization\",\n",
            "      \"Descriptive Analytics\",\n",
            "      \"Prescriptive Analytics\"\n",
            "    ]\n",
            "  },\n",
            "  {\n",
            "    \"domain\": \"Business Finance\",\n",
            "    \"jargon_terms\": [\n",
            "      \"EBITDA\",\n",
            "      \"ROI\",\n",
            "      \"DCF\",\n",
            "      \"IRR\",\n",
            "      \"NPV\"\n",
            "    ]\n",
            "  },\n",
            "  {\n",
            "    \"domain\": \"Business Economics\",\n",
            "    \"jargon_terms\": [\n",
            "      \"Demand Curve\",\n",
            "      \"Opportunity Cost\",\n",
            "      \"Elasticity\",\n",
            "      \"Monopoly\",\n",
            "      \"Oligopoly\"\n",
            "    ]\n",
            "  },\n",
            "  {\n",
            "    \"domain\": \"Business Accounting\",\n",
            "    \"jargon_terms\": [\n",
            "      \"Balance Sheet\",\n",
            "      \"Cash Flow Statement\",\n",
            "      \"Accrual Basis\",\n",
            "      \"Depreciation\",\n",
            "      \"Inventory Valuation\"\n",
            "    ]\n",
            "  },\n",
            "  {\n",
            "    \"domain\": \"Business Management\",\n",
            "    \"jargon_terms\": [\n",
            "      \"KPI\",\n",
            "      \"ROI\",\n",
            "      \"SWOT\",\n",
            "      \"B2B\",\n",
            "      \"B2C\"\n",
            "    ]\n",
            "  }\n",
            "]\n"
          ]
        }
      ],
      "source": [
        "from langchain_openai import OpenAI\n",
        "from langchain.chains import LLMChain\n",
        "from langchain_core.prompts import PromptTemplate\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "import json\n",
        "import re\n",
        "from typing import List, Dict, Any, Optional\n",
        "from langgraph.graph import StateGraph, END\n",
        "\n",
        "# Define the state schema\n",
        "class DomainDetectorState(dict):\n",
        "    \"\"\"State for the domain detector agent.\"\"\"\n",
        "    def __init__(self, \n",
        "                 columns: List[str],\n",
        "                 column_types: Dict[str, str],\n",
        "                 domains_found: List[Dict[str, Any]] = None,\n",
        "                 current_domain: Optional[str] = None,\n",
        "                 jargon_terms: List[str] = None,\n",
        "                 remaining_columns: List[str] = None,\n",
        "                 iteration: int = 0,\n",
        "                 messages: List[str] = None):\n",
        "        \n",
        "        self.columns = columns\n",
        "        self.column_types = column_types\n",
        "        self.domains_found = domains_found or []\n",
        "        self.current_domain = current_domain\n",
        "        self.jargon_terms = jargon_terms or []\n",
        "        self.remaining_columns = remaining_columns or list(columns)\n",
        "        self.iteration = iteration\n",
        "        self.messages = messages or []\n",
        "        \n",
        "        super().__init__(\n",
        "            columns=self.columns,\n",
        "            column_types=self.column_types,\n",
        "            domains_found=self.domains_found,\n",
        "            current_domain=self.current_domain,\n",
        "            jargon_terms=self.jargon_terms,\n",
        "            remaining_columns=self.remaining_columns,\n",
        "            iteration=self.iteration,\n",
        "            messages=self.messages\n",
        "        )\n",
        "\n",
        "# Initialize LLM\n",
        "llm = OpenAI(temperature=0)\n",
        "\n",
        "# Define the \"Think\" node - Identify a potential domain\n",
        "def think(state: DomainDetectorState) -> DomainDetectorState:\n",
        "    \"\"\"Identify a potential domain based on remaining columns.\"\"\"\n",
        "    \n",
        "    # Skip if we already have 5 domains or no columns remain\n",
        "    if len(state[\"domains_found\"]) >= 5 or not state[\"remaining_columns\"]:\n",
        "        return state\n",
        "    \n",
        "    think_template = \"\"\"\n",
        "    You are a domain expert tasked with identifying knowledge domains from a set of data columns.\n",
        "    \n",
        "    Current columns to analyze: {remaining_columns}\n",
        "    Column types: {column_types}\n",
        "    \n",
        "    Domains already identified: {domains_found}\n",
        "    \n",
        "    Based on the remaining columns, identify ONE new knowledge domain that best represents them.\n",
        "    Consider business, scientific, or technical domains that would use such terminology.\n",
        "    \n",
        "    Return only the domain name as a single word or short phrase.\n",
        "    \"\"\"\n",
        "    \n",
        "    think_prompt = PromptTemplate(\n",
        "        template=think_template,\n",
        "        input_variables=[\"remaining_columns\", \"column_types\", \"domains_found\"]\n",
        "    )\n",
        "    \n",
        "    think_chain = LLMChain(llm=llm, prompt=think_prompt)\n",
        "    \n",
        "    domain = think_chain.run({\n",
        "        \"remaining_columns\": state[\"remaining_columns\"],\n",
        "        \"column_types\": state[\"column_types\"],\n",
        "        \"domains_found\": [d[\"domain\"] for d in state[\"domains_found\"]]\n",
        "    }).strip()\n",
        "    \n",
        "    new_state = state.copy()\n",
        "    new_state[\"current_domain\"] = domain\n",
        "    new_state[\"messages\"].append(f\"Identified potential domain: {domain}\")\n",
        "    \n",
        "    return new_state\n",
        "\n",
        "# -------------------------------------------------------------------\n",
        "# Dynamic LLM-powered jargon fetcher\n",
        "# -------------------------------------------------------------------\n",
        "def search_examples(domain: str, n_terms: int = 5, llm_model=llm) -> List[str]:\n",
        "    \"\"\"\n",
        "    Query the LLM for ~n_terms canonical jargon / acronyms that typify `domain`.\n",
        "    Falls back to a small generic list if the model response is unusable.\n",
        "    \"\"\"\n",
        "\n",
        "    # 1️⃣  Compose the prompt\n",
        "    prompt = PromptTemplate.from_template(\n",
        "        \"\"\"\n",
        "        You are a senior specialist in {domain}.\n",
        "        List {n} widely-used jargon terms or acronyms **unique** to this field.\n",
        "        Return ONLY a valid JSON array of quoted strings, nothing else.\n",
        "        Example → [\"term1\",\"term2\",...]\n",
        "        \"\"\"\n",
        "    )\n",
        "\n",
        "    # 2️⃣  Run the model\n",
        "    raw_response: str = (\n",
        "        prompt\n",
        "        | llm_model\n",
        "        | StrOutputParser()         # gives us the raw string\n",
        "    ).invoke({\"domain\": domain, \"n\": n_terms})\n",
        "\n",
        "    # 3️⃣  Try strict JSON parsing first\n",
        "    try:\n",
        "        terms = json.loads(raw_response)\n",
        "        if isinstance(terms, list) and len(terms) >= 3:\n",
        "            return terms[:n_terms]\n",
        "    except Exception:\n",
        "        pass\n",
        "\n",
        "    # 4️⃣  Regex rescue for “almost JSON”\n",
        "    match = re.search(r\"\\[(.*?)\\]\", raw_response, re.S)\n",
        "    if match:\n",
        "        rough = re.split(r\"[\\\"',\\[\\]]+\", match.group(1))\n",
        "        cleaned = [t.strip() for t in rough if t.strip()]\n",
        "        if cleaned:\n",
        "            return cleaned[:n_terms]\n",
        "\n",
        "    # 5️⃣  Final generic fallback\n",
        "    return [\"metric\", \"indicator\", \"analysis\", \"benchmark\", \"trend\"][:n_terms]\n",
        "\n",
        "\n",
        "# Define the \"Act\" node - Get jargon terms\n",
        "def act(state: DomainDetectorState) -> DomainDetectorState:\n",
        "    \n",
        "    \"\"\"Generate jargon terms for the current domain.\"\"\"\n",
        "\n",
        "    # Skip only if there is *no* domain to work on\n",
        "    if not state[\"current_domain\"]:\n",
        "        new_state = state.copy()\n",
        "        new_state[\"iteration\"] += 1\n",
        "        return new_state\n",
        "    \n",
        "    # Get example jargon terms\n",
        "    example_terms = search_examples(state[\"current_domain\"])\n",
        "    \n",
        "    act_template = \"\"\"\n",
        "    You are a domain expert in {domain}.\n",
        "    \n",
        "    Your task is to generate at least 5 jargon terms that are commonly used in the {domain} domain \n",
        "    but do NOT appear verbatim in the following column names: {columns}.\n",
        "    \n",
        "    Here are some example jargon terms for this domain: {examples}\n",
        "    \n",
        "    Return a JSON array of strings containing ONLY the jargon terms.\n",
        "    Example: [\"term1\", \"term2\", \"term3\", \"term4\", \"term5\"]\n",
        "    \"\"\"\n",
        "    \n",
        "    act_prompt = PromptTemplate(\n",
        "        template=act_template,\n",
        "        input_variables=[\"domain\", \"columns\", \"examples\"]\n",
        "    )\n",
        "    \n",
        "    act_chain = LLMChain(llm=llm, prompt=act_prompt)\n",
        "    \n",
        "    jargon_response = act_chain.run({\n",
        "        \"domain\": state[\"current_domain\"],\n",
        "        \"columns\": state[\"columns\"],\n",
        "        \"examples\": example_terms\n",
        "    })\n",
        "    \n",
        "    # Extract the JSON array from the response\n",
        "    try:\n",
        "        # Find anything that looks like a JSON array\n",
        "        match = re.search(r'\\[.*\\]', jargon_response, re.DOTALL)\n",
        "        if match:\n",
        "            jargon_terms = json.loads(match.group(0))\n",
        "        else:\n",
        "            jargon_terms = []\n",
        "    except Exception:\n",
        "        jargon_terms = []\n",
        "    \n",
        "    new_state = state.copy()\n",
        "    new_state[\"jargon_terms\"] = jargon_terms\n",
        "    new_state[\"messages\"].append(f\"Generated jargon terms: {jargon_terms}\")\n",
        "    new_state[\"iteration\"] += 1\n",
        "    return new_state\n",
        "\n",
        "# Define the \"Reflect\" node - Validate jargon terms\n",
        "def reflect(state: DomainDetectorState) -> DomainDetectorState:\n",
        "    \"\"\"Validate jargon terms and update domains found.\"\"\"\n",
        "    \n",
        "    if not state[\"current_domain\"] or not state[\"jargon_terms\"]:\n",
        "        return state\n",
        "    \n",
        "    # Convert column names to lowercase for case-insensitive comparison\n",
        "    columns_lower = [col.lower() for col in state[\"columns\"]]\n",
        "    \n",
        "    # Filter out jargon terms that appear in column names\n",
        "    valid_terms = []\n",
        "    for term in state[\"jargon_terms\"]:\n",
        "        if term.lower() not in columns_lower:\n",
        "            valid_terms.append(term)\n",
        "    \n",
        "    # If we have at least 3 valid terms, add the domain to our list\n",
        "    new_state = state.copy()\n",
        "    if len(valid_terms) >= 3:\n",
        "        domain_entry = {\n",
        "            \"domain\": state[\"current_domain\"],\n",
        "            \"jargon_terms\": valid_terms[:5]  # Limit to 5 terms\n",
        "        }\n",
        "        new_state[\"domains_found\"].append(domain_entry)\n",
        "        new_state[\"messages\"].append(f\"Added domain: {state['current_domain']} with terms: {valid_terms[:5]}\")\n",
        "        \n",
        "        # Remove columns that were used for this domain (optional)\n",
        "        # This is a simplified approach - in a real implementation, you might want\n",
        "        # to use the LLM to determine which columns were used for this domain\n",
        "        if len(new_state[\"remaining_columns\"]) > 0:\n",
        "            new_state[\"remaining_columns\"].pop(0)\n",
        "    else:\n",
        "        new_state[\"messages\"].append(f\"Rejected domain: {state['current_domain']} - not enough valid jargon terms\")\n",
        "    \n",
        "    # Reset current domain and jargon terms\n",
        "    new_state[\"current_domain\"] = None\n",
        "    new_state[\"jargon_terms\"] = []\n",
        "    new_state[\"iteration\"] += 1\n",
        "    \n",
        "    return new_state\n",
        "\n",
        "# Define the condition to end the graph\n",
        "def should_end(state: DomainDetectorState) -> str:\n",
        "    \"\"\"Determine if the graph should end.\"\"\"\n",
        "    if len(state[\"domains_found\"]) >= 5:\n",
        "        return \"end\"\n",
        "    if not state[\"remaining_columns\"]:\n",
        "        return \"end\"\n",
        "    if state[\"iteration\"] >= 10:  # Safety limit\n",
        "        return \"end\"\n",
        "    return \"continue\"\n",
        "\n",
        "# Build the graph\n",
        "def build_domain_detector_graph():\n",
        "    \"\"\"Build and return the domain detector graph.\"\"\"\n",
        "    workflow = StateGraph(DomainDetectorState)\n",
        "    \n",
        "    # Add nodes\n",
        "    workflow.add_node(\"think\", think)\n",
        "    workflow.add_node(\"act\", act)\n",
        "    workflow.add_node(\"reflect\", reflect)\n",
        "    \n",
        "    # Add edges\n",
        "    workflow.add_edge(\"think\", \"act\")\n",
        "    workflow.add_edge(\"act\", \"reflect\")\n",
        "    \n",
        "    # Add conditional edge\n",
        "    workflow.add_conditional_edges(\n",
        "        \"reflect\",\n",
        "        should_end,\n",
        "        {\n",
        "            \"continue\": \"think\",\n",
        "            \"end\": END\n",
        "        }\n",
        "    )\n",
        "    \n",
        "    # Set the entry point\n",
        "    workflow.set_entry_point(\"think\")\n",
        "    \n",
        "    return workflow.compile()\n",
        "\n",
        "# Function to run the domain detector\n",
        "def run_domain_detector_test1(columns, column_types=None):\n",
        "    \"\"\"\n",
        "    Run the domain detector on the given columns.\n",
        "    \n",
        "    Args:\n",
        "        columns (list): List of column names\n",
        "        column_types (dict, optional): Dictionary mapping column names to their data types\n",
        "    \n",
        "    Returns:\n",
        "        list: List of domains with their jargon terms\n",
        "    \"\"\"\n",
        "    if column_types is None:\n",
        "        column_types = {col: \"text\" for col in columns}\n",
        "    \n",
        "    # Initialize the state\n",
        "    initial_state = DomainDetectorState(\n",
        "        columns=columns,\n",
        "        column_types=column_types\n",
        "    )\n",
        "    \n",
        "    # Build and run the graph\n",
        "    graph = build_domain_detector_graph()\n",
        "    final_state = graph.invoke(initial_state)\n",
        "    \n",
        "    return final_state[\"domains_found\"]\n",
        "\n",
        "# Example usage\n",
        "if __name__ == \"__main__\":\n",
        "    columns = [\"Quarter\", \"number_Customers\", \"Total_Transactions\", \"Revenue\", \"Profit\"]\n",
        "    column_types = {\n",
        "        \"Quarter\": \"object\",\n",
        "        \"number_Customers\": \"int\",\n",
        "        \"Total_Transactions\": \"float\",\n",
        "        \"Revenue\": \"float\",\n",
        "        \"Profit\": \"float\"\n",
        "    }\n",
        "    \n",
        "    domains = run_domain_detector_test1(columns, column_types)\n",
        "    print(json.dumps(domains, indent=2))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 1. Cleaned Domain-Concept Pairs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[{'domain': 'Business Analytics',\n",
            "  'jargon_terms': 'Data Mining'},\n",
            " {'domain': 'Business Analytics',\n",
            "  'jargon_terms': 'Predictive Modeling'},\n",
            " {'domain': 'Business Analytics',\n",
            "  'jargon_terms': 'Data Visualization'},\n",
            " {'domain': 'Business Analytics',\n",
            "  'jargon_terms': 'Descriptive Analytics'},\n",
            " {'domain': 'Business Analytics',\n",
            "  'jargon_terms': 'Prescriptive Analytics'},\n",
            " {'domain': 'Business Finance', 'jargon_terms': 'EBITDA'},\n",
            " {'domain': 'Business Finance', 'jargon_terms': 'ROI'},\n",
            " {'domain': 'Business Finance', 'jargon_terms': 'DCF'},\n",
            " {'domain': 'Business Finance', 'jargon_terms': 'IRR'},\n",
            " {'domain': 'Business Finance', 'jargon_terms': 'NPV'},\n",
            " {'domain': 'Business Economics',\n",
            "  'jargon_terms': 'Demand Curve'},\n",
            " {'domain': 'Business Economics',\n",
            "  'jargon_terms': 'Opportunity Cost'},\n",
            " {'domain': 'Business Economics',\n",
            "  'jargon_terms': 'Elasticity'},\n",
            " {'domain': 'Business Economics',\n",
            "  'jargon_terms': 'Monopoly'},\n",
            " {'domain': 'Business Economics',\n",
            "  'jargon_terms': 'Oligopoly'},\n",
            " {'domain': 'Business Accounting',\n",
            "  'jargon_terms': 'Balance Sheet'},\n",
            " {'domain': 'Business Accounting',\n",
            "  'jargon_terms': 'Cash Flow Statement'},\n",
            " {'domain': 'Business Accounting',\n",
            "  'jargon_terms': 'Accrual Basis'},\n",
            " {'domain': 'Business Accounting',\n",
            "  'jargon_terms': 'Depreciation'},\n",
            " {'domain': 'Business Accounting',\n",
            "  'jargon_terms': 'Inventory Valuation'},\n",
            " {'domain': 'Business Management', 'jargon_terms': 'KPI'},\n",
            " {'domain': 'Business Management', 'jargon_terms': 'SWOT'},\n",
            " {'domain': 'Business Management', 'jargon_terms': 'B2B'},\n",
            " {'domain': 'Business Management', 'jargon_terms': 'B2C'}]\n"
          ]
        }
      ],
      "source": [
        "from collections import Counter\n",
        "\n",
        "# keep the first occurrence of any jargon term;\n",
        "# drop later duplicates that show up in other domains.\n",
        "\n",
        "def get_first_unique_pairs(domains_found):\n",
        "    \"\"\"\n",
        "    Keep the first‑seen (domain, jargon) pair for every jargon_term.\n",
        "    Later occurrences of the same jargon_term in other domains are skipped.\n",
        "    \"\"\"\n",
        "    seen = set()\n",
        "    unique_pairs = []\n",
        "\n",
        "    for entry in domains_found:          # keep original order\n",
        "        dom = entry[\"domain\"]\n",
        "        for term in entry[\"jargon_terms\"]:\n",
        "            if term not in seen:         # only accept the first time we see it\n",
        "                unique_pairs.append({\"domain\": dom, \"jargon_terms\": term})\n",
        "                seen.add(term)\n",
        "\n",
        "    return unique_pairs\n",
        "\n",
        "cleaned = get_first_unique_pairs(domains)\n",
        "import json, pprint; pprint.pp(cleaned, width=60)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2. Filter by yes/no"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ------------ 1. imports & chat object ------------\n",
        "from langchain_openai import ChatOpenAI\n",
        "from typing import List, Dict, Union\n",
        "\n",
        "# feel free to tweak these\n",
        "MODEL_NAME   = \"gpt-4o\"   # or \"gpt-4o\", \"gpt-3.5-turbo\"\n",
        "TEMPERATURE  = 0\n",
        "MAX_TOKENS   = 6               # we only need YES / NO\n",
        "API_KEY_ENV  = \"OPENAI_API_KEY\"\n",
        "\n",
        "# singleton chat object (re‑used for every call)\n",
        "chat = ChatOpenAI(\n",
        "    model_name   = MODEL_NAME,\n",
        "    temperature  = TEMPERATURE,\n",
        "    max_tokens   = MAX_TOKENS,\n",
        "    openai_api_key = None,     # uses env var by default\n",
        ")\n",
        "\n",
        "\n",
        "# ------------ 2. prompt builder ------------\n",
        "def _build_prompt(jargon:str, domain:str,\n",
        "                  columns:List[str], column_types:Dict[str,str]) -> str:\n",
        "    few_shots = \"\"\"\n",
        "### Example 1\n",
        "Data columns: [\"Date\",\"Open\",\"High\",\"Low\",\"Close\"]\n",
        "Column types: {\"Date\":\"object\",\"Open\":\"float\",\"High\":\"float\",\"Low\":\"float\",\"Close\":\"float\"}\n",
        "Jargon term: \"EBITDA\"\n",
        "Answer: YES, YES\n",
        "\n",
        "### Example 2\n",
        "Data columns: [\"User_ID\",\"Session_Duration\",\"Clicks\"]\n",
        "Column types: {\"User_ID\":\"int\",\"Session_Duration\":\"float\",\"Clicks\":\"int\"}\n",
        "Jargon term: \"Exploratory Data Analysis\"\n",
        "Answer: YES, NO\n",
        "\n",
        "### Example 3\n",
        "Data columns: [\"Temperature\",\"Humidity\"]\n",
        "Column types: {\"Temperature\":\"float\",\"Humidity\":\"float\"}\n",
        "Jargon term: \"Sharpe Ratio\"\n",
        "Answer: NO, YES\n",
        "\"\"\".strip()\n",
        "\n",
        "    rule = (\n",
        "        \"First flag = YES if the term is related to the given columns; else NO.\\n\"\n",
        "        \"Second flag = YES only if the term is normally written as a numeric or algebraic \"\n",
        "        \"equation (e.g. ROI = Profit/Cost); else NO.\\n\"\n",
        "        \"Answer format: YES/NO,YES/NO ‑ no extra words.\"\n",
        "    )\n",
        "\n",
        "    task = f\"\"\"\n",
        "### Task\n",
        "Domain      : {domain}\n",
        "Data columns: {json.dumps(columns)}\n",
        "Column types: {json.dumps(column_types)}\n",
        "Jargon term : \"{jargon}\"\n",
        "{rule}\n",
        "Answer:\"\"\"\n",
        "\n",
        "    return f\"{few_shots}\\n{task}\"\n",
        "\n",
        "# ------------- 3. evaluator -------------\n",
        "def lc_relevance(\n",
        "        pairs: List[Dict[str, str]],\n",
        "        columns: List[str],\n",
        "        column_types: Dict[str, str],\n",
        "        *,\n",
        "        keep_only_formula: bool = True,   # <-- new switch\n",
        ") -> List[Dict[str, Union[str, bool]]]:\n",
        "    \"\"\"\n",
        "    Evaluate every jargon term and (optionally) RETURN ONLY THOSE\n",
        "    that are both   relevant == True   AND   has_formula == True.\n",
        "\n",
        "    Set `keep_only_formula=False` if you still want the full list.\n",
        "    \"\"\"\n",
        "    good_rows: list[dict] = []\n",
        "    all_rows : list[dict] = []\n",
        "\n",
        "    for p in pairs:\n",
        "        term   = p.get(\"jargon_terms\") or p.get(\"concept\")\n",
        "        domain = p[\"domain\"]\n",
        "\n",
        "        prompt = _build_prompt(term, domain, columns, column_types)\n",
        "        reply  = chat.invoke(prompt).content.strip().upper()\n",
        "\n",
        "        # Accept variants such as \"YES , NO\"\n",
        "        parts       = [x.strip() for x in reply.split(\",\")]\n",
        "        rel_flag    = parts[0].startswith(\"Y\") if parts else False\n",
        "        formula_flag = parts[1].startswith(\"Y\") if len(parts) > 1 else False\n",
        "\n",
        "        row = {\n",
        "            \"domain\"      : domain,\n",
        "            \"jargon_term\" : term,\n",
        "            \"relevant\"    : rel_flag,\n",
        "            \"has_formula\" : formula_flag,\n",
        "        }\n",
        "\n",
        "        all_rows.append(row)\n",
        "        if rel_flag and formula_flag:\n",
        "            good_rows.append(row)\n",
        "\n",
        "    return good_rows if keep_only_formula else all_rows\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "===== evaluator output (full list) =====\n",
            "\n",
            "             domain            jargon_term  relevant  has_formula\n",
            " Business Analytics            Data Mining      True        False\n",
            " Business Analytics    Predictive Modeling      True        False\n",
            " Business Analytics     Data Visualization      True        False\n",
            " Business Analytics  Descriptive Analytics      True        False\n",
            " Business Analytics Prescriptive Analytics      True        False\n",
            "   Business Finance                 EBITDA      True         True\n",
            "   Business Finance                    ROI      True         True\n",
            "   Business Finance                    DCF      True         True\n",
            "   Business Finance                    IRR      True         True\n",
            "   Business Finance                    NPV      True         True\n",
            " Business Economics           Demand Curve      True        False\n",
            " Business Economics       Opportunity Cost      True        False\n",
            " Business Economics             Elasticity      True         True\n",
            " Business Economics               Monopoly      True        False\n",
            " Business Economics              Oligopoly      True        False\n",
            "Business Accounting          Balance Sheet      True        False\n",
            "Business Accounting    Cash Flow Statement      True        False\n",
            "Business Accounting          Accrual Basis      True        False\n",
            "Business Accounting           Depreciation      True        False\n",
            "Business Accounting    Inventory Valuation      True        False\n",
            "Business Management                    KPI      True        False\n",
            "Business Management                   SWOT      True        False\n",
            "Business Management                    B2B      True        False\n",
            "Business Management                    B2C      True        False\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# --- Evaluate every jargon term ------------------------------\n",
        "\n",
        "evaluated_all = lc_relevance(\n",
        "        cleaned,\n",
        "        columns,\n",
        "        column_types,\n",
        "        keep_only_formula=False   # return *all* rows so we can inspect the two flags\n",
        ")\n",
        "\n",
        "# --- Put results in a nice, readable table -------------------\n",
        "import pandas as pd\n",
        "from IPython.display import display  # Jupyter‑friendly\n",
        "\n",
        "# convert list[dict] → DataFrame\n",
        "results_df = pd.DataFrame(evaluated_all)\n",
        "\n",
        "# reorder columns for clarity (optional)\n",
        "col_order = [\n",
        "    \"domain\",\n",
        "    \"jargon_term\",\n",
        "    \"relevant\",\n",
        "    \"has_formula\",\n",
        "]\n",
        "results_df = results_df[col_order]\n",
        "\n",
        "# show the DataFrame\n",
        "print(\"\\n===== evaluator output (full list) =====\\n\")\n",
        "print(results_df.to_string(index=False))  # nice console print\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3. Prepare for Formula Retriever"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[\n",
            "  {\n",
            "    \"domain\": \"Business Finance\",\n",
            "    \"jargon_term\": \"EBITDA\",\n",
            "    \"relevant\": true,\n",
            "    \"has_formula\": true\n",
            "  },\n",
            "  {\n",
            "    \"domain\": \"Business Finance\",\n",
            "    \"jargon_term\": \"ROI\",\n",
            "    \"relevant\": true,\n",
            "    \"has_formula\": true\n",
            "  },\n",
            "  {\n",
            "    \"domain\": \"Business Finance\",\n",
            "    \"jargon_term\": \"DCF\",\n",
            "    \"relevant\": true,\n",
            "    \"has_formula\": true\n",
            "  },\n",
            "  {\n",
            "    \"domain\": \"Business Finance\",\n",
            "    \"jargon_term\": \"IRR\",\n",
            "    \"relevant\": true,\n",
            "    \"has_formula\": true\n",
            "  },\n",
            "  {\n",
            "    \"domain\": \"Business Finance\",\n",
            "    \"jargon_term\": \"NPV\",\n",
            "    \"relevant\": true,\n",
            "    \"has_formula\": true\n",
            "  },\n",
            "  {\n",
            "    \"domain\": \"Business Economics\",\n",
            "    \"jargon_term\": \"Elasticity\",\n",
            "    \"relevant\": true,\n",
            "    \"has_formula\": true\n",
            "  }\n",
            "]\n"
          ]
        }
      ],
      "source": [
        "evaluated = lc_relevance(cleaned, columns, column_types)\n",
        "\n",
        "print(json.dumps(evaluated, indent=2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[{'domain': 'Business Finance', 'jargon_term': 'EBITDA', 'relevant': True, 'has_formula': True}, {'domain': 'Business Finance', 'jargon_term': 'ROI', 'relevant': True, 'has_formula': True}, {'domain': 'Business Finance', 'jargon_term': 'DCF', 'relevant': True, 'has_formula': True}, {'domain': 'Business Finance', 'jargon_term': 'IRR', 'relevant': True, 'has_formula': True}, {'domain': 'Business Finance', 'jargon_term': 'NPV', 'relevant': True, 'has_formula': True}, {'domain': 'Business Economics', 'jargon_term': 'Elasticity', 'relevant': True, 'has_formula': True}]\n"
          ]
        }
      ],
      "source": [
        "print(evaluated)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Agent2: Formula Fetcher"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 1. Prompt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {},
      "outputs": [],
      "source": [
        "_GET_FORMULA_TMPL = \"\"\"\\\n",
        "You are a business‑analytics assistant.\n",
        "\n",
        "### Task\n",
        "For the given *jargon term* and *business domain*:\n",
        "\n",
        "1. State the best‑known **numeric formula** (use valid python‑style identifiers).\n",
        "2. List every variable that appears in the formula, with a 1‑line definition.\n",
        "\n",
        "### Format\n",
        "Return **valid JSON** exactly like:\n",
        "\n",
        "{{\n",
        "  \"formula\"  : \"<formula_here>\",\n",
        "  \"variables\": {{\n",
        "      \"<var1>\": \"<definition var1>\",\n",
        "      \"<var2>\": \"<definition var2>\"\n",
        "  }}\n",
        "}}\n",
        "\n",
        "### Examples\n",
        "---\n",
        "Domain     : Business Finance\n",
        "Jargon term: ROI\n",
        "JSON:\n",
        "{{\n",
        "  \"formula\"  : \"Net_Profit / Investment_Cost\",\n",
        "  \"variables\": {{\n",
        "      \"Net_Profit\"     : \"Total profit generated by the investment\",\n",
        "      \"Investment_Cost\": \"Initial cash outlay\"\n",
        "  }}\n",
        "}}\n",
        "---\n",
        "Domain     : Business Finance\n",
        "Jargon term: EBITDA\n",
        "JSON:\n",
        "{{\n",
        "  \"formula\"  : \"Operating_Income + Depreciation + Amortization\",\n",
        "  \"variables\": {{\n",
        "      \"Operating_Income\": \"Earnings from operations before interest & taxes\",\n",
        "      \"Depreciation\"    : \"Expense for tangible asset depreciation\",\n",
        "      \"Amortization\"    : \"Expense for intangible asset amortization\"\n",
        "  }}\n",
        "}}\n",
        "---\n",
        "Now answer for:\n",
        "Domain     : {domain}\n",
        "Jargon term: {term}\n",
        "JSON:\"\"\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2. Formula Fetcher"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 113,
      "metadata": {},
      "outputs": [],
      "source": [
        "import json, re\n",
        "from langchain.schema import HumanMessage       \n",
        "from tenacity import retry, stop_after_attempt, wait_fixed\n",
        "\n",
        "chat_formula = ChatOpenAI(\n",
        "    model_name      = MODEL_NAME,\n",
        "    temperature     = 0,\n",
        "    max_tokens      = 256,\n",
        "    openai_api_key  = None,\n",
        "    # the API itself can insist on JSON if you have gpt‑4o/3.5‑turbo‑0125+:\n",
        "    model_kwargs   = {\"response_format\": {\"type\": \"json_object\"}},\n",
        ")\n",
        "\n",
        "@retry(stop=stop_after_attempt(3), wait=wait_fixed(1))\n",
        "def _ask_formula(term: str, domain: str) -> dict:\n",
        "    prompt = _GET_FORMULA_TMPL.format(term=term, domain=domain)\n",
        "    raw    = chat_formula.invoke(prompt).content.strip()\n",
        "\n",
        "    # 1️⃣ strip code‑fences if present\n",
        "    if raw.startswith(\"```\"):\n",
        "        raw = raw.split(\"```\")[1].strip()\n",
        "\n",
        "    # 2️⃣ drop a leading language identifier such as “json”\n",
        "    if raw.lower().startswith(\"json\"):\n",
        "        raw = raw[4:].lstrip()          # remove “json” + any following spaces/newlines\n",
        "\n",
        "    # 3️⃣ (extra‑robust) grab just the JSON block\n",
        "    first_brace = raw.find(\"{\")\n",
        "    last_brace  = raw.rfind(\"}\")\n",
        "    if first_brace == -1 or last_brace == -1:\n",
        "        raise ValueError(\"No JSON object found in model response:\\n\" + raw)\n",
        "\n",
        "    json_str = raw[first_brace : last_brace + 1]\n",
        "    return json.loads(json_str)\n",
        "\n",
        "\n",
        "\n",
        "def get_formula(jargon_rows: list[dict]) -> list[dict]:\n",
        "    \"\"\"\n",
        "    Takes the *filtered* output from lc_relevance()\n",
        "    (list of dicts with domain & jargon_term) and returns\n",
        "    a **new list** that adds 'formula' and 'variables'.\n",
        "    \"\"\"\n",
        "    enriched = []\n",
        "    for row in jargon_rows:\n",
        "        term   = row[\"jargon_term\"]\n",
        "        domain = row[\"domain\"]\n",
        "\n",
        "        try:\n",
        "            data = _ask_formula(term, domain)\n",
        "            row  = {**row, **data}           # merge dicts (PY≥3.9)\n",
        "        except Exception as e:\n",
        "            print(type(e).__name__, \"→\", e)          # <‑‑ add this\n",
        "            row = {**row,\n",
        "               \"formula\": None,\n",
        "                \"variables\": {},\n",
        "               \"error\": str(e)}\n",
        "        \n",
        "        enriched.append(row)\n",
        "\n",
        "    return enriched\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 114,
      "metadata": {},
      "outputs": [],
      "source": [
        "# relevant_rows = lc_relevance(pairs, cols, col_types, keep_only_formula=True)\n",
        "\n",
        "formulas = get_formula(evaluated)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 118,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[{'domain': 'Business Finance', 'jargon_term': 'EBITDA', 'relevant': True, 'has_formula': True, 'formula': 'Operating_Income + Depreciation + Amortization', 'variables': {'Operating_Income': 'Earnings from operations before interest & taxes', 'Depreciation': 'Expense for tangible asset depreciation', 'Amortization': 'Expense for intangible asset amortization'}}, {'domain': 'Business Finance', 'jargon_term': 'ROI', 'relevant': True, 'has_formula': True, 'formula': 'Net_Profit / Investment_Cost', 'variables': {'Net_Profit': 'Total profit generated by the investment', 'Investment_Cost': 'Initial cash outlay'}}, {'domain': 'Business Finance', 'jargon_term': 'DCF', 'relevant': True, 'has_formula': True, 'formula': 'sum(CF_t / (1 + r)**t for t in range(1, n+1))', 'variables': {'CF_t': 'Cash flow at time t', 'r': 'Discount rate', 't': 'Time period', 'n': 'Total number of periods'}}, {'domain': 'Business Finance', 'jargon_term': 'IRR', 'relevant': True, 'has_formula': True, 'formula': 'npv = sum((Cash_Flow_t / (1 + IRR)**t) for t in range(1, n+1))', 'variables': {'npv': 'Net present value, set to zero to solve for IRR', 'Cash_Flow_t': 'Cash flow at time t', 'IRR': 'Internal rate of return, the discount rate that makes npv zero', 't': 'Time period, typically in years', 'n': 'Total number of time periods'}}, {'domain': 'Business Finance', 'jargon_term': 'NPV', 'relevant': True, 'has_formula': True, 'formula': 'sum(Cash_Flow_t / (1 + Discount_Rate)**t for t in range(1, n+1)) - Initial_Investment', 'variables': {'Cash_Flow_t': 'Net cash inflow during the period t', 'Discount_Rate': 'Rate of return used to discount future cash flows', 't': 'Time period, typically in years', 'n': 'Total number of periods', 'Initial_Investment': 'Initial cash outlay for the investment'}}, {'domain': 'Business Economics', 'jargon_term': 'Elasticity', 'relevant': True, 'has_formula': True, 'formula': '(%_Change_in_Quantity_Demanded) / (%_Change_in_Price)', 'variables': {'%_Change_in_Quantity_Demanded': 'Percentage change in the quantity demanded of a good', '%_Change_in_Price': 'Percentage change in the price of the good'}}]\n"
          ]
        }
      ],
      "source": [
        "print(formulas)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 116,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>domain</th>\n",
              "      <th>jargon_term</th>\n",
              "      <th>relevant</th>\n",
              "      <th>has_formula</th>\n",
              "      <th>formula</th>\n",
              "      <th>variables</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Business Finance</td>\n",
              "      <td>EBITDA</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>Operating_Income + Depreciation + Amortization</td>\n",
              "      <td>{'Operating_Income': 'Earnings from operations...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Business Finance</td>\n",
              "      <td>ROI</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>Net_Profit / Investment_Cost</td>\n",
              "      <td>{'Net_Profit': 'Total profit generated by the ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Business Finance</td>\n",
              "      <td>DCF</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>sum(CF_t / (1 + r)**t for t in range(1, n+1))</td>\n",
              "      <td>{'CF_t': 'Cash flow at time t', 'r': 'Discount...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Business Finance</td>\n",
              "      <td>IRR</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>npv = sum((Cash_Flow_t / (1 + IRR)**t) for t i...</td>\n",
              "      <td>{'npv': 'Net present value, set to zero to sol...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Business Finance</td>\n",
              "      <td>NPV</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>sum(Cash_Flow_t / (1 + Discount_Rate)**t for t...</td>\n",
              "      <td>{'Cash_Flow_t': 'Net cash inflow during the pe...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             domain jargon_term  relevant  has_formula  \\\n",
              "0  Business Finance      EBITDA      True         True   \n",
              "1  Business Finance         ROI      True         True   \n",
              "2  Business Finance         DCF      True         True   \n",
              "3  Business Finance         IRR      True         True   \n",
              "4  Business Finance         NPV      True         True   \n",
              "\n",
              "                                             formula  \\\n",
              "0     Operating_Income + Depreciation + Amortization   \n",
              "1                       Net_Profit / Investment_Cost   \n",
              "2      sum(CF_t / (1 + r)**t for t in range(1, n+1))   \n",
              "3  npv = sum((Cash_Flow_t / (1 + IRR)**t) for t i...   \n",
              "4  sum(Cash_Flow_t / (1 + Discount_Rate)**t for t...   \n",
              "\n",
              "                                           variables  \n",
              "0  {'Operating_Income': 'Earnings from operations...  \n",
              "1  {'Net_Profit': 'Total profit generated by the ...  \n",
              "2  {'CF_t': 'Cash flow at time t', 'r': 'Discount...  \n",
              "3  {'npv': 'Net present value, set to zero to sol...  \n",
              "4  {'Cash_Flow_t': 'Net cash inflow during the pe...  "
            ]
          },
          "execution_count": 116,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = pd.DataFrame(formulas)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3. Prepare for Matcher"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 136,
      "metadata": {},
      "outputs": [],
      "source": [
        "def extract_formula_keys(items):\n",
        "    \"\"\"\n",
        "    Parameters\n",
        "    ----------\n",
        "    items : list[dict]\n",
        "        The list of dictionaries containing formula information.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    list[str]\n",
        "        All formulas, deduplicated in order of first appearance.\n",
        "    \"\"\"\n",
        "    seen, out = set(), []\n",
        "    for d in items:\n",
        "        formula = d.get(\"formula\")\n",
        "        if formula and formula not in seen:\n",
        "            seen.add(formula)\n",
        "            out.append(formula)\n",
        "    return out\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 138,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['Operating_Income + Depreciation + Amortization', 'Net_Profit / Investment_Cost', 'sum(CF_t / (1 + r)**t for t in range(1, n+1))', 'npv = sum((Cash_Flow_t / (1 + IRR)**t) for t in range(1, n+1))', 'sum(Cash_Flow_t / (1 + Discount_Rate)**t for t in range(1, n+1)) - Initial_Investment', '(%_Change_in_Quantity_Demanded) / (%_Change_in_Price)']\n"
          ]
        }
      ],
      "source": [
        "matcher_variables = extract_formula_keys(formulas)\n",
        "print(matcher_variables)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Agent 3: Formula Matcher"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 130,
      "metadata": {},
      "outputs": [],
      "source": [
        "import re\n",
        "import json\n",
        "import asyncio\n",
        "from typing import List, Dict, Any, Optional\n",
        "\n",
        "from langchain_openai import OpenAI\n",
        "from langchain_core.prompts import PromptTemplate\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain.chains import LLMChain\n",
        "\n",
        "# ────────────────────────────────────────────────────────────────\n",
        "# 0.  Helper — shared async run for notebooks that may already\n",
        "#     have a running event‑loop (e.g. Jupyter, VSCode)\n",
        "# ----------------------------------------------------------------\n",
        "try:\n",
        "    import nest_asyncio\n",
        "    nest_asyncio.apply()\n",
        "except ImportError:\n",
        "    # ok if the package is missing in pure‑script execution\n",
        "    pass\n",
        "\n",
        "\n",
        "def run_async(coro):\n",
        "    \"\"\"Safe `await` helper that works in both scripts & notebooks.\"\"\"\n",
        "    try:\n",
        "        return asyncio.run(coro)\n",
        "    except RuntimeError as err:\n",
        "        if \"already running\" in str(err):\n",
        "            return asyncio.get_event_loop().run_until_complete(coro)\n",
        "        raise\n",
        "\n",
        "# ────────────────────────────────────────────────────────────────\n",
        "# 1.  Initialise the LLM \n",
        "# ----------------------------------------------------------------\n",
        "\n",
        "llm_matcher = ChatOpenAI(\n",
        "    model_name      = MODEL_NAME,\n",
        "    temperature     = TEMPERATURE,\n",
        "    max_tokens      = 256,\n",
        "    openai_api_key  = None,      # `None` → pull from env var automatically\n",
        "    # the API itself can insist on JSON if you have gpt‑4o/3.5‑turbo‑0125+:\n",
        "    model_kwargs   = {\"response_format\": {\"type\": \"json_object\"}}\n",
        ")\n",
        "\n",
        "# ────────────────────────────────────────────────────────────────\n",
        "# 2.  Wrap the two external tools as tiny LLM chains\n",
        "# ----------------------------------------------------------------\n",
        "FUZZY_PROMPT = PromptTemplate(\n",
        "    input_variables=[\"var\", \"columns\"],\n",
        "    template=(\n",
        "        \"You are a helper that aligns a short **variable** name to **one** of the \"\n",
        "        \"candidate *column* names.\\n\\n\"\n",
        "        \"Variable: {var}\\n\"\n",
        "        \"Candidates: {columns}\\n\\n\"\n",
        "        \"Which candidate is the **best semantic match**?  Reply **JSON only**:\\n\"\n",
        "        '{{\"match\":\"<column_name>\", \"score\": <0.0-1.0>}}'\n",
        "    ),\n",
        ")\n",
        "\n",
        "fuzzy_chain = LLMChain(\n",
        "    llm=llm_matcher,\n",
        "    prompt=FUZZY_PROMPT,\n",
        "    output_parser=StrOutputParser(),\n",
        ")\n",
        "\n",
        "DERIVE_PROMPT = PromptTemplate(\n",
        "    input_variables=[\"var\", \"columns\"],\n",
        "    template=(\n",
        "        \"You are given a variable `{var}` and these table columns: {columns}.\\n\\n\"\n",
        "        \"Can `{var}` be **computed** from the columns (via arithmetic or ratios)?\\n\"\n",
        "        \"If yes → output **exactly** the JSON:\\n\"\n",
        "        '{{\"expr\":\"<python-or-pandas-expression>\"}} \\n'\n",
        "        \"If impossible →  {{\\\"expr\\\": null}}\"\n",
        "    ),\n",
        ")\n",
        "\n",
        "derive_chain = LLMChain(\n",
        "    llm=llm_matcher,\n",
        "    prompt=DERIVE_PROMPT,\n",
        "    output_parser=StrOutputParser(),\n",
        ")\n",
        "\n",
        "# ────────────────────────────────────────────────────────────────\n",
        "# 3. ReAct‑style agent operating *per formula*\n",
        "# ----------------------------------------------------------------\n",
        "class FormulaAgent:\n",
        "    \"\"\"Single‑formula matcher that records every ReAct step.\"\"\"\n",
        "\n",
        "    _VAR_REGEX = re.compile(r\"\\b[A-Za-z_][A-Za-z0-9_]*\\b\")\n",
        "\n",
        "    def __init__(\n",
        "        self, formula: str, columns: List[str], *, threshold: float = 0.8\n",
        "    ) -> None:\n",
        "        self.formula = formula\n",
        "        self.columns = columns\n",
        "        self.threshold = threshold\n",
        "        self.vars = self._extract_vars(formula)\n",
        "\n",
        "        # ReAct trace & outputs\n",
        "        self.log: List[Dict[str, Any]] = []\n",
        "        self.mapping: Dict[str, str] = {}\n",
        "        self.status: str = \"pending\"\n",
        "        self.failure_reason: Optional[str] = None\n",
        "\n",
        "    # ------------------------------------------------------------\n",
        "    @staticmethod\n",
        "    def _extract_vars(expr: str) -> List[str]:\n",
        "        # crude: all identifiers that *start* with a letter/underscore\n",
        "        return list(dict.fromkeys(FormulaAgent._VAR_REGEX.findall(expr)))\n",
        "\n",
        "    # ------------------------------------------------------------\n",
        "    async def _fuzzy(self, var: str) -> Dict[str, Any]:\n",
        "        \"\"\"Call fuzzy_match tool and parse JSON.\"\"\"\n",
        "        raw = await fuzzy_chain.arun(var=var, columns=self.columns)\n",
        "        return json.loads(raw)\n",
        "\n",
        "    async def _derive(self, var: str) -> Dict[str, Any]:\n",
        "        raw = await derive_chain.arun(var=var, columns=self.columns)\n",
        "        return json.loads(raw)\n",
        "\n",
        "    # ------------------------------------------------------------\n",
        "    async def run(self) -> Dict[str, Any]:\n",
        "        for v in self.vars:\n",
        "            # THOUGHT\n",
        "            self.log.append({\"step\": \"thought\", \"text\": f\"Match variable '{v}'\"})\n",
        "\n",
        "            # ACTION 1: fuzzy_match\n",
        "            res = await self._fuzzy(v)\n",
        "            self.log.append({\"step\": \"action\", \"tool\": \"fuzzy_match\", \"input\": v, \"output\": res})\n",
        "\n",
        "            if res.get(\"score\", 0) >= self.threshold:\n",
        "                self.mapping[v] = res[\"match\"]\n",
        "                continue\n",
        "\n",
        "            # THOUGHT again\n",
        "            self.log.append({\"step\": \"thought\", \"text\": f\"Try derive '{v}'\"})\n",
        "\n",
        "            # ACTION 2: can_be_derived\n",
        "            der = await self._derive(v)\n",
        "            self.log.append({\"step\": \"action\", \"tool\": \"can_be_derived\", \"input\": v, \"output\": der})\n",
        "\n",
        "            if der.get(\"expr\"):\n",
        "                self.mapping[v] = der[\"expr\"]\n",
        "                continue\n",
        "\n",
        "            # FAILURE — give up for this formula\n",
        "            self.status = \"fail\"\n",
        "            self.failure_reason = \"derive_fail\"\n",
        "            break\n",
        "        else:\n",
        "            # completed loop without break ⇒ success!\n",
        "            self.status = \"saved\"\n",
        "\n",
        "        return {\n",
        "            \"formula\": self.formula,\n",
        "            \"mapping\": self.mapping,\n",
        "            \"status\": self.status,\n",
        "            \"failure_reason\": self.failure_reason,\n",
        "            \"log\": self.log,\n",
        "        }\n",
        "\n",
        "# ────────────────────────────────────────────────────────────────\n",
        "# 4.  Async batch helper\n",
        "# ----------------------------------------------------------------\n",
        "async def batch_match(formulas: List[str], columns: List[str]) -> List[Dict[str, Any]]:\n",
        "    agents = [FormulaAgent(f, columns) for f in formulas]\n",
        "    return await asyncio.gather(*[a.run() for a in agents])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 139,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[{'failure_reason': 'derive_fail',\n",
            "  'formula': 'Operating_Income + Depreciation + Amortization',\n",
            "  'log': [{'step': 'thought', 'text': \"Match variable 'Operating_Income'\"},\n",
            "          {'input': 'Operating_Income',\n",
            "           'output': {'match': 'Profit', 'score': 0.8},\n",
            "           'step': 'action',\n",
            "           'tool': 'fuzzy_match'},\n",
            "          {'step': 'thought', 'text': \"Match variable 'Depreciation'\"},\n",
            "          {'input': 'Depreciation',\n",
            "           'output': {'match': 'Profit', 'score': 0.3},\n",
            "           'step': 'action',\n",
            "           'tool': 'fuzzy_match'},\n",
            "          {'step': 'thought', 'text': \"Try derive 'Depreciation'\"},\n",
            "          {'input': 'Depreciation', 'output': {'expr': None}, 'step': 'action', 'tool': 'can_be_derived'}],\n",
            "  'mapping': {'Operating_Income': 'Profit'},\n",
            "  'status': 'fail'},\n",
            " {'failure_reason': 'derive_fail',\n",
            "  'formula': 'Net_Profit / Investment_Cost',\n",
            "  'log': [{'step': 'thought', 'text': \"Match variable 'Net_Profit'\"},\n",
            "          {'input': 'Net_Profit', 'output': {'match': 'Profit', 'score': 0.9}, 'step': 'action', 'tool': 'fuzzy_match'},\n",
            "          {'step': 'thought', 'text': \"Match variable 'Investment_Cost'\"},\n",
            "          {'input': 'Investment_Cost',\n",
            "           'output': {'match': 'Profit', 'score': 0.7},\n",
            "           'step': 'action',\n",
            "           'tool': 'fuzzy_match'},\n",
            "          {'step': 'thought', 'text': \"Try derive 'Investment_Cost'\"},\n",
            "          {'input': 'Investment_Cost', 'output': {'expr': None}, 'step': 'action', 'tool': 'can_be_derived'}],\n",
            "  'mapping': {'Net_Profit': 'Profit'},\n",
            "  'status': 'fail'},\n",
            " {'failure_reason': 'derive_fail',\n",
            "  'formula': 'sum(CF_t / (1 + r)**t for t in range(1, n+1))',\n",
            "  'log': [{'step': 'thought', 'text': \"Match variable 'sum'\"},\n",
            "          {'input': 'sum', 'output': {'match': 'Revenue', 'score': 0.8}, 'step': 'action', 'tool': 'fuzzy_match'},\n",
            "          {'step': 'thought', 'text': \"Match variable 'CF_t'\"},\n",
            "          {'input': 'CF_t', 'output': {'match': 'Profit', 'score': 0.7}, 'step': 'action', 'tool': 'fuzzy_match'},\n",
            "          {'step': 'thought', 'text': \"Try derive 'CF_t'\"},\n",
            "          {'input': 'CF_t', 'output': {'expr': None}, 'step': 'action', 'tool': 'can_be_derived'}],\n",
            "  'mapping': {'sum': 'Revenue'},\n",
            "  'status': 'fail'},\n",
            " {'failure_reason': 'derive_fail',\n",
            "  'formula': 'npv = sum((Cash_Flow_t / (1 + IRR)**t) for t in range(1, n+1))',\n",
            "  'log': [{'step': 'thought', 'text': \"Match variable 'npv'\"},\n",
            "          {'input': 'npv', 'output': {'match': 'Profit', 'score': 0.8}, 'step': 'action', 'tool': 'fuzzy_match'},\n",
            "          {'step': 'thought', 'text': \"Match variable 'sum'\"},\n",
            "          {'input': 'sum', 'output': {'match': 'Revenue', 'score': 0.8}, 'step': 'action', 'tool': 'fuzzy_match'},\n",
            "          {'step': 'thought', 'text': \"Match variable 'Cash_Flow_t'\"},\n",
            "          {'input': 'Cash_Flow_t',\n",
            "           'output': {'match': 'Profit', 'score': 0.7},\n",
            "           'step': 'action',\n",
            "           'tool': 'fuzzy_match'},\n",
            "          {'step': 'thought', 'text': \"Try derive 'Cash_Flow_t'\"},\n",
            "          {'input': 'Cash_Flow_t', 'output': {'expr': None}, 'step': 'action', 'tool': 'can_be_derived'}],\n",
            "  'mapping': {'npv': 'Profit', 'sum': 'Revenue'},\n",
            "  'status': 'fail'},\n",
            " {'failure_reason': 'derive_fail',\n",
            "  'formula': 'sum(Cash_Flow_t / (1 + Discount_Rate)**t for t in range(1, n+1)) - Initial_Investment',\n",
            "  'log': [{'step': 'thought', 'text': \"Match variable 'sum'\"},\n",
            "          {'input': 'sum', 'output': {'match': 'Revenue', 'score': 0.8}, 'step': 'action', 'tool': 'fuzzy_match'},\n",
            "          {'step': 'thought', 'text': \"Match variable 'Cash_Flow_t'\"},\n",
            "          {'input': 'Cash_Flow_t',\n",
            "           'output': {'match': 'Profit', 'score': 0.7},\n",
            "           'step': 'action',\n",
            "           'tool': 'fuzzy_match'},\n",
            "          {'step': 'thought', 'text': \"Try derive 'Cash_Flow_t'\"},\n",
            "          {'input': 'Cash_Flow_t', 'output': {'expr': None}, 'step': 'action', 'tool': 'can_be_derived'}],\n",
            "  'mapping': {'sum': 'Revenue'},\n",
            "  'status': 'fail'},\n",
            " {'failure_reason': 'derive_fail',\n",
            "  'formula': '(%_Change_in_Quantity_Demanded) / (%_Change_in_Price)',\n",
            "  'log': [{'step': 'thought', 'text': \"Match variable '_Change_in_Quantity_Demanded'\"},\n",
            "          {'input': '_Change_in_Quantity_Demanded',\n",
            "           'output': {'match': 'number_Customers', 'score': 0.7},\n",
            "           'step': 'action',\n",
            "           'tool': 'fuzzy_match'},\n",
            "          {'step': 'thought', 'text': \"Try derive '_Change_in_Quantity_Demanded'\"},\n",
            "          {'input': '_Change_in_Quantity_Demanded',\n",
            "           'output': {'expr': None},\n",
            "           'step': 'action',\n",
            "           'tool': 'can_be_derived'}],\n",
            "  'mapping': {},\n",
            "  'status': 'fail'}]\n"
          ]
        }
      ],
      "source": [
        "# ────────────────────────────────────────────────────────────────\n",
        "# 5.  Quick interactive demo (only runs when executed as a script)\n",
        "# ----------------------------------------------------------------\n",
        "if __name__ == \"__main__\":\n",
        "    demo_columns = [\n",
        "        \"Quarter\",\n",
        "        \"number_Customers\",\n",
        "        \"Total_Transactions\",\n",
        "        \"Revenue\",\n",
        "        \"Profit\",\n",
        "    ]\n",
        "\n",
        "    demo_formulas = matcher_variables\n",
        "\n",
        "    output = run_async(batch_match(demo_formulas, demo_columns))\n",
        "    from pprint import pprint\n",
        "\n",
        "    pprint(output, width=120, compact=True)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
