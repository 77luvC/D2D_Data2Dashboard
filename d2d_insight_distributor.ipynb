{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Preperation: OpenAI API KEY"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "import json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from dotenv import load_dotenv\n",
        "import os\n",
        "\n",
        "load_dotenv()\n",
        "print(os.getenv(\"OPENAI_API_KEY\"))  # should show your key\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Agent1: Domain Detector"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: langchain-core in /Users/zhangran/Library/Python/3.9/lib/python/site-packages (0.3.56)\n",
            "Requirement already satisfied: langchain-openai in /Users/zhangran/Library/Python/3.9/lib/python/site-packages (0.3.14)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.125 in /Users/zhangran/Library/Python/3.9/lib/python/site-packages (from langchain-core) (0.3.33)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /Users/zhangran/Library/Python/3.9/lib/python/site-packages (from langchain-core) (9.1.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /Users/zhangran/Library/Python/3.9/lib/python/site-packages (from langchain-core) (1.33)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /Users/zhangran/Library/Python/3.9/lib/python/site-packages (from langchain-core) (6.0.2)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /Users/zhangran/Library/Python/3.9/lib/python/site-packages (from langchain-core) (24.1)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /Users/zhangran/Library/Python/3.9/lib/python/site-packages (from langchain-core) (4.12.2)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.5.2 in /Users/zhangran/Library/Python/3.9/lib/python/site-packages (from langchain-core) (2.11.3)\n",
            "Requirement already satisfied: openai<2.0.0,>=1.68.2 in /Users/zhangran/Library/Python/3.9/lib/python/site-packages (from langchain-openai) (1.76.0)\n",
            "Requirement already satisfied: tiktoken<1,>=0.7 in /Users/zhangran/Library/Python/3.9/lib/python/site-packages (from langchain-openai) (0.9.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /Users/zhangran/Library/Python/3.9/lib/python/site-packages (from jsonpatch<2.0,>=1.33->langchain-core) (3.0.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /Users/zhangran/Library/Python/3.9/lib/python/site-packages (from langsmith<0.4,>=0.1.125->langchain-core) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /Users/zhangran/Library/Python/3.9/lib/python/site-packages (from langsmith<0.4,>=0.1.125->langchain-core) (3.10.16)\n",
            "Requirement already satisfied: requests<3,>=2 in /Users/zhangran/Library/Python/3.9/lib/python/site-packages (from langsmith<0.4,>=0.1.125->langchain-core) (2.32.3)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /Users/zhangran/Library/Python/3.9/lib/python/site-packages (from langsmith<0.4,>=0.1.125->langchain-core) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /Users/zhangran/Library/Python/3.9/lib/python/site-packages (from langsmith<0.4,>=0.1.125->langchain-core) (0.23.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /Users/zhangran/Library/Python/3.9/lib/python/site-packages (from openai<2.0.0,>=1.68.2->langchain-openai) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /Users/zhangran/Library/Python/3.9/lib/python/site-packages (from openai<2.0.0,>=1.68.2->langchain-openai) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /Users/zhangran/Library/Python/3.9/lib/python/site-packages (from openai<2.0.0,>=1.68.2->langchain-openai) (0.9.0)\n",
            "Requirement already satisfied: sniffio in /Users/zhangran/Library/Python/3.9/lib/python/site-packages (from openai<2.0.0,>=1.68.2->langchain-openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /Users/zhangran/Library/Python/3.9/lib/python/site-packages (from openai<2.0.0,>=1.68.2->langchain-openai) (4.67.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /Users/zhangran/Library/Python/3.9/lib/python/site-packages (from pydantic<3.0.0,>=2.5.2->langchain-core) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.1 in /Users/zhangran/Library/Python/3.9/lib/python/site-packages (from pydantic<3.0.0,>=2.5.2->langchain-core) (2.33.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /Users/zhangran/Library/Python/3.9/lib/python/site-packages (from pydantic<3.0.0,>=2.5.2->langchain-core) (0.4.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /Users/zhangran/Library/Python/3.9/lib/python/site-packages (from tiktoken<1,>=0.7->langchain-openai) (2024.11.6)\n",
            "Requirement already satisfied: exceptiongroup>=1.0.2 in /Users/zhangran/Library/Python/3.9/lib/python/site-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.68.2->langchain-openai) (1.2.2)\n",
            "Requirement already satisfied: idna>=2.8 in /Users/zhangran/Library/Python/3.9/lib/python/site-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.68.2->langchain-openai) (3.10)\n",
            "Requirement already satisfied: certifi in /Users/zhangran/Library/Python/3.9/lib/python/site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in /Users/zhangran/Library/Python/3.9/lib/python/site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core) (1.0.8)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /Users/zhangran/Library/Python/3.9/lib/python/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core) (0.14.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/zhangran/Library/Python/3.9/lib/python/site-packages (from requests<3,>=2->langsmith<0.4,>=0.1.125->langchain-core) (3.4.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/zhangran/Library/Python/3.9/lib/python/site-packages (from requests<3,>=2->langsmith<0.4,>=0.1.125->langchain-core) (2.2.3)\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49m/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!pip install -U langchain-core langchain-openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install -U langgraph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install langchain-openai langchain-core langgraph"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### TBF-Test 0 for Agent_D: with a fixed knowledge database"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "ename": "SyntaxError",
          "evalue": "unexpected character after line continuation character (1981263389.py, line 77)",
          "output_type": "error",
          "traceback": [
            "\u001b[0;36m  Cell \u001b[0;32mIn[14], line 77\u001b[0;36m\u001b[0m\n\u001b[0;31m    match = re.search(r\\\"\\\\[.*?\\\\]\\\", raw, re.S)\u001b[0m\n\u001b[0m                                               ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unexpected character after line continuation character\n"
          ]
        }
      ],
      "source": [
        "# ---------- imports ----------\n",
        "from langchain_openai import OpenAI\n",
        "from langchain.chains import LLMChain\n",
        "from langchain_core.prompts import PromptTemplate\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.runnables import RunnablePassthrough\n",
        "from langgraph.graph import StateGraph, END\n",
        "\n",
        "import json, re\n",
        "from typing import List, Dict, Any, Optional\n",
        "\n",
        "# ---------- state ----------\n",
        "class DomainDetectorState(dict):\n",
        "    def __init__(\n",
        "        self,\n",
        "        columns: List[str],\n",
        "        column_types: Dict[str, str],\n",
        "        domains_found: List[Dict[str, Any]] = None,\n",
        "        current_domain: Optional[str] = None,\n",
        "        jargon_terms: List[str] = None,\n",
        "        remaining_columns: List[str] = None,\n",
        "        iteration: int = 0,\n",
        "        messages: List[str] = None,\n",
        "    ):\n",
        "        super().__init__(\n",
        "            columns=columns,\n",
        "            column_types=column_types,\n",
        "            domains_found=domains_found or [],\n",
        "            current_domain=current_domain,\n",
        "            jargon_terms=jargon_terms or [],\n",
        "            remaining_columns=remaining_columns or list(columns),\n",
        "            iteration=iteration,\n",
        "            messages=messages or [],\n",
        "        )\n",
        "\n",
        "# ---------- LLM ----------\n",
        "llm = OpenAI(temperature=0)\n",
        "\n",
        "# ---------- think ----------\n",
        "def think(state: DomainDetectorState) -> DomainDetectorState:\n",
        "    if len(state[\"domains_found\"]) >= 5 or not state[\"remaining_columns\"]:\n",
        "        return state\n",
        "\n",
        "    prompt = PromptTemplate.from_template(\n",
        "        \"\"\"\n",
        "        You are a domain expert.\n",
        "        Remaining columns: {remaining_columns}\n",
        "        Column types: {column_types}\n",
        "        Domains already found: {domains_found}\n",
        "        Identify ONE new domain (single word / short phrase).\n",
        "        \"\"\"\n",
        "    )\n",
        "    name = LLMChain(llm=llm, prompt=prompt).run(\n",
        "        remaining_columns=state[\"remaining_columns\"],\n",
        "        column_types=state[\"column_types\"],\n",
        "        domains_found=[d[\"domain\"] for d in state[\"domains_found\"]],\n",
        "    ).strip()\n",
        "\n",
        "    new = state.copy()\n",
        "    new[\"current_domain\"] = name\n",
        "    new[\"messages\"].append(f\"Think → {name}\")\n",
        "    return new\n",
        "\n",
        "# ---------- helper ----------\n",
        "def search_examples(domain: str, n: int = 5) -> List[str]:\n",
        "    raw = (prompt | llm | StrOutputParser()).invoke({\"domain\": domain, \"n\": n})\n",
        "\n",
        "    # ① Strict JSON path\n",
        "    try:\n",
        "        terms = json.loads(raw)\n",
        "        if isinstance(terms, list) and len(terms) >= 3:\n",
        "            return terms[:n]\n",
        "    except Exception:\n",
        "        pass\n",
        "    \n",
        "    match = re.search(r\"\\[(.*?)\\]\", raw_response, re.S)\n",
        "    if match:\n",
        "        rough = re.split(r\"[\\\"',\\[\\]]+\", match.group(1))\n",
        "        cleaned = [t.strip() for t in rough if t.strip()]\n",
        "        if cleaned:\n",
        "            return cleaned[:n_terms]\n",
        "\n",
        "    # 5️⃣  Final generic fallback\n",
        "    return [\"metric\", \"indicator\", \"analysis\", \"benchmark\", \"trend\"][:n_terms]\n",
        "\n",
        "# ---------- act ----------\n",
        "def act(state: DomainDetectorState) -> DomainDetectorState:\n",
        "    if not state[\"current_domain\"]:\n",
        "        new = state.copy(); new[\"iteration\"] += 1; return new\n",
        "\n",
        "    examples = search_examples(state[\"current_domain\"])\n",
        "\n",
        "    prompt = PromptTemplate.from_template(\n",
        "        \"\"\"\n",
        "        Domain: {domain}\n",
        "        Columns: {columns}\n",
        "        Example jargon: {examples}\n",
        "        Produce ≥5 NEW jargon terms (JSON array).\n",
        "        \"\"\"\n",
        "    )\n",
        "    jargon_response = LLMChain(llm=llm, prompt=prompt).run(\n",
        "        domain=state[\"current_domain\"],\n",
        "        columns=state[\"columns\"],\n",
        "        examples=examples,\n",
        "    )\n",
        "    try:\n",
        "        array_txt = re.search(r\\\"\\\\[.*?\\\\]\\\", jargon_response, re.S).group(0)\n",
        "        jargon_terms = json.loads(array_txt)\n",
        "    except Exception:\n",
        "        jargon_terms = []\n",
        "\n",
        "    new = state.copy()\n",
        "    new[\\\"jargon_terms\\\"] = jargon_terms        # <- store the *parsed* list\n",
        "    new[\\\"messages\\\"].append(f\\\"Act → {jargon_terms}\\\")\n",
        "    new[\\\"iteration\\\"] += 1\n",
        "    return new\n",
        "\n",
        "# ---------- reflect ----------\n",
        "def reflect(state: DomainDetectorState) -> DomainDetectorState:\n",
        "    if not state[\"current_domain\"] or not state[\"jargon_terms\"]:\n",
        "        new_state = state.copy()\n",
        "        new_state[\\\"iteration\\\"] += 1\n",
        "        return new_state\n",
        "\n",
        "    cols_lower = {c.lower() for c in state[\"columns\"]}\n",
        "    valid = [t for t in state[\"jargon_terms\"] if t.lower() not in cols_lower]\n",
        "\n",
        "    new = state.copy()\n",
        "    if len(valid) >= 3:\n",
        "        new[\"domains_found\"].append(\n",
        "            {\"domain\": state[\"current_domain\"], \"jargon_terms\": valid[:5]}\n",
        "        )\n",
        "        new[\"messages\"].append(f\"Reflect ✔ {state['current_domain']}\")\n",
        "        if new[\"remaining_columns\"]:\n",
        "            new[\"remaining_columns\"].pop(0)\n",
        "    else:\n",
        "        new[\"messages\"].append(f\"Reflect ✖ {state['current_domain']}\")\n",
        "\n",
        "    new[\"current_domain\"] = None\n",
        "    new[\"jargon_terms\"] = []\n",
        "    new[\"iteration\"] += 1\n",
        "    return new\n",
        "\n",
        "# ---------- stop rule ----------\n",
        "def should_end(state: DomainDetectorState) -> str:\n",
        "    if len(state[\"domains_found\"]) >= 5 or not state[\"remaining_columns\"] or state[\"iteration\"] >= 10:\n",
        "        return \"end\"\n",
        "    return \"continue\"\n",
        "\n",
        "# ---------- graph ----------\n",
        "def build_graph():\n",
        "    g = StateGraph(DomainDetectorState)\n",
        "    g.add_node(\"think\", think)\n",
        "    g.add_node(\"act\", act)\n",
        "    g.add_node(\"reflect\", reflect)\n",
        "    g.add_edge(\"think\", \"act\")\n",
        "    g.add_edge(\"act\", \"reflect\")\n",
        "    g.add_conditional_edges(\"reflect\", should_end, {\"continue\": \"think\", \"end\": END})\n",
        "    g.set_entry_point(\"think\")\n",
        "    return g.compile()\n",
        "\n",
        "# ---------- run ----------\n",
        "def run_domain_detector(columns, column_types=None):\n",
        "    column_types = column_types or {c: \"text\" for c in columns}\n",
        "    state0 = DomainDetectorState(columns=columns, column_types=column_types)\n",
        "    return build_graph().invoke(state0, config={\"recursion_limit\": 50})[\"domains_found\"]\n",
        "\n",
        "# ---- quick test ----\n",
        "if __name__ == \"__main__\":\n",
        "    cols = [\"Quarter\", \"number_Customers\", \"Total_Transactions\", \"Revenue\", \"Profit\"]\n",
        "    print(json.dumps(run_domain_detector(cols), indent=2))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[\n",
            "  {\n",
            "    \"domain\": \"Business Analytics\",\n",
            "    \"jargon_terms\": [\n",
            "      \"KPI\",\n",
            "      \"ROI\",\n",
            "      \"Forecasting\",\n",
            "      \"Segmentation\",\n",
            "      \"Data Mining\"\n",
            "    ]\n",
            "  },\n",
            "  {\n",
            "    \"domain\": \"Business Finance\",\n",
            "    \"jargon_terms\": [\n",
            "      \"ROI\",\n",
            "      \"EBITDA\",\n",
            "      \"Liquidity\",\n",
            "      \"Cash Flow\",\n",
            "      \"Capital Expenditure\"\n",
            "    ]\n",
            "  },\n",
            "  {\n",
            "    \"domain\": \"Business Economics\",\n",
            "    \"jargon_terms\": [\n",
            "      \"demand_curve\",\n",
            "      \"elasticity\",\n",
            "      \"marginal_cost\",\n",
            "      \"opportunity_cost\",\n",
            "      \"market_share\"\n",
            "    ]\n",
            "  },\n",
            "  {\n",
            "    \"domain\": \"Business Accounting\",\n",
            "    \"jargon_terms\": [\n",
            "      \"ledger\",\n",
            "      \"depreciation\",\n",
            "      \"amortization\",\n",
            "      \"accrual\",\n",
            "      \"cash flow\"\n",
            "    ]\n",
            "  },\n",
            "  {\n",
            "    \"domain\": \"Business Management\",\n",
            "    \"jargon_terms\": [\n",
            "      \"KPI\",\n",
            "      \"ROI\",\n",
            "      \"SWOT\",\n",
            "      \"P&L\",\n",
            "      \"Forecast\"\n",
            "    ]\n",
            "  }\n",
            "]\n"
          ]
        }
      ],
      "source": [
        "from langchain_openai import OpenAI\n",
        "from langchain.chains import LLMChain\n",
        "from langchain_core.prompts import PromptTemplate\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "import json\n",
        "import re\n",
        "from typing import List, Dict, Any, Optional\n",
        "from langgraph.graph import StateGraph, END\n",
        "\n",
        "# Define the state schema\n",
        "class DomainDetectorState(dict):\n",
        "    \"\"\"State for the domain detector agent.\"\"\"\n",
        "    def __init__(self, \n",
        "                 columns: List[str],\n",
        "                 column_types: Dict[str, str],\n",
        "                 domains_found: List[Dict[str, Any]] = None,\n",
        "                 current_domain: Optional[str] = None,\n",
        "                 jargon_terms: List[str] = None,\n",
        "                 remaining_columns: List[str] = None,\n",
        "                 iteration: int = 0,\n",
        "                 messages: List[str] = None):\n",
        "        \n",
        "        self.columns = columns\n",
        "        self.column_types = column_types\n",
        "        self.domains_found = domains_found or []\n",
        "        self.current_domain = current_domain\n",
        "        self.jargon_terms = jargon_terms or []\n",
        "        self.remaining_columns = remaining_columns or list(columns)\n",
        "        self.iteration = iteration\n",
        "        self.messages = messages or []\n",
        "        \n",
        "        super().__init__(\n",
        "            columns=self.columns,\n",
        "            column_types=self.column_types,\n",
        "            domains_found=self.domains_found,\n",
        "            current_domain=self.current_domain,\n",
        "            jargon_terms=self.jargon_terms,\n",
        "            remaining_columns=self.remaining_columns,\n",
        "            iteration=self.iteration,\n",
        "            messages=self.messages\n",
        "        )\n",
        "\n",
        "# Initialize LLM\n",
        "llm = OpenAI(temperature=0)\n",
        "\n",
        "# Define the \"Think\" node - Identify a potential domain\n",
        "def think(state: DomainDetectorState) -> DomainDetectorState:\n",
        "    \"\"\"Identify a potential domain based on remaining columns.\"\"\"\n",
        "    \n",
        "    # Skip if we already have 5 domains or no columns remain\n",
        "    if len(state[\"domains_found\"]) >= 5 or not state[\"remaining_columns\"]:\n",
        "        return state\n",
        "    \n",
        "    think_template = \"\"\"\n",
        "    You are a domain expert tasked with identifying knowledge domains from a set of data columns.\n",
        "    \n",
        "    Current columns to analyze: {remaining_columns}\n",
        "    Column types: {column_types}\n",
        "    \n",
        "    Domains already identified: {domains_found}\n",
        "    \n",
        "    Based on the remaining columns, identify ONE new knowledge domain that best represents them.\n",
        "    Consider business, scientific, or technical domains that would use such terminology.\n",
        "    \n",
        "    Return only the domain name as a single word or short phrase.\n",
        "    \"\"\"\n",
        "    \n",
        "    think_prompt = PromptTemplate(\n",
        "        template=think_template,\n",
        "        input_variables=[\"remaining_columns\", \"column_types\", \"domains_found\"]\n",
        "    )\n",
        "    \n",
        "    think_chain = LLMChain(llm=llm, prompt=think_prompt)\n",
        "    \n",
        "    domain = think_chain.run({\n",
        "        \"remaining_columns\": state[\"remaining_columns\"],\n",
        "        \"column_types\": state[\"column_types\"],\n",
        "        \"domains_found\": [d[\"domain\"] for d in state[\"domains_found\"]]\n",
        "    }).strip()\n",
        "    \n",
        "    new_state = state.copy()\n",
        "    new_state[\"current_domain\"] = domain\n",
        "    new_state[\"messages\"].append(f\"Identified potential domain: {domain}\")\n",
        "    \n",
        "    return new_state\n",
        "\n",
        "# Mock function for search_examples\n",
        "def search_examples(domain: str) -> List[str]:\n",
        "    \"\"\"Mock function to simulate fetching jargon hints for a domain.\"\"\"\n",
        "    # In a real implementation, this would call an external API or database\n",
        "    domain_examples = {\n",
        "        \"Finance\": [\"ROI\", \"EBITDA\", \"liquidity\", \"amortization\", \"depreciation\"],\n",
        "        \"Retail\": [\"SKU\", \"inventory turnover\", \"markdown\", \"POS\", \"shrinkage\"],\n",
        "        \"E-commerce\": [\"conversion rate\", \"cart abandonment\", \"AOV\", \"CPC\", \"CTR\"],\n",
        "        \"Sales\": [\"pipeline\", \"lead generation\", \"churn rate\", \"upselling\", \"quota\"],\n",
        "        \"Marketing\": [\"CAC\", \"LTV\", \"engagement rate\", \"attribution\", \"funnel\"],\n",
        "        \"Business Intelligence\": [\"KPI\", \"dashboard\", \"data warehouse\", \"ETL\", \"OLAP\"]\n",
        "    }\n",
        "    \n",
        "    # Default examples for domains not in our mock database\n",
        "    default_examples = [\"metric\", \"indicator\", \"analysis\", \"benchmark\", \"trend\"]\n",
        "    \n",
        "    return domain_examples.get(domain, default_examples)\n",
        "\n",
        "# Define the \"Act\" node - Get jargon terms\n",
        "def act(state: DomainDetectorState) -> DomainDetectorState:\n",
        "    \n",
        "    \"\"\"Generate jargon terms for the current domain.\"\"\"\n",
        "\n",
        "    # Skip only if there is *no* domain to work on\n",
        "    if not state[\"current_domain\"]:\n",
        "        new_state = state.copy()\n",
        "        new_state[\"iteration\"] += 1\n",
        "        return new_state\n",
        "    \n",
        "    # Get example jargon terms\n",
        "    example_terms = search_examples(state[\"current_domain\"])\n",
        "    \n",
        "    act_template = \"\"\"\n",
        "    You are a domain expert in {domain}.\n",
        "    \n",
        "    Your task is to generate at least 5 jargon terms that are commonly used in the {domain} domain \n",
        "    but do NOT appear verbatim in the following column names: {columns}.\n",
        "    \n",
        "    Here are some example jargon terms for this domain: {examples}\n",
        "    \n",
        "    Return a JSON array of strings containing ONLY the jargon terms.\n",
        "    Example: [\"term1\", \"term2\", \"term3\", \"term4\", \"term5\"]\n",
        "    \"\"\"\n",
        "    \n",
        "    act_prompt = PromptTemplate(\n",
        "        template=act_template,\n",
        "        input_variables=[\"domain\", \"columns\", \"examples\"]\n",
        "    )\n",
        "    \n",
        "    act_chain = LLMChain(llm=llm, prompt=act_prompt)\n",
        "    \n",
        "    jargon_response = act_chain.run({\n",
        "        \"domain\": state[\"current_domain\"],\n",
        "        \"columns\": state[\"columns\"],\n",
        "        \"examples\": example_terms\n",
        "    })\n",
        "    \n",
        "    # Extract the JSON array from the response\n",
        "    try:\n",
        "        # Find anything that looks like a JSON array\n",
        "        match = re.search(r'\\[.*\\]', jargon_response, re.DOTALL)\n",
        "        if match:\n",
        "            jargon_terms = json.loads(match.group(0))\n",
        "        else:\n",
        "            jargon_terms = []\n",
        "    except Exception:\n",
        "        jargon_terms = []\n",
        "    \n",
        "    new_state = state.copy()\n",
        "    new_state[\"jargon_terms\"] = jargon_terms\n",
        "    new_state[\"messages\"].append(f\"Generated jargon terms: {jargon_terms}\")\n",
        "    new_state[\"iteration\"] += 1\n",
        "    return new_state\n",
        "\n",
        "# Define the \"Reflect\" node - Validate jargon terms\n",
        "def reflect(state: DomainDetectorState) -> DomainDetectorState:\n",
        "    \"\"\"Validate jargon terms and update domains found.\"\"\"\n",
        "    \n",
        "    if not state[\"current_domain\"] or not state[\"jargon_terms\"]:\n",
        "        return state\n",
        "    \n",
        "    # Convert column names to lowercase for case-insensitive comparison\n",
        "    columns_lower = [col.lower() for col in state[\"columns\"]]\n",
        "    \n",
        "    # Filter out jargon terms that appear in column names\n",
        "    valid_terms = []\n",
        "    for term in state[\"jargon_terms\"]:\n",
        "        if term.lower() not in columns_lower:\n",
        "            valid_terms.append(term)\n",
        "    \n",
        "    # If we have at least 3 valid terms, add the domain to our list\n",
        "    new_state = state.copy()\n",
        "    if len(valid_terms) >= 3:\n",
        "        domain_entry = {\n",
        "            \"domain\": state[\"current_domain\"],\n",
        "            \"jargon_terms\": valid_terms[:5]  # Limit to 5 terms\n",
        "        }\n",
        "        new_state[\"domains_found\"].append(domain_entry)\n",
        "        new_state[\"messages\"].append(f\"Added domain: {state['current_domain']} with terms: {valid_terms[:5]}\")\n",
        "        \n",
        "        # Remove columns that were used for this domain (optional)\n",
        "        # This is a simplified approach - in a real implementation, you might want\n",
        "        # to use the LLM to determine which columns were used for this domain\n",
        "        if len(new_state[\"remaining_columns\"]) > 0:\n",
        "            new_state[\"remaining_columns\"].pop(0)\n",
        "    else:\n",
        "        new_state[\"messages\"].append(f\"Rejected domain: {state['current_domain']} - not enough valid jargon terms\")\n",
        "    \n",
        "    # Reset current domain and jargon terms\n",
        "    new_state[\"current_domain\"] = None\n",
        "    new_state[\"jargon_terms\"] = []\n",
        "    new_state[\"iteration\"] += 1\n",
        "    \n",
        "    return new_state\n",
        "\n",
        "# Define the condition to end the graph\n",
        "def should_end(state: DomainDetectorState) -> str:\n",
        "    \"\"\"Determine if the graph should end.\"\"\"\n",
        "    if len(state[\"domains_found\"]) >= 5:\n",
        "        return \"end\"\n",
        "    if not state[\"remaining_columns\"]:\n",
        "        return \"end\"\n",
        "    if state[\"iteration\"] >= 10:  # Safety limit\n",
        "        return \"end\"\n",
        "    return \"continue\"\n",
        "\n",
        "# Build the graph\n",
        "def build_domain_detector_graph():\n",
        "    \"\"\"Build and return the domain detector graph.\"\"\"\n",
        "    workflow = StateGraph(DomainDetectorState)\n",
        "    \n",
        "    # Add nodes\n",
        "    workflow.add_node(\"think\", think)\n",
        "    workflow.add_node(\"act\", act)\n",
        "    workflow.add_node(\"reflect\", reflect)\n",
        "    \n",
        "    # Add edges\n",
        "    workflow.add_edge(\"think\", \"act\")\n",
        "    workflow.add_edge(\"act\", \"reflect\")\n",
        "    \n",
        "    # Add conditional edge\n",
        "    workflow.add_conditional_edges(\n",
        "        \"reflect\",\n",
        "        should_end,\n",
        "        {\n",
        "            \"continue\": \"think\",\n",
        "            \"end\": END\n",
        "        }\n",
        "    )\n",
        "    \n",
        "    # Set the entry point\n",
        "    workflow.set_entry_point(\"think\")\n",
        "    \n",
        "    return workflow.compile()\n",
        "\n",
        "# Function to run the domain detector\n",
        "def run_domain_detector(columns, column_types=None):\n",
        "    \"\"\"\n",
        "    Run the domain detector on the given columns.\n",
        "    \n",
        "    Args:\n",
        "        columns (list): List of column names\n",
        "        column_types (dict, optional): Dictionary mapping column names to their data types\n",
        "    \n",
        "    Returns:\n",
        "        list: List of domains with their jargon terms\n",
        "    \"\"\"\n",
        "    if column_types is None:\n",
        "        column_types = {col: \"text\" for col in columns}\n",
        "    \n",
        "    # Initialize the state\n",
        "    initial_state = DomainDetectorState(\n",
        "        columns=columns,\n",
        "        column_types=column_types\n",
        "    )\n",
        "    \n",
        "    # Build and run the graph\n",
        "    graph = build_domain_detector_graph()\n",
        "    final_state = graph.invoke(initial_state)\n",
        "    \n",
        "    return final_state[\"domains_found\"]\n",
        "\n",
        "# Example usage\n",
        "if __name__ == \"__main__\":\n",
        "    columns = [\"Quarter\", \"number_Customers\", \"Total_Transactions\", \"Revenue\", \"Profit\"]\n",
        "    column_types = {\n",
        "        \"Quarter\": \"object\",\n",
        "        \"number_Customers\": \"int\",\n",
        "        \"Total_Transactions\": \"float\",\n",
        "        \"Revenue\": \"float\",\n",
        "        \"Profit\": \"float\"\n",
        "    }\n",
        "    \n",
        "    domains = run_domain_detector(columns, column_types)\n",
        "    print(json.dumps(domains, indent=2))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### - Visualization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "git: 'filter-repo' is not a git command. See 'git --help'.\n",
            "Enumerating objects: 19, done.\n",
            "Counting objects: 100% (19/19), done.\n",
            "Delta compression using up to 8 threads\n",
            "Compressing objects: 100% (14/14), done.\n",
            "Writing objects: 100% (16/16), 14.48 KiB | 7.24 MiB/s, done.\n",
            "Total 16 (delta 5), reused 0 (delta 0), pack-reused 0\n",
            "remote: Resolving deltas: 100% (5/5), completed with 1 local object.\u001b[K\n",
            "remote: \u001b[1;31merror\u001b[m: GH013: Repository rule violations found for refs/heads/main.\u001b[K\n",
            "remote: \n",
            "remote: - GITHUB PUSH PROTECTION\u001b[K\n",
            "remote:   —————————————————————————————————————————\u001b[K\n",
            "remote:     Resolve the following violations before pushing again\u001b[K\n",
            "remote: \n",
            "remote:     - Push cannot contain secrets\u001b[K\n",
            "remote: \n",
            "remote:     \u001b[K\n",
            "remote:      (?) Learn how to resolve a blocked push\u001b[K\n",
            "remote:      https://docs.github.com/code-security/secret-scanning/working-with-secret-scanning-and-push-protection/working-with-push-protection-from-the-command-line#resolving-a-blocked-push\u001b[K\n",
            "remote:     \u001b[K\n",
            "remote:     \u001b[K\n",
            "remote:       —— OpenAI API Key ————————————————————————————————————\u001b[K\n",
            "remote:        locations:\u001b[K\n",
            "remote:          - commit: 233c8bbf62758132e46ef01f8bc8ffbee5ed2acf\u001b[K\n",
            "remote:            path: .env:1\u001b[K\n",
            "remote:     \u001b[K\n",
            "remote:        (?) To push, remove secret from commit(s) or follow this URL to allow the secret.\u001b[K\n",
            "remote:        https://github.com/77luvC/D2D_Data2Dashboard/security/secret-scanning/unblock-secret/2wPsUzOm5Or3WaUS97MUN2fU3OC\u001b[K\n",
            "remote:     \u001b[K\n",
            "remote: \n",
            "remote: \n",
            "To https://github.com/77luvC/D2D_Data2Dashboard.git\n",
            " \u001b[31m! [remote rejected]\u001b[m main -> main (push declined due to repository rule violations)\n",
            "\u001b[31merror: failed to push some refs to 'https://github.com/77luvC/D2D_Data2Dashboard.git'\n",
            "\u001b[m"
          ]
        }
      ],
      "source": [
        "!git filter-repo --path .env --invert-paths\n",
        "!git push origin main --force\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "zsh:1: command not found: brew\n"
          ]
        }
      ],
      "source": [
        "!brew install git-filter-repo\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Collecting git-filter-repo\n",
            "  Downloading git_filter_repo-2.47.0-py3-none-any.whl.metadata (31 kB)\n",
            "Downloading git_filter_repo-2.47.0-py3-none-any.whl (76 kB)\n",
            "Installing collected packages: git-filter-repo\n",
            "Successfully installed git-filter-repo-2.47.0\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49m/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!pip install git-filter-repo  # May not work on all setups\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Aborting: Refusing to destructively overwrite repo history since\n",
            "this does not look like a fresh clone.\n",
            "  (expected freshly packed repo)\n",
            "Please operate on a fresh clone instead.  If you want to proceed\n",
            "anyway, use --force.\n"
          ]
        }
      ],
      "source": [
        "!git filter-repo --path .env --invert-paths\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enumerating objects: 19, done.\n",
            "Counting objects: 100% (19/19), done.\n",
            "Delta compression using up to 8 threads\n",
            "Compressing objects: 100% (14/14), done.\n",
            "Writing objects: 100% (16/16), 14.48 KiB | 7.24 MiB/s, done.\n",
            "Total 16 (delta 5), reused 0 (delta 0), pack-reused 0\n",
            "remote: Resolving deltas: 100% (5/5), completed with 1 local object.\u001b[K\n",
            "remote: \u001b[1;31merror\u001b[m: GH013: Repository rule violations found for refs/heads/main.\u001b[K\n",
            "remote: \n",
            "remote: - GITHUB PUSH PROTECTION\u001b[K\n",
            "remote:   —————————————————————————————————————————\u001b[K\n",
            "remote:     Resolve the following violations before pushing again\u001b[K\n",
            "remote: \n",
            "remote:     - Push cannot contain secrets\u001b[K\n",
            "remote: \n",
            "remote:     \u001b[K\n",
            "remote:      (?) Learn how to resolve a blocked push\u001b[K\n",
            "remote:      https://docs.github.com/code-security/secret-scanning/working-with-secret-scanning-and-push-protection/working-with-push-protection-from-the-command-line#resolving-a-blocked-push\u001b[K\n",
            "remote:     \u001b[K\n",
            "remote:     \u001b[K\n",
            "remote:       —— OpenAI API Key ————————————————————————————————————\u001b[K\n",
            "remote:        locations:\u001b[K\n",
            "remote:          - commit: 233c8bbf62758132e46ef01f8bc8ffbee5ed2acf\u001b[K\n",
            "remote:            path: .env:1\u001b[K\n",
            "remote:     \u001b[K\n",
            "remote:        (?) To push, remove secret from commit(s) or follow this URL to allow the secret.\u001b[K\n",
            "remote:        https://github.com/77luvC/D2D_Data2Dashboard/security/secret-scanning/unblock-secret/2wPsUzOm5Or3WaUS97MUN2fU3OC\u001b[K\n",
            "remote:     \u001b[K\n",
            "remote: \n",
            "remote: \n",
            "To https://github.com/77luvC/D2D_Data2Dashboard.git\n",
            " \u001b[31m! [remote rejected]\u001b[m main -> main (push declined due to repository rule violations)\n",
            "\u001b[31merror: failed to push some refs to 'https://github.com/77luvC/D2D_Data2Dashboard.git'\n",
            "\u001b[m"
          ]
        }
      ],
      "source": [
        "!git push origin main --force\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "NOTICE: Removing 'origin' remote; see 'Why is my origin removed?'\n",
            "        in the manual if you want to push back there.\n",
            "        (was https://github.com/77luvC/D2D_Data2Dashboard.git)\n",
            "Parsed 10 commits\n",
            "New history written in 0.06 seconds; now repacking/cleaning...\n",
            "Repacking your repo and cleaning out old unneeded objects\n",
            "HEAD is now at 22fed46 agentize domain detector\n",
            "Enumerating objects: 32, done.\n",
            "Counting objects: 100% (32/32), done.\n",
            "Delta compression using up to 8 threads\n",
            "Compressing objects: 100% (29/29), done.\n",
            "Writing objects: 100% (32/32), done.\n",
            "Total 32 (delta 10), reused 1 (delta 0), pack-reused 0\n",
            "Completely finished after 0.14 seconds.\n"
          ]
        }
      ],
      "source": [
        "!git filter-repo --path .env --invert-paths --force\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "fatal: 'origin' does not appear to be a git repository\n",
            "fatal: Could not read from remote repository.\n",
            "\n",
            "Please make sure you have the correct access rights\n",
            "and the repository exists.\n"
          ]
        }
      ],
      "source": [
        "!git push origin main --force\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {},
      "outputs": [],
      "source": [
        "!git remote add origin https://github.com/77luvC/D2D_Data2Dashboard.git\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enumerating objects: 32, done.\n",
            "Counting objects: 100% (32/32), done.\n",
            "Delta compression using up to 8 threads\n",
            "Compressing objects: 100% (19/19), done.\n",
            "Writing objects: 100% (32/32), 39.08 KiB | 39.08 MiB/s, done.\n",
            "Total 32 (delta 10), reused 32 (delta 10), pack-reused 0\n",
            "remote: Resolving deltas: 100% (10/10), done.\u001b[K\n",
            "To https://github.com/77luvC/D2D_Data2Dashboard.git\n",
            " + e96d856...22fed46 main -> main (forced update)\n"
          ]
        }
      ],
      "source": [
        "!git push origin main --force\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Test 1 for Agent_D: Dynamic LLM-powered jargon fetcher"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[\n",
            "  {\n",
            "    \"domain\": \"Business Analytics\",\n",
            "    \"jargon_terms\": [\n",
            "      \"Data Mining\",\n",
            "      \"Predictive Modeling\",\n",
            "      \"Data Visualization\",\n",
            "      \"Descriptive Analytics\",\n",
            "      \"Prescriptive Analytics\"\n",
            "    ]\n",
            "  },\n",
            "  {\n",
            "    \"domain\": \"Business Finance\",\n",
            "    \"jargon_terms\": [\n",
            "      \"EBITDA\",\n",
            "      \"ROI\",\n",
            "      \"DCF\",\n",
            "      \"IRR\",\n",
            "      \"NPV\"\n",
            "    ]\n",
            "  },\n",
            "  {\n",
            "    \"domain\": \"Business Economics\",\n",
            "    \"jargon_terms\": [\n",
            "      \"Demand Curve\",\n",
            "      \"Opportunity Cost\",\n",
            "      \"Elasticity\",\n",
            "      \"Monopoly\",\n",
            "      \"Oligopoly\"\n",
            "    ]\n",
            "  },\n",
            "  {\n",
            "    \"domain\": \"Business Accounting\",\n",
            "    \"jargon_terms\": [\n",
            "      \"Balance Sheet\",\n",
            "      \"Cash Flow Statement\",\n",
            "      \"Accrual Basis\",\n",
            "      \"Depreciation\",\n",
            "      \"Inventory Valuation\"\n",
            "    ]\n",
            "  },\n",
            "  {\n",
            "    \"domain\": \"Business Management\",\n",
            "    \"jargon_terms\": [\n",
            "      \"KPI\",\n",
            "      \"ROI\",\n",
            "      \"SWOT\",\n",
            "      \"B2B\",\n",
            "      \"B2C\"\n",
            "    ]\n",
            "  }\n",
            "]\n"
          ]
        }
      ],
      "source": [
        "from langchain_openai import OpenAI\n",
        "from langchain.chains import LLMChain\n",
        "from langchain_core.prompts import PromptTemplate\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "import json\n",
        "import re\n",
        "from typing import List, Dict, Any, Optional\n",
        "from langgraph.graph import StateGraph, END\n",
        "\n",
        "# Define the state schema\n",
        "class DomainDetectorState(dict):\n",
        "    \"\"\"State for the domain detector agent.\"\"\"\n",
        "    def __init__(self, \n",
        "                 columns: List[str],\n",
        "                 column_types: Dict[str, str],\n",
        "                 domains_found: List[Dict[str, Any]] = None,\n",
        "                 current_domain: Optional[str] = None,\n",
        "                 jargon_terms: List[str] = None,\n",
        "                 remaining_columns: List[str] = None,\n",
        "                 iteration: int = 0,\n",
        "                 messages: List[str] = None):\n",
        "        \n",
        "        self.columns = columns\n",
        "        self.column_types = column_types\n",
        "        self.domains_found = domains_found or []\n",
        "        self.current_domain = current_domain\n",
        "        self.jargon_terms = jargon_terms or []\n",
        "        self.remaining_columns = remaining_columns or list(columns)\n",
        "        self.iteration = iteration\n",
        "        self.messages = messages or []\n",
        "        \n",
        "        super().__init__(\n",
        "            columns=self.columns,\n",
        "            column_types=self.column_types,\n",
        "            domains_found=self.domains_found,\n",
        "            current_domain=self.current_domain,\n",
        "            jargon_terms=self.jargon_terms,\n",
        "            remaining_columns=self.remaining_columns,\n",
        "            iteration=self.iteration,\n",
        "            messages=self.messages\n",
        "        )\n",
        "\n",
        "# Initialize LLM\n",
        "llm = OpenAI(temperature=0)\n",
        "\n",
        "# Define the \"Think\" node - Identify a potential domain\n",
        "def think(state: DomainDetectorState) -> DomainDetectorState:\n",
        "    \"\"\"Identify a potential domain based on remaining columns.\"\"\"\n",
        "    \n",
        "    # Skip if we already have 5 domains or no columns remain\n",
        "    if len(state[\"domains_found\"]) >= 5 or not state[\"remaining_columns\"]:\n",
        "        return state\n",
        "    \n",
        "    think_template = \"\"\"\n",
        "    You are a domain expert tasked with identifying knowledge domains from a set of data columns.\n",
        "    \n",
        "    Current columns to analyze: {remaining_columns}\n",
        "    Column types: {column_types}\n",
        "    \n",
        "    Domains already identified: {domains_found}\n",
        "    \n",
        "    Based on the remaining columns, identify ONE new knowledge domain that best represents them.\n",
        "    Consider business, scientific, or technical domains that would use such terminology.\n",
        "    \n",
        "    Return only the domain name as a single word or short phrase.\n",
        "    \"\"\"\n",
        "    \n",
        "    think_prompt = PromptTemplate(\n",
        "        template=think_template,\n",
        "        input_variables=[\"remaining_columns\", \"column_types\", \"domains_found\"]\n",
        "    )\n",
        "    \n",
        "    think_chain = LLMChain(llm=llm, prompt=think_prompt)\n",
        "    \n",
        "    domain = think_chain.run({\n",
        "        \"remaining_columns\": state[\"remaining_columns\"],\n",
        "        \"column_types\": state[\"column_types\"],\n",
        "        \"domains_found\": [d[\"domain\"] for d in state[\"domains_found\"]]\n",
        "    }).strip()\n",
        "    \n",
        "    new_state = state.copy()\n",
        "    new_state[\"current_domain\"] = domain\n",
        "    new_state[\"messages\"].append(f\"Identified potential domain: {domain}\")\n",
        "    \n",
        "    return new_state\n",
        "\n",
        "# -------------------------------------------------------------------\n",
        "# Dynamic LLM-powered jargon fetcher\n",
        "# -------------------------------------------------------------------\n",
        "def search_examples(domain: str, n_terms: int = 5, llm_model=llm) -> List[str]:\n",
        "    \"\"\"\n",
        "    Query the LLM for ~n_terms canonical jargon / acronyms that typify `domain`.\n",
        "    Falls back to a small generic list if the model response is unusable.\n",
        "    \"\"\"\n",
        "\n",
        "    # 1️⃣  Compose the prompt\n",
        "    prompt = PromptTemplate.from_template(\n",
        "        \"\"\"\n",
        "        You are a senior specialist in {domain}.\n",
        "        List {n} widely-used jargon terms or acronyms **unique** to this field.\n",
        "        Return ONLY a valid JSON array of quoted strings, nothing else.\n",
        "        Example → [\"term1\",\"term2\",...]\n",
        "        \"\"\"\n",
        "    )\n",
        "\n",
        "    # 2️⃣  Run the model\n",
        "    raw_response: str = (\n",
        "        prompt\n",
        "        | llm_model\n",
        "        | StrOutputParser()         # gives us the raw string\n",
        "    ).invoke({\"domain\": domain, \"n\": n_terms})\n",
        "\n",
        "    # 3️⃣  Try strict JSON parsing first\n",
        "    try:\n",
        "        terms = json.loads(raw_response)\n",
        "        if isinstance(terms, list) and len(terms) >= 3:\n",
        "            return terms[:n_terms]\n",
        "    except Exception:\n",
        "        pass\n",
        "\n",
        "    # 4️⃣  Regex rescue for “almost JSON”\n",
        "    match = re.search(r\"\\[(.*?)\\]\", raw_response, re.S)\n",
        "    if match:\n",
        "        rough = re.split(r\"[\\\"',\\[\\]]+\", match.group(1))\n",
        "        cleaned = [t.strip() for t in rough if t.strip()]\n",
        "        if cleaned:\n",
        "            return cleaned[:n_terms]\n",
        "\n",
        "    # 5️⃣  Final generic fallback\n",
        "    return [\"metric\", \"indicator\", \"analysis\", \"benchmark\", \"trend\"][:n_terms]\n",
        "\n",
        "\n",
        "# Define the \"Act\" node - Get jargon terms\n",
        "def act(state: DomainDetectorState) -> DomainDetectorState:\n",
        "    \n",
        "    \"\"\"Generate jargon terms for the current domain.\"\"\"\n",
        "\n",
        "    # Skip only if there is *no* domain to work on\n",
        "    if not state[\"current_domain\"]:\n",
        "        new_state = state.copy()\n",
        "        new_state[\"iteration\"] += 1\n",
        "        return new_state\n",
        "    \n",
        "    # Get example jargon terms\n",
        "    example_terms = search_examples(state[\"current_domain\"])\n",
        "    \n",
        "    act_template = \"\"\"\n",
        "    You are a domain expert in {domain}.\n",
        "    \n",
        "    Your task is to generate at least 5 jargon terms that are commonly used in the {domain} domain \n",
        "    but do NOT appear verbatim in the following column names: {columns}.\n",
        "    \n",
        "    Here are some example jargon terms for this domain: {examples}\n",
        "    \n",
        "    Return a JSON array of strings containing ONLY the jargon terms.\n",
        "    Example: [\"term1\", \"term2\", \"term3\", \"term4\", \"term5\"]\n",
        "    \"\"\"\n",
        "    \n",
        "    act_prompt = PromptTemplate(\n",
        "        template=act_template,\n",
        "        input_variables=[\"domain\", \"columns\", \"examples\"]\n",
        "    )\n",
        "    \n",
        "    act_chain = LLMChain(llm=llm, prompt=act_prompt)\n",
        "    \n",
        "    jargon_response = act_chain.run({\n",
        "        \"domain\": state[\"current_domain\"],\n",
        "        \"columns\": state[\"columns\"],\n",
        "        \"examples\": example_terms\n",
        "    })\n",
        "    \n",
        "    # Extract the JSON array from the response\n",
        "    try:\n",
        "        # Find anything that looks like a JSON array\n",
        "        match = re.search(r'\\[.*\\]', jargon_response, re.DOTALL)\n",
        "        if match:\n",
        "            jargon_terms = json.loads(match.group(0))\n",
        "        else:\n",
        "            jargon_terms = []\n",
        "    except Exception:\n",
        "        jargon_terms = []\n",
        "    \n",
        "    new_state = state.copy()\n",
        "    new_state[\"jargon_terms\"] = jargon_terms\n",
        "    new_state[\"messages\"].append(f\"Generated jargon terms: {jargon_terms}\")\n",
        "    new_state[\"iteration\"] += 1\n",
        "    return new_state\n",
        "\n",
        "# Define the \"Reflect\" node - Validate jargon terms\n",
        "def reflect(state: DomainDetectorState) -> DomainDetectorState:\n",
        "    \"\"\"Validate jargon terms and update domains found.\"\"\"\n",
        "    \n",
        "    if not state[\"current_domain\"] or not state[\"jargon_terms\"]:\n",
        "        return state\n",
        "    \n",
        "    # Convert column names to lowercase for case-insensitive comparison\n",
        "    columns_lower = [col.lower() for col in state[\"columns\"]]\n",
        "    \n",
        "    # Filter out jargon terms that appear in column names\n",
        "    valid_terms = []\n",
        "    for term in state[\"jargon_terms\"]:\n",
        "        if term.lower() not in columns_lower:\n",
        "            valid_terms.append(term)\n",
        "    \n",
        "    # If we have at least 3 valid terms, add the domain to our list\n",
        "    new_state = state.copy()\n",
        "    if len(valid_terms) >= 3:\n",
        "        domain_entry = {\n",
        "            \"domain\": state[\"current_domain\"],\n",
        "            \"jargon_terms\": valid_terms[:5]  # Limit to 5 terms\n",
        "        }\n",
        "        new_state[\"domains_found\"].append(domain_entry)\n",
        "        new_state[\"messages\"].append(f\"Added domain: {state['current_domain']} with terms: {valid_terms[:5]}\")\n",
        "        \n",
        "        # Remove columns that were used for this domain (optional)\n",
        "        # This is a simplified approach - in a real implementation, you might want\n",
        "        # to use the LLM to determine which columns were used for this domain\n",
        "        if len(new_state[\"remaining_columns\"]) > 0:\n",
        "            new_state[\"remaining_columns\"].pop(0)\n",
        "    else:\n",
        "        new_state[\"messages\"].append(f\"Rejected domain: {state['current_domain']} - not enough valid jargon terms\")\n",
        "    \n",
        "    # Reset current domain and jargon terms\n",
        "    new_state[\"current_domain\"] = None\n",
        "    new_state[\"jargon_terms\"] = []\n",
        "    new_state[\"iteration\"] += 1\n",
        "    \n",
        "    return new_state\n",
        "\n",
        "# Define the condition to end the graph\n",
        "def should_end(state: DomainDetectorState) -> str:\n",
        "    \"\"\"Determine if the graph should end.\"\"\"\n",
        "    if len(state[\"domains_found\"]) >= 5:\n",
        "        return \"end\"\n",
        "    if not state[\"remaining_columns\"]:\n",
        "        return \"end\"\n",
        "    if state[\"iteration\"] >= 10:  # Safety limit\n",
        "        return \"end\"\n",
        "    return \"continue\"\n",
        "\n",
        "# Build the graph\n",
        "def build_domain_detector_graph():\n",
        "    \"\"\"Build and return the domain detector graph.\"\"\"\n",
        "    workflow = StateGraph(DomainDetectorState)\n",
        "    \n",
        "    # Add nodes\n",
        "    workflow.add_node(\"think\", think)\n",
        "    workflow.add_node(\"act\", act)\n",
        "    workflow.add_node(\"reflect\", reflect)\n",
        "    \n",
        "    # Add edges\n",
        "    workflow.add_edge(\"think\", \"act\")\n",
        "    workflow.add_edge(\"act\", \"reflect\")\n",
        "    \n",
        "    # Add conditional edge\n",
        "    workflow.add_conditional_edges(\n",
        "        \"reflect\",\n",
        "        should_end,\n",
        "        {\n",
        "            \"continue\": \"think\",\n",
        "            \"end\": END\n",
        "        }\n",
        "    )\n",
        "    \n",
        "    # Set the entry point\n",
        "    workflow.set_entry_point(\"think\")\n",
        "    \n",
        "    return workflow.compile()\n",
        "\n",
        "# Function to run the domain detector\n",
        "def run_domain_detector_test1(columns, column_types=None):\n",
        "    \"\"\"\n",
        "    Run the domain detector on the given columns.\n",
        "    \n",
        "    Args:\n",
        "        columns (list): List of column names\n",
        "        column_types (dict, optional): Dictionary mapping column names to their data types\n",
        "    \n",
        "    Returns:\n",
        "        list: List of domains with their jargon terms\n",
        "    \"\"\"\n",
        "    if column_types is None:\n",
        "        column_types = {col: \"text\" for col in columns}\n",
        "    \n",
        "    # Initialize the state\n",
        "    initial_state = DomainDetectorState(\n",
        "        columns=columns,\n",
        "        column_types=column_types\n",
        "    )\n",
        "    \n",
        "    # Build and run the graph\n",
        "    graph = build_domain_detector_graph()\n",
        "    final_state = graph.invoke(initial_state)\n",
        "    \n",
        "    return final_state[\"domains_found\"]\n",
        "\n",
        "# Example usage\n",
        "if __name__ == \"__main__\":\n",
        "    columns = [\"Quarter\", \"number_Customers\", \"Total_Transactions\", \"Revenue\", \"Profit\"]\n",
        "    column_types = {\n",
        "        \"Quarter\": \"object\",\n",
        "        \"number_Customers\": \"int\",\n",
        "        \"Total_Transactions\": \"float\",\n",
        "        \"Revenue\": \"float\",\n",
        "        \"Profit\": \"float\"\n",
        "    }\n",
        "    \n",
        "    domains = run_domain_detector_test1(columns, column_types)\n",
        "    print(json.dumps(domains, indent=2))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 1. Cleaned Domain-Concept Pairs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[{'domain': 'Business Analytics',\n",
            "  'jargon_terms': 'Data Mining'},\n",
            " {'domain': 'Business Analytics',\n",
            "  'jargon_terms': 'Predictive Modeling'},\n",
            " {'domain': 'Business Analytics',\n",
            "  'jargon_terms': 'Data Visualization'},\n",
            " {'domain': 'Business Analytics',\n",
            "  'jargon_terms': 'Descriptive Analytics'},\n",
            " {'domain': 'Business Analytics',\n",
            "  'jargon_terms': 'Prescriptive Analytics'},\n",
            " {'domain': 'Business Finance', 'jargon_terms': 'EBITDA'},\n",
            " {'domain': 'Business Finance', 'jargon_terms': 'ROI'},\n",
            " {'domain': 'Business Finance', 'jargon_terms': 'DCF'},\n",
            " {'domain': 'Business Finance', 'jargon_terms': 'IRR'},\n",
            " {'domain': 'Business Finance', 'jargon_terms': 'NPV'},\n",
            " {'domain': 'Business Economics',\n",
            "  'jargon_terms': 'Demand Curve'},\n",
            " {'domain': 'Business Economics',\n",
            "  'jargon_terms': 'Opportunity Cost'},\n",
            " {'domain': 'Business Economics',\n",
            "  'jargon_terms': 'Elasticity'},\n",
            " {'domain': 'Business Economics',\n",
            "  'jargon_terms': 'Monopoly'},\n",
            " {'domain': 'Business Economics',\n",
            "  'jargon_terms': 'Oligopoly'},\n",
            " {'domain': 'Business Accounting',\n",
            "  'jargon_terms': 'Balance Sheet'},\n",
            " {'domain': 'Business Accounting',\n",
            "  'jargon_terms': 'Cash Flow Statement'},\n",
            " {'domain': 'Business Accounting',\n",
            "  'jargon_terms': 'Accrual Basis'},\n",
            " {'domain': 'Business Accounting',\n",
            "  'jargon_terms': 'Depreciation'},\n",
            " {'domain': 'Business Accounting',\n",
            "  'jargon_terms': 'Inventory Valuation'},\n",
            " {'domain': 'Business Management', 'jargon_terms': 'KPI'},\n",
            " {'domain': 'Business Management', 'jargon_terms': 'SWOT'},\n",
            " {'domain': 'Business Management', 'jargon_terms': 'B2B'},\n",
            " {'domain': 'Business Management', 'jargon_terms': 'B2C'}]\n"
          ]
        }
      ],
      "source": [
        "from collections import Counter\n",
        "\n",
        "# keep the first occurrence of any jargon term;\n",
        "# drop later duplicates that show up in other domains.\n",
        "\n",
        "def get_first_unique_pairs(domains_found):\n",
        "    \"\"\"\n",
        "    Keep the first‑seen (domain, jargon) pair for every jargon_term.\n",
        "    Later occurrences of the same jargon_term in other domains are skipped.\n",
        "    \"\"\"\n",
        "    seen = set()\n",
        "    unique_pairs = []\n",
        "\n",
        "    for entry in domains_found:          # keep original order\n",
        "        dom = entry[\"domain\"]\n",
        "        for term in entry[\"jargon_terms\"]:\n",
        "            if term not in seen:         # only accept the first time we see it\n",
        "                unique_pairs.append({\"domain\": dom, \"jargon_terms\": term})\n",
        "                seen.add(term)\n",
        "\n",
        "    return unique_pairs\n",
        "\n",
        "cleaned = get_first_unique_pairs(domains)\n",
        "import json, pprint; pprint.pp(cleaned, width=60)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2. Filter by yes/no"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ------------ 1. imports & chat object ------------\n",
        "from langchain_openai import ChatOpenAI\n",
        "from typing import List, Dict, Union\n",
        "\n",
        "# feel free to tweak these\n",
        "MODEL_NAME   = \"gpt-4o\"   # or \"gpt-4o\", \"gpt-3.5-turbo\"\n",
        "TEMPERATURE  = 0\n",
        "MAX_TOKENS   = 3               # we only need YES / NO\n",
        "API_KEY_ENV  = \"OPENAI_API_KEY\"\n",
        "\n",
        "# singleton chat object (re‑used for every call)\n",
        "chat = ChatOpenAI(\n",
        "    model_name   = MODEL_NAME,\n",
        "    temperature  = TEMPERATURE,\n",
        "    max_tokens   = MAX_TOKENS,\n",
        "    openai_api_key = None,     # uses env var by default\n",
        ")\n",
        "\n",
        "\n",
        "# ------------ 2. prompt builder ------------\n",
        "def _build_prompt(jargon: str,\n",
        "                  domain: str,\n",
        "                  columns: List[str],\n",
        "                  column_types: Dict[str, str]) -> str:\n",
        "    \"\"\"\n",
        "    Few‑shot prompt.  The model must output TWO flags separated by a comma:\n",
        "      * first flag  – YES/NO: term is relevant to the data columns\n",
        "      * second flag – YES/NO: term generally has a well‑defined numeric formula\n",
        "    \"\"\"\n",
        "    few_shots = \"\"\"\n",
        "### Example 1\n",
        "Data columns: [\"Date\", \"Open\", \"High\", \"Low\", \"Close\"]\n",
        "Column types: {\"Date\":\"object\",\"Open\":\"float\",\"High\":\"float\",\"Low\":\"float\",\"Close\":\"float\"}\n",
        "Jargon term: \"EBITDA\"\n",
        "Answer: YES, YES\n",
        "\n",
        "### Example 2\n",
        "Data columns: [\"Epoch\", \"Loss\", \"Accuracy\"]\n",
        "Column types: {\"Epoch\":\"int\",\"Loss\":\"float\",\"Accuracy\":\"float\"}\n",
        "Jargon term: \"Predictive Modeling\"\n",
        "Answer: NO, NO\n",
        "\n",
        "### Example 3\n",
        "Data columns: [\"Customer_ID\", \"Invoice_Amount\", \"Payment_Date\"]\n",
        "Column types: {\"Customer_ID\":\"int\",\"Invoice_Amount\":\"float\",\"Payment_Date\":\"object\"}\n",
        "Jargon term: \"ROI\"\n",
        "Answer: YES, YES\n",
        "\"\"\".strip()\n",
        "\n",
        "    task = f\"\"\"\n",
        "### Task\n",
        "Data columns: {json.dumps(columns)}\n",
        "Column types: {json.dumps(column_types)}\n",
        "Jargon term: \"{jargon}\"\n",
        "Answer (format YES/NO,YES/NO — no extra text):\"\"\".rstrip()\n",
        "\n",
        "    return f\"{few_shots}\\n{task}\"\n",
        "\n",
        "\n",
        "# ------------ 3. evaluator ------------\n",
        "def lc_relevance(pairs: List[Dict[str, str]],\n",
        "                 columns: List[str],\n",
        "                 column_types: Dict[str, str]\n",
        "                ) -> List[Dict[str, Union[str, bool]]]:\n",
        "    \"\"\"\n",
        "    Returns a list with two Boolean flags for each jargon term:\n",
        "      - relevant    : related to the dataframe columns\n",
        "      - has_formula : likely has a numeric / algebraic formula\n",
        "    \"\"\"\n",
        "    results = []\n",
        "    for p in pairs:\n",
        "        term   = p.get(\"jargon_terms\") or p.get(\"concept\")\n",
        "        domain = p[\"domain\"]\n",
        "\n",
        "        prompt = _build_prompt(term, domain, columns, column_types)\n",
        "        reply  = chat.invoke(prompt).content.strip().upper()\n",
        "\n",
        "        # Accept variants such as \"YES , NO\"\n",
        "        parts = [x.strip() for x in reply.split(\",\")]\n",
        "        rel_flag   = parts[0].startswith(\"Y\") if parts else False\n",
        "        formula_fl = parts[1].startswith(\"Y\") if len(parts) > 1 else False\n",
        "\n",
        "        results.append({\n",
        "            \"domain\"      : domain,\n",
        "            \"jargon_term\" : term,\n",
        "            \"relevant\"    : rel_flag,\n",
        "            \"has_formula\" : formula_fl,\n",
        "        })\n",
        "    return results\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>domain</th>\n",
              "      <th>jargon_term</th>\n",
              "      <th>relevant</th>\n",
              "      <th>has_formula</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Business Analytics</td>\n",
              "      <td>Data Mining</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Business Analytics</td>\n",
              "      <td>Predictive Modeling</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Business Analytics</td>\n",
              "      <td>Data Visualization</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Business Analytics</td>\n",
              "      <td>Descriptive Analytics</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Business Analytics</td>\n",
              "      <td>Prescriptive Analytics</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Business Finance</td>\n",
              "      <td>EBITDA</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Business Finance</td>\n",
              "      <td>ROI</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Business Finance</td>\n",
              "      <td>DCF</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Business Finance</td>\n",
              "      <td>IRR</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Business Finance</td>\n",
              "      <td>NPV</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>Business Economics</td>\n",
              "      <td>Demand Curve</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>Business Economics</td>\n",
              "      <td>Opportunity Cost</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>Business Economics</td>\n",
              "      <td>Elasticity</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>Business Economics</td>\n",
              "      <td>Monopoly</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>Business Economics</td>\n",
              "      <td>Oligopoly</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>Business Accounting</td>\n",
              "      <td>Balance Sheet</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>Business Accounting</td>\n",
              "      <td>Cash Flow Statement</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>Business Accounting</td>\n",
              "      <td>Accrual Basis</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>Business Accounting</td>\n",
              "      <td>Depreciation</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>Business Accounting</td>\n",
              "      <td>Inventory Valuation</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>Business Management</td>\n",
              "      <td>KPI</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>Business Management</td>\n",
              "      <td>SWOT</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>Business Management</td>\n",
              "      <td>B2B</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>Business Management</td>\n",
              "      <td>B2C</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 domain             jargon_term  relevant  has_formula\n",
              "0    Business Analytics             Data Mining      True        False\n",
              "1    Business Analytics     Predictive Modeling      True        False\n",
              "2    Business Analytics      Data Visualization     False        False\n",
              "3    Business Analytics   Descriptive Analytics      True         True\n",
              "4    Business Analytics  Prescriptive Analytics      True         True\n",
              "5      Business Finance                  EBITDA      True         True\n",
              "6      Business Finance                     ROI      True         True\n",
              "7      Business Finance                     DCF      True         True\n",
              "8      Business Finance                     IRR      True         True\n",
              "9      Business Finance                     NPV      True         True\n",
              "10   Business Economics            Demand Curve      True        False\n",
              "11   Business Economics        Opportunity Cost      True         True\n",
              "12   Business Economics              Elasticity      True         True\n",
              "13   Business Economics                Monopoly     False        False\n",
              "14   Business Economics               Oligopoly     False        False\n",
              "15  Business Accounting           Balance Sheet      True        False\n",
              "16  Business Accounting     Cash Flow Statement      True         True\n",
              "17  Business Accounting           Accrual Basis      True         True\n",
              "18  Business Accounting            Depreciation      True         True\n",
              "19  Business Accounting     Inventory Valuation      True        False\n",
              "20  Business Management                     KPI      True         True\n",
              "21  Business Management                    SWOT     False        False\n",
              "22  Business Management                     B2B      True         True\n",
              "23  Business Management                     B2C      True         True"
            ]
          },
          "execution_count": 67,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "evaluated = lc_relevance(cleaned, columns, column_types)\n",
        "\n",
        "import pandas as pd\n",
        "pd.DataFrame(evaluated)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3. Prepare for Formula Retriever"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[\n",
            "  {\n",
            "    \"domain\": \"Business Analytics\",\n",
            "    \"jargon_term\": \"Descriptive Analytics\"\n",
            "  },\n",
            "  {\n",
            "    \"domain\": \"Business Analytics\",\n",
            "    \"jargon_term\": \"Prescriptive Analytics\"\n",
            "  },\n",
            "  {\n",
            "    \"domain\": \"Business Finance\",\n",
            "    \"jargon_term\": \"EBITDA\"\n",
            "  },\n",
            "  {\n",
            "    \"domain\": \"Business Finance\",\n",
            "    \"jargon_term\": \"ROI\"\n",
            "  },\n",
            "  {\n",
            "    \"domain\": \"Business Finance\",\n",
            "    \"jargon_term\": \"DCF\"\n",
            "  },\n",
            "  {\n",
            "    \"domain\": \"Business Finance\",\n",
            "    \"jargon_term\": \"IRR\"\n",
            "  },\n",
            "  {\n",
            "    \"domain\": \"Business Finance\",\n",
            "    \"jargon_term\": \"NPV\"\n",
            "  },\n",
            "  {\n",
            "    \"domain\": \"Business Economics\",\n",
            "    \"jargon_term\": \"Opportunity Cost\"\n",
            "  },\n",
            "  {\n",
            "    \"domain\": \"Business Economics\",\n",
            "    \"jargon_term\": \"Elasticity\"\n",
            "  },\n",
            "  {\n",
            "    \"domain\": \"Business Accounting\",\n",
            "    \"jargon_term\": \"Cash Flow Statement\"\n",
            "  },\n",
            "  {\n",
            "    \"domain\": \"Business Accounting\",\n",
            "    \"jargon_term\": \"Accrual Basis\"\n",
            "  },\n",
            "  {\n",
            "    \"domain\": \"Business Accounting\",\n",
            "    \"jargon_term\": \"Depreciation\"\n",
            "  },\n",
            "  {\n",
            "    \"domain\": \"Business Management\",\n",
            "    \"jargon_term\": \"KPI\"\n",
            "  },\n",
            "  {\n",
            "    \"domain\": \"Business Management\",\n",
            "    \"jargon_term\": \"B2B\"\n",
            "  },\n",
            "  {\n",
            "    \"domain\": \"Business Management\",\n",
            "    \"jargon_term\": \"B2C\"\n",
            "  }\n",
            "]\n"
          ]
        }
      ],
      "source": [
        "from typing import List, Dict\n",
        "\n",
        "def to_formula_targets(df: pd.DataFrame) -> List[Dict[str, str]]:\n",
        "    \"\"\"\n",
        "    Keep only rows where   relevant == True   AND   has_formula == True,\n",
        "    and return a list of plain dicts:  { \"domain\": ..., \"jargon_term\": ... }.\n",
        "    \"\"\"\n",
        "    mask   = (df[\"relevant\"]) & (df[\"has_formula\"])\n",
        "    subset = df.loc[mask, [\"domain\", \"jargon_term\"]]\n",
        "    return subset.to_dict(orient=\"records\")\n",
        "\n",
        "# ---- example usage ---------------------------------------------\n",
        "df         = pd.DataFrame(evaluated)     # «evaluated» is the list from step 3\n",
        "targets    = to_formula_targets(df)\n",
        "print(json.dumps(targets, indent=2))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Agent2: Formula Retriever"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: wikipedia in /Users/zhangran/Library/Python/3.9/lib/python/site-packages (1.4.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /Users/zhangran/Library/Python/3.9/lib/python/site-packages (from wikipedia) (4.13.4)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.0.0 in /Users/zhangran/Library/Python/3.9/lib/python/site-packages (from wikipedia) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/zhangran/Library/Python/3.9/lib/python/site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /Users/zhangran/Library/Python/3.9/lib/python/site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/zhangran/Library/Python/3.9/lib/python/site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /Users/zhangran/Library/Python/3.9/lib/python/site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2024.8.30)\n",
            "Requirement already satisfied: soupsieve>1.2 in /Users/zhangran/Library/Python/3.9/lib/python/site-packages (from beautifulsoup4->wikipedia) (2.7)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /Users/zhangran/Library/Python/3.9/lib/python/site-packages (from beautifulsoup4->wikipedia) (4.12.2)\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49m/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!pip install wikipedia"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/p4/f1848b4x3815qpp5kmf2j66w0000gn/T/ipykernel_1798/2626271568.py:21: LangChainDeprecationWarning: The class `OpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import OpenAI``.\n",
            "  llm = OpenAI(temperature=0)\n",
            "/var/folders/p4/f1848b4x3815qpp5kmf2j66w0000gn/T/ipykernel_1798/2626271568.py:61: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use :meth:`~RunnableSequence, e.g., `prompt | llm`` instead.\n",
            "  formula_contextualized_chain = LLMChain(llm=llm, prompt=formula_contextualized_prompt)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Retrieved formula information for Return on Investment in Finance:\n",
            "Page: Return on investment\n",
            "Summary: Return on investment (ROI) or return on costs (ROC) is the ratio between net income (over a period) and investment (costs resulting from an investment of some resou...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/p4/f1848b4x3815qpp5kmf2j66w0000gn/T/ipykernel_1798/2626271568.py:79: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
            "  contextualized_formula = formula_contextualized_chain.run(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "contextualized formula:\n",
            "\n",
            "The return on investment (ROI) is a measure of how much profit or gain an investment has generated compared to the cost of the investment. It is calculated by dividing the net income (total income minus expenses) by the initial investment cost. This ratio is expressed as a percentage and is used to evaluate the efficiency of an investment or to compare different investments.\n",
            "\n",
            "To calculate ROI, you need to know the net income and the initial investment cost. Net income is the total amount of money earned from the investment, while the initial investment cost is the amount of money that was initially put into the investment.\n",
            "\n",
            "For example, if you invest $100 and earn a net income of $20, your ROI would be 20%. This means that for every dollar you invested, you earned an additional 20 cents in profit.\n",
            "\n",
            "Another related concept is the rate of return, which is a way to compare returns over different time periods. This is useful because it allows for a fair comparison of investments that have different lengths of time. The rate of return is calculated by converting the return into a standard time period, usually a year.\n",
            "\n",
            "Return on equity (ROE) is a specific type of return that measures the profitability of a business in relation to its equity. Equity is the value of a company\n"
          ]
        }
      ],
      "source": [
        "from langchain.tools import WikipediaQueryRun\n",
        "from langchain.utilities import WikipediaAPIWrapper\n",
        "from langchain.chains import LLMChain\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.llms import OpenAI\n",
        "import json\n",
        "\n",
        "# Initialize Wikipedia tool\n",
        "wikipedia = WikipediaQueryRun(api_wrapper=WikipediaAPIWrapper())\n",
        "\n",
        "# Function to search domain-specific formulas from Wikipedia\n",
        "def search_domain_formulas(domain, concept):\n",
        "    \"\"\"Search Wikipedia for formulas related to a specific domain and concept.\"\"\"\n",
        "    try:\n",
        "        results = wikipedia.run(f\"{domain} {concept} formula\")\n",
        "        return results\n",
        "    except Exception as e:\n",
        "        return f\"Error searching Wikipedia: {str(e)}\"\n",
        "\n",
        "# Initialize LLM for formula contextualization\n",
        "llm = OpenAI(temperature=0)\n",
        "\n",
        "# Create a prompt template for converting formulas to textual descriptions\n",
        "formula_contextualized_prompt = PromptTemplate(\n",
        "    input_variables=[\"formula\", \"domain\", \"concept\"],\n",
        "    template=\"\"\"\n",
        "    Convert the following mathematical formula into a clear textual explanation:\n",
        "    \n",
        "    Domain: {domain}\n",
        "    Concept: {concept}\n",
        "    Formula: {formula}\n",
        "    \n",
        "    Provide a step-by-step explanation of what this formula means in plain language.\n",
        "    Explain each variable and how they relate to each other.\n",
        "    \"\"\"\n",
        ")\n",
        "\n",
        "# Create a prompt template for extracting variables from formulas\n",
        "formula_variables_prompt = PromptTemplate(\n",
        "    input_variables=[\"formula\"],\n",
        "    template=\"\"\"\n",
        "    Extract all variables from the following formula and return them in JSON format:\n",
        "   \n",
        "    Formula: {formula}\n",
        "    \n",
        "    For each variable, provide:\n",
        "    1. The variable name/symbol\n",
        "    2. What it represents in this context\n",
        "    3. Its typical unit of measurement (if applicable)\n",
        "    \n",
        "    Return as a valid JSON object with this structure:\n",
        "    {{\n",
        "        \"variables\": [\n",
        "            {{\"name\": \"variable_symbol\", \"represents\": \"description\", \"unit\": \"unit_of_measurement\"}}\n",
        "        ]\n",
        "    }}\n",
        "    \"\"\"\n",
        ")\n",
        "\n",
        "# Create a chain for formula contextualized\n",
        "formula_contextualized_chain = LLMChain(llm=llm, prompt=formula_contextualized_prompt)\n",
        "\n",
        "# Create a chain for extracting variables\n",
        "formula_variables_chain = LLMChain(llm=llm, prompt=formula_variables_prompt)\n",
        "\n",
        "\n",
        "\n",
        "# -------------------------------- Example usage --------------------------- #\n",
        "\n",
        "domain_example = \"Finance\"\n",
        "concept_example = \"Return on Investment\"\n",
        "\n",
        "# Retrieve formula from Wikipedia\n",
        "formula_text = search_domain_formulas(domain_example, concept_example)\n",
        "print(f\"Retrieved formula information for {concept_example} in {domain_example}:\")\n",
        "print(formula_text[:200] + \"...\" if len(formula_text) > 200 else formula_text)\n",
        "\n",
        "# Convert formula to textual explanation\n",
        "contextualized_formula = formula_contextualized_chain.run(\n",
        "    formula=formula_text, \n",
        "    domain=domain_example, \n",
        "    concept=concept_example\n",
        ")\n",
        "print(\"\\ncontextualized formula:\")\n",
        "print(contextualized_formula)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Extracted variables:\n",
            "Could not parse variables as JSON. Raw output:\n",
            "\n",
            "{\n",
            "    \"variables\": [\n",
            "        {\"name\": \"ROI\", \"represents\": \"Return on investment\", \"unit\": \"ratio\"},\n",
            "        {\"name\": \"ROC\", \"represents\": \"Return on costs\", \"unit\": \"ratio\"},\n",
            "        {\"name\": \"net_income\", \"represents\": \"Net income\", \"unit\": \"currency\"},\n",
            "        {\"name\": \"investment\", \"represents\": \"Costs resulting from an investment\", \"unit\": \"currency\"},\n",
            "        {\"name\": \"performance_measure\", \"represents\": \"Efficiency of an investment\", \"unit\": \"ratio\"},\n",
            "        {\"name\": \"economics\", \"represents\": \"Profits to capital invested\", \"unit\": \"ratio\"},\n",
            "        {\"name\": \"rate_of_return\", \"represents\": \"Profit on an investment\", \"unit\": \"percentage\"},\n",
            "        {\"name\": \"absolute_return\", \"represents\": \"Change in value of the investment\", \"unit\": \"currency\"},\n",
            "        {\"name\": \"holding_period_return\", \"represents\": \"Return over a period of time\", \"unit\": \"percentage\"},\n",
            "        {\"name\": \"annualized_return\", \"represents\": \"Rate of return over a year\", \"unit\": \"percentage\"},\n",
            "        {\"name\n"
          ]
        }
      ],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
