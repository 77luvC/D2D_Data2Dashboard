{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Preperation: Prompt File & OpenAI API KE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: langchain in /Users/zhangran/Library/Python/3.9/lib/python/site-packages (0.3.24)\n",
            "Requirement already satisfied: langchain_community in /Users/zhangran/Library/Python/3.9/lib/python/site-packages (0.3.22)\n",
            "Requirement already satisfied: openai in /Users/zhangran/Library/Python/3.9/lib/python/site-packages (1.76.0)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.55 in /Users/zhangran/Library/Python/3.9/lib/python/site-packages (from langchain) (0.3.55)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in /Users/zhangran/Library/Python/3.9/lib/python/site-packages (from langchain) (0.3.8)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.17 in /Users/zhangran/Library/Python/3.9/lib/python/site-packages (from langchain) (0.3.33)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /Users/zhangran/Library/Python/3.9/lib/python/site-packages (from langchain) (2.11.3)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /Users/zhangran/Library/Python/3.9/lib/python/site-packages (from langchain) (2.0.40)\n",
            "Requirement already satisfied: requests<3,>=2 in /Users/zhangran/Library/Python/3.9/lib/python/site-packages (from langchain) (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /Users/zhangran/Library/Python/3.9/lib/python/site-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /Users/zhangran/Library/Python/3.9/lib/python/site-packages (from langchain) (4.0.3)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /Users/zhangran/Library/Python/3.9/lib/python/site-packages (from langchain_community) (3.11.18)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /Users/zhangran/Library/Python/3.9/lib/python/site-packages (from langchain_community) (9.1.2)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /Users/zhangran/Library/Python/3.9/lib/python/site-packages (from langchain_community) (0.6.7)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /Users/zhangran/Library/Python/3.9/lib/python/site-packages (from langchain_community) (2.9.1)\n",
            "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /Users/zhangran/Library/Python/3.9/lib/python/site-packages (from langchain_community) (0.4.0)\n",
            "Requirement already satisfied: numpy>=1.26.2 in /Users/zhangran/Library/Python/3.9/lib/python/site-packages (from langchain_community) (2.0.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /Users/zhangran/Library/Python/3.9/lib/python/site-packages (from openai) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /Users/zhangran/Library/Python/3.9/lib/python/site-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /Users/zhangran/Library/Python/3.9/lib/python/site-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /Users/zhangran/Library/Python/3.9/lib/python/site-packages (from openai) (0.9.0)\n",
            "Requirement already satisfied: sniffio in /Users/zhangran/Library/Python/3.9/lib/python/site-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /Users/zhangran/Library/Python/3.9/lib/python/site-packages (from openai) (4.67.0)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /Users/zhangran/Library/Python/3.9/lib/python/site-packages (from openai) (4.12.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /Users/zhangran/Library/Python/3.9/lib/python/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /Users/zhangran/Library/Python/3.9/lib/python/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /Users/zhangran/Library/Python/3.9/lib/python/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /Users/zhangran/Library/Python/3.9/lib/python/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/zhangran/Library/Python/3.9/lib/python/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /Users/zhangran/Library/Python/3.9/lib/python/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /Users/zhangran/Library/Python/3.9/lib/python/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.20.0)\n",
            "Requirement already satisfied: exceptiongroup>=1.0.2 in /Users/zhangran/Library/Python/3.9/lib/python/site-packages (from anyio<5,>=3.5.0->openai) (1.2.2)\n",
            "Requirement already satisfied: idna>=2.8 in /Users/zhangran/Library/Python/3.9/lib/python/site-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /Users/zhangran/Library/Python/3.9/lib/python/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (3.26.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /Users/zhangran/Library/Python/3.9/lib/python/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (0.9.0)\n",
            "Requirement already satisfied: certifi in /Users/zhangran/Library/Python/3.9/lib/python/site-packages (from httpx<1,>=0.23.0->openai) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in /Users/zhangran/Library/Python/3.9/lib/python/site-packages (from httpx<1,>=0.23.0->openai) (1.0.8)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /Users/zhangran/Library/Python/3.9/lib/python/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /Users/zhangran/Library/Python/3.9/lib/python/site-packages (from langchain-core<1.0.0,>=0.3.55->langchain) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /Users/zhangran/Library/Python/3.9/lib/python/site-packages (from langchain-core<1.0.0,>=0.3.55->langchain) (24.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /Users/zhangran/Library/Python/3.9/lib/python/site-packages (from langsmith<0.4,>=0.1.17->langchain) (3.10.16)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /Users/zhangran/Library/Python/3.9/lib/python/site-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /Users/zhangran/Library/Python/3.9/lib/python/site-packages (from langsmith<0.4,>=0.1.17->langchain) (0.23.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /Users/zhangran/Library/Python/3.9/lib/python/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.1 in /Users/zhangran/Library/Python/3.9/lib/python/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /Users/zhangran/Library/Python/3.9/lib/python/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.0)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /Users/zhangran/Library/Python/3.9/lib/python/site-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain_community) (1.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/zhangran/Library/Python/3.9/lib/python/site-packages (from requests<3,>=2->langchain) (3.4.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/zhangran/Library/Python/3.9/lib/python/site-packages (from requests<3,>=2->langchain) (2.2.3)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /Users/zhangran/Library/Python/3.9/lib/python/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.55->langchain) (3.0.0)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /Users/zhangran/Library/Python/3.9/lib/python/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community) (1.1.0)\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49m/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!pip install langchain langchain_community openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: python-dotenv in /Users/zhangran/Library/Python/3.9/lib/python/site-packages (1.1.0)\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49m/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!pip install python-dotenv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "OPENAI_API_KEY=\"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\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from dotenv import load_dotenv\n",
        "import os\n",
        "\n",
        "# Load environment variables from .env file\n",
        "load_dotenv()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## AGENT1: Insigt Distributor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: langchain-core in /Users/zhangran/Library/Python/3.9/lib/python/site-packages (0.3.55)\n",
            "Collecting langchain-core\n",
            "  Downloading langchain_core-0.3.56-py3-none-any.whl.metadata (5.9 kB)\n",
            "Collecting langchain-openai\n",
            "  Downloading langchain_openai-0.3.14-py3-none-any.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.125 in /Users/zhangran/Library/Python/3.9/lib/python/site-packages (from langchain-core) (0.3.33)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /Users/zhangran/Library/Python/3.9/lib/python/site-packages (from langchain-core) (9.1.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /Users/zhangran/Library/Python/3.9/lib/python/site-packages (from langchain-core) (1.33)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /Users/zhangran/Library/Python/3.9/lib/python/site-packages (from langchain-core) (6.0.2)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /Users/zhangran/Library/Python/3.9/lib/python/site-packages (from langchain-core) (24.1)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /Users/zhangran/Library/Python/3.9/lib/python/site-packages (from langchain-core) (4.12.2)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.5.2 in /Users/zhangran/Library/Python/3.9/lib/python/site-packages (from langchain-core) (2.11.3)\n",
            "Requirement already satisfied: openai<2.0.0,>=1.68.2 in /Users/zhangran/Library/Python/3.9/lib/python/site-packages (from langchain-openai) (1.76.0)\n",
            "Collecting tiktoken<1,>=0.7 (from langchain-openai)\n",
            "  Downloading tiktoken-0.9.0-cp39-cp39-macosx_11_0_arm64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /Users/zhangran/Library/Python/3.9/lib/python/site-packages (from jsonpatch<2.0,>=1.33->langchain-core) (3.0.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /Users/zhangran/Library/Python/3.9/lib/python/site-packages (from langsmith<0.4,>=0.1.125->langchain-core) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /Users/zhangran/Library/Python/3.9/lib/python/site-packages (from langsmith<0.4,>=0.1.125->langchain-core) (3.10.16)\n",
            "Requirement already satisfied: requests<3,>=2 in /Users/zhangran/Library/Python/3.9/lib/python/site-packages (from langsmith<0.4,>=0.1.125->langchain-core) (2.32.3)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /Users/zhangran/Library/Python/3.9/lib/python/site-packages (from langsmith<0.4,>=0.1.125->langchain-core) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /Users/zhangran/Library/Python/3.9/lib/python/site-packages (from langsmith<0.4,>=0.1.125->langchain-core) (0.23.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /Users/zhangran/Library/Python/3.9/lib/python/site-packages (from openai<2.0.0,>=1.68.2->langchain-openai) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /Users/zhangran/Library/Python/3.9/lib/python/site-packages (from openai<2.0.0,>=1.68.2->langchain-openai) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /Users/zhangran/Library/Python/3.9/lib/python/site-packages (from openai<2.0.0,>=1.68.2->langchain-openai) (0.9.0)\n",
            "Requirement already satisfied: sniffio in /Users/zhangran/Library/Python/3.9/lib/python/site-packages (from openai<2.0.0,>=1.68.2->langchain-openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /Users/zhangran/Library/Python/3.9/lib/python/site-packages (from openai<2.0.0,>=1.68.2->langchain-openai) (4.67.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /Users/zhangran/Library/Python/3.9/lib/python/site-packages (from pydantic<3.0.0,>=2.5.2->langchain-core) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.1 in /Users/zhangran/Library/Python/3.9/lib/python/site-packages (from pydantic<3.0.0,>=2.5.2->langchain-core) (2.33.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /Users/zhangran/Library/Python/3.9/lib/python/site-packages (from pydantic<3.0.0,>=2.5.2->langchain-core) (0.4.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /Users/zhangran/Library/Python/3.9/lib/python/site-packages (from tiktoken<1,>=0.7->langchain-openai) (2024.11.6)\n",
            "Requirement already satisfied: exceptiongroup>=1.0.2 in /Users/zhangran/Library/Python/3.9/lib/python/site-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.68.2->langchain-openai) (1.2.2)\n",
            "Requirement already satisfied: idna>=2.8 in /Users/zhangran/Library/Python/3.9/lib/python/site-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.68.2->langchain-openai) (3.10)\n",
            "Requirement already satisfied: certifi in /Users/zhangran/Library/Python/3.9/lib/python/site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in /Users/zhangran/Library/Python/3.9/lib/python/site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core) (1.0.8)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /Users/zhangran/Library/Python/3.9/lib/python/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core) (0.14.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/zhangran/Library/Python/3.9/lib/python/site-packages (from requests<3,>=2->langsmith<0.4,>=0.1.125->langchain-core) (3.4.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/zhangran/Library/Python/3.9/lib/python/site-packages (from requests<3,>=2->langsmith<0.4,>=0.1.125->langchain-core) (2.2.3)\n",
            "Downloading langchain_core-0.3.56-py3-none-any.whl (437 kB)\n",
            "Downloading langchain_openai-0.3.14-py3-none-any.whl (62 kB)\n",
            "Downloading tiktoken-0.9.0-cp39-cp39-macosx_11_0_arm64.whl (1.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tiktoken, langchain-core, langchain-openai\n",
            "  Attempting uninstall: langchain-core\n",
            "    Found existing installation: langchain-core 0.3.55\n",
            "    Uninstalling langchain-core-0.3.55:\n",
            "      Successfully uninstalled langchain-core-0.3.55\n",
            "Successfully installed langchain-core-0.3.56 langchain-openai-0.3.14 tiktoken-0.9.0\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49m/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!pip install -U langchain-core langchain-openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "scoUpPDc1M91"
      },
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "Invalid template: input_variables=['columns'] input_types={} partial_variables={} template='\\n{{ columns }}\\n\\n{% raw %}\\n<<< # Domain Identification Prompt (ReAct\\xa0+\\xa0Reflexion style)\\n\\n---\\n## System message (immutable)\\n```\\nYou are a *domain‑identification agent*.\\nInput: a JSON array of objects, each object having exactly two keys:\\n  • \"column\": string – the column name\\n  • \"dtype\"  : string – a coarse data type such as \"numeric\", \"categorical\", \"date\", \"text\".\\n\\nGoal: return a ranked list of candidate knowledge domains *plus* the domain‑specific concepts / jargon that are *not already present* verbatim in the column list.\\n\\nUse a ReAct loop:\\n 1. **Think** – reason about what real‑world domains typically contain variables like these dtypes / names.\\n 2. **Act**   – (optional) call tools such as `search_examples(domain)` to recall external hints.\\n 3. **Reflect** – after a tentative answer, invoke the *Evaluator* to critique whether any proposed concept is merely an existing column name. If so, revise.\\n\\nReturn JSON with this exact schema:\\n{\\n  \"domains\": [\\n    {\\n      \"name\"        : string,          # e.g. \"Finance\"\\n      \"confidence\"  : number 0‑1,\\n      \"concepts\"    : [string,...]    # at least 3 unique jargon terms NOT identical (case‑insensitive) to any column name\\n    },\\n    ...\\n  ]\\n}\\n\\nAlways produce **exactly 5** domain objects.  Order by descending confidence.\\n```\\n\\n---\\n## Few‑shot exemplars (abbreviated)\\n\\n> ### Example 1\\n> **Input**  \\n> ```json\\n> [{\"column\": \"loan_amount\", \"dtype\": \"numeric\"}, {\"column\": \"interest_rate\", \"dtype\": \"numeric\"}, {\"column\": \"term_months\", \"dtype\": \"numeric\"}]\\n> ```\\n> **Thought**: Numeric loan variables → Finance or Banking.\\n> **Reflection**: Concepts must not repeat column names.\\n> **Answer**  \\n> ```json\\n> {\"domains\":[{\"name\":\"Banking\",\"confidence\":0.9,\"concepts\":[\"amortization\",\"principal\",\"APR\"]}, …]}\\n> ```\\n\\n### Example 2\\n**Input**\\n```json\\n[\\n  {\"column\": \"age\", \"dtype\": \"numeric\"},\\n  {\"column\": \"height_cm\", \"dtype\": \"numeric\"},\\n  {\"column\": \"weight_kg\", \"dtype\": \"numeric\"},\\n  {\"column\": \"blood_pressure\", \"dtype\": \"numeric\"},\\n  {\"column\": \"cholesterol_level\", \"dtype\": \"numeric\"}\\n]\\n```\\n**Think**: Vital‑sign style metrics suggest Healthcare / Clinical / Physiology domains.\\n\\n**Reflect** *(Evaluator)*: Ensure jargon isn’t merely “age”, “height”, etc. Swap in higher‑level concepts.\\n\\n**Answer**\\n```json\\n{\\n  \"domains\": [\\n    {\\n      \"name\": \"Healthcare\",\\n      \"confidence\": 0.88,\\n      \"concepts\": [\"BMI\", \"systolic\", \"diastolic\"]\\n    },\\n    {\\n      \"name\": \"Exercise Science\",\\n      \"confidence\": 0.6,\\n      \"concepts\": [\"VO2max\", \"basal_metabolic_rate\", \"cardiorespiratory_fitness\"]\\n    },\\n    {\\n      \"name\": \"Nutrition\",\\n      \"confidence\": 0.55,\\n      \"concepts\": [\"macronutrient\", \"lipid_profile\", \"HDL\"]\\n    },\\n    {\\n      \"name\": \"Public Health\",\\n      \"confidence\": 0.42,\\n      \"concepts\": [\"epidemiology\", \"risk_factor\", \"population_health\"]\\n    },\\n    {\\n      \"name\": \"Gerontology\",\\n      \"confidence\": 0.25,\\n      \"concepts\": [\"frailty_index\", \"chronological_age\", \"longevity\"]\\n    }\\n  ]\\n}\\n```\\n\\n >>>\\n{% endraw %}\\n' template_format='jinja2'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[38], line 34\u001b[0m\n\u001b[1;32m     20\u001b[0m USER_TMPL \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;130;01m{{\u001b[39;00m\u001b[38;5;130;01m{{\u001b[39;00m\u001b[38;5;124m columns \u001b[39m\u001b[38;5;130;01m}}\u001b[39;00m\u001b[38;5;130;01m}}\u001b[39;00m\n\u001b[1;32m     22\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;130;01m{{\u001b[39;00m\u001b[38;5;124m% endraw %\u001b[39m\u001b[38;5;130;01m}}\u001b[39;00m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m     28\u001b[0m user_prompt \u001b[38;5;241m=\u001b[39m PromptTemplate(\n\u001b[1;32m     29\u001b[0m     input_variables\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m],   \u001b[38;5;66;03m# <- we fill just this\u001b[39;00m\n\u001b[1;32m     30\u001b[0m     template\u001b[38;5;241m=\u001b[39mUSER_TMPL,\n\u001b[1;32m     31\u001b[0m     template_format\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjinja2\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     32\u001b[0m )\n\u001b[0;32m---> 34\u001b[0m chat_prompt \u001b[38;5;241m=\u001b[39m \u001b[43mChatPromptTemplate\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_messages\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[43m    \u001b[49m\u001b[43m[\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muser_prompt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     36\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;66;03m# ────────────────────────────────────────────────────────────────\u001b[39;00m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;66;03m# 3.  Instantiate the chat model\u001b[39;00m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;66;03m# ────────────────────────────────────────────────────────────────\u001b[39;00m\n\u001b[1;32m     41\u001b[0m llm \u001b[38;5;241m=\u001b[39m ChatOpenAI(\n\u001b[1;32m     42\u001b[0m     model_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgpt-4o-mini\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     43\u001b[0m     temperature\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m,\n\u001b[1;32m     44\u001b[0m )\n",
            "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/langchain_core/prompts/chat.py:1155\u001b[0m, in \u001b[0;36mfrom_messages\u001b[0;34m(cls, messages, template_format)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfrom_messages\u001b[39m(\n\u001b[1;32m   1128\u001b[0m     \u001b[38;5;28mcls\u001b[39m,\n\u001b[1;32m   1129\u001b[0m     messages: Sequence[MessageLikeRepresentation],\n\u001b[1;32m   1130\u001b[0m     template_format: PromptTemplateFormat \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mf-string\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1131\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ChatPromptTemplate:\n\u001b[1;32m   1132\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Create a chat prompt template from a variety of message formats.\u001b[39;00m\n\u001b[1;32m   1133\u001b[0m \n\u001b[1;32m   1134\u001b[0m \u001b[38;5;124;03m    Examples:\u001b[39;00m\n\u001b[1;32m   1135\u001b[0m \u001b[38;5;124;03m        Instantiation from a list of message templates:\u001b[39;00m\n\u001b[1;32m   1136\u001b[0m \n\u001b[1;32m   1137\u001b[0m \u001b[38;5;124;03m        .. code-block:: python\u001b[39;00m\n\u001b[1;32m   1138\u001b[0m \n\u001b[1;32m   1139\u001b[0m \u001b[38;5;124;03m            template = ChatPromptTemplate.from_messages([\u001b[39;00m\n\u001b[1;32m   1140\u001b[0m \u001b[38;5;124;03m                (\"human\", \"Hello, how are you?\"),\u001b[39;00m\n\u001b[1;32m   1141\u001b[0m \u001b[38;5;124;03m                (\"ai\", \"I'm doing well, thanks!\"),\u001b[39;00m\n\u001b[1;32m   1142\u001b[0m \u001b[38;5;124;03m                (\"human\", \"That's good to hear.\"),\u001b[39;00m\n\u001b[1;32m   1143\u001b[0m \u001b[38;5;124;03m            ])\u001b[39;00m\n\u001b[1;32m   1144\u001b[0m \n\u001b[1;32m   1145\u001b[0m \u001b[38;5;124;03m        Instantiation from mixed message formats:\u001b[39;00m\n\u001b[1;32m   1146\u001b[0m \n\u001b[1;32m   1147\u001b[0m \u001b[38;5;124;03m        .. code-block:: python\u001b[39;00m\n\u001b[1;32m   1148\u001b[0m \n\u001b[1;32m   1149\u001b[0m \u001b[38;5;124;03m            template = ChatPromptTemplate.from_messages([\u001b[39;00m\n\u001b[1;32m   1150\u001b[0m \u001b[38;5;124;03m                SystemMessage(content=\"hello\"),\u001b[39;00m\n\u001b[1;32m   1151\u001b[0m \u001b[38;5;124;03m                (\"human\", \"Hello, how are you?\"),\u001b[39;00m\n\u001b[1;32m   1152\u001b[0m \u001b[38;5;124;03m            ])\u001b[39;00m\n\u001b[1;32m   1153\u001b[0m \n\u001b[1;32m   1154\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m-> 1155\u001b[0m \u001b[38;5;124;03m        messages: sequence of message representations.\u001b[39;00m\n\u001b[1;32m   1156\u001b[0m \u001b[38;5;124;03m              A message can be represented using the following formats:\u001b[39;00m\n\u001b[1;32m   1157\u001b[0m \u001b[38;5;124;03m              (1) BaseMessagePromptTemplate, (2) BaseMessage, (3) 2-tuple of\u001b[39;00m\n\u001b[1;32m   1158\u001b[0m \u001b[38;5;124;03m              (message type, template); e.g., (\"human\", \"{user_input}\"),\u001b[39;00m\n\u001b[1;32m   1159\u001b[0m \u001b[38;5;124;03m              (4) 2-tuple of (message class, template), (5) a string which is\u001b[39;00m\n\u001b[1;32m   1160\u001b[0m \u001b[38;5;124;03m              shorthand for (\"human\", template); e.g., \"{user_input}\".\u001b[39;00m\n\u001b[1;32m   1161\u001b[0m \u001b[38;5;124;03m        template_format: format of the template. Defaults to \"f-string\".\u001b[39;00m\n\u001b[1;32m   1162\u001b[0m \n\u001b[1;32m   1163\u001b[0m \u001b[38;5;124;03m    Returns:\u001b[39;00m\n\u001b[1;32m   1164\u001b[0m \u001b[38;5;124;03m        a chat prompt template.\u001b[39;00m\n\u001b[1;32m   1165\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m   1166\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m(messages, template_format\u001b[38;5;241m=\u001b[39mtemplate_format)\n",
            "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/langchain_core/prompts/chat.py:937\u001b[0m, in \u001b[0;36m__init__\u001b[0;34m(self, messages, template_format, **kwargs)\u001b[0m\n\u001b[1;32m    894\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m    895\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    896\u001b[0m     messages: Sequence[MessageLikeRepresentation],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    899\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    900\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    901\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Create a chat prompt template from a variety of message formats.\u001b[39;00m\n\u001b[1;32m    902\u001b[0m \n\u001b[1;32m    903\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m    904\u001b[0m \u001b[38;5;124;03m        messages: sequence of message representations.\u001b[39;00m\n\u001b[1;32m    905\u001b[0m \u001b[38;5;124;03m              A message can be represented using the following formats:\u001b[39;00m\n\u001b[1;32m    906\u001b[0m \u001b[38;5;124;03m              (1) BaseMessagePromptTemplate, (2) BaseMessage, (3) 2-tuple of\u001b[39;00m\n\u001b[1;32m    907\u001b[0m \u001b[38;5;124;03m              (message type, template); e.g., (\"human\", \"{user_input}\"),\u001b[39;00m\n\u001b[1;32m    908\u001b[0m \u001b[38;5;124;03m              (4) 2-tuple of (message class, template), (5) a string which is\u001b[39;00m\n\u001b[1;32m    909\u001b[0m \u001b[38;5;124;03m              shorthand for (\"human\", template); e.g., \"{user_input}\".\u001b[39;00m\n\u001b[1;32m    910\u001b[0m \u001b[38;5;124;03m        template_format: format of the template. Defaults to \"f-string\".\u001b[39;00m\n\u001b[1;32m    911\u001b[0m \u001b[38;5;124;03m        input_variables: A list of the names of the variables whose values are\u001b[39;00m\n\u001b[1;32m    912\u001b[0m \u001b[38;5;124;03m            required as inputs to the prompt.\u001b[39;00m\n\u001b[1;32m    913\u001b[0m \u001b[38;5;124;03m        optional_variables: A list of the names of the variables for placeholder\u001b[39;00m\n\u001b[1;32m    914\u001b[0m \u001b[38;5;124;03m            or MessagePlaceholder that are optional.\u001b[39;00m\n\u001b[1;32m    915\u001b[0m \u001b[38;5;124;03m            These variables are auto inferred from the prompt and user need not\u001b[39;00m\n\u001b[1;32m    916\u001b[0m \u001b[38;5;124;03m            provide them.\u001b[39;00m\n\u001b[1;32m    917\u001b[0m \u001b[38;5;124;03m        partial_variables: A dictionary of the partial variables the prompt\u001b[39;00m\n\u001b[1;32m    918\u001b[0m \u001b[38;5;124;03m            template carries. Partial variables populate the template so that you\u001b[39;00m\n\u001b[1;32m    919\u001b[0m \u001b[38;5;124;03m            don't need to pass them in every time you call the prompt.\u001b[39;00m\n\u001b[1;32m    920\u001b[0m \u001b[38;5;124;03m        validate_template: Whether to validate the template.\u001b[39;00m\n\u001b[1;32m    921\u001b[0m \u001b[38;5;124;03m        input_types: A dictionary of the types of the variables the prompt template\u001b[39;00m\n\u001b[1;32m    922\u001b[0m \u001b[38;5;124;03m            expects. If not provided, all variables are assumed to be strings.\u001b[39;00m\n\u001b[1;32m    923\u001b[0m \n\u001b[1;32m    924\u001b[0m \u001b[38;5;124;03m    Returns:\u001b[39;00m\n\u001b[1;32m    925\u001b[0m \u001b[38;5;124;03m        A chat prompt template.\u001b[39;00m\n\u001b[1;32m    926\u001b[0m \n\u001b[1;32m    927\u001b[0m \u001b[38;5;124;03m    Examples:\u001b[39;00m\n\u001b[1;32m    928\u001b[0m \u001b[38;5;124;03m        Instantiation from a list of message templates:\u001b[39;00m\n\u001b[1;32m    929\u001b[0m \n\u001b[1;32m    930\u001b[0m \u001b[38;5;124;03m        .. code-block:: python\u001b[39;00m\n\u001b[1;32m    931\u001b[0m \n\u001b[1;32m    932\u001b[0m \u001b[38;5;124;03m            template = ChatPromptTemplate([\u001b[39;00m\n\u001b[1;32m    933\u001b[0m \u001b[38;5;124;03m                (\"human\", \"Hello, how are you?\"),\u001b[39;00m\n\u001b[1;32m    934\u001b[0m \u001b[38;5;124;03m                (\"ai\", \"I'm doing well, thanks!\"),\u001b[39;00m\n\u001b[1;32m    935\u001b[0m \u001b[38;5;124;03m                (\"human\", \"That's good to hear.\"),\u001b[39;00m\n\u001b[1;32m    936\u001b[0m \u001b[38;5;124;03m            ])\u001b[39;00m\n\u001b[0;32m--> 937\u001b[0m \n\u001b[1;32m    938\u001b[0m \u001b[38;5;124;03m        Instantiation from mixed message formats:\u001b[39;00m\n\u001b[1;32m    939\u001b[0m \n\u001b[1;32m    940\u001b[0m \u001b[38;5;124;03m        .. code-block:: python\u001b[39;00m\n\u001b[1;32m    941\u001b[0m \n\u001b[1;32m    942\u001b[0m \u001b[38;5;124;03m            template = ChatPromptTemplate([\u001b[39;00m\n\u001b[1;32m    943\u001b[0m \u001b[38;5;124;03m                SystemMessage(content=\"hello\"),\u001b[39;00m\n\u001b[1;32m    944\u001b[0m \u001b[38;5;124;03m                (\"human\", \"Hello, how are you?\"),\u001b[39;00m\n\u001b[1;32m    945\u001b[0m \u001b[38;5;124;03m            ])\u001b[39;00m\n\u001b[1;32m    946\u001b[0m \n\u001b[1;32m    947\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m    948\u001b[0m     _messages \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    949\u001b[0m         _convert_to_message_template(message, template_format)\n\u001b[1;32m    950\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m message \u001b[38;5;129;01min\u001b[39;00m messages\n\u001b[1;32m    951\u001b[0m     ]\n\u001b[1;32m    953\u001b[0m     \u001b[38;5;66;03m# Automatically infer input variables from messages\u001b[39;00m\n",
            "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/langchain_core/prompts/chat.py:938\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    894\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m    895\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    896\u001b[0m     messages: Sequence[MessageLikeRepresentation],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    899\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    900\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    901\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Create a chat prompt template from a variety of message formats.\u001b[39;00m\n\u001b[1;32m    902\u001b[0m \n\u001b[1;32m    903\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m    904\u001b[0m \u001b[38;5;124;03m        messages: sequence of message representations.\u001b[39;00m\n\u001b[1;32m    905\u001b[0m \u001b[38;5;124;03m              A message can be represented using the following formats:\u001b[39;00m\n\u001b[1;32m    906\u001b[0m \u001b[38;5;124;03m              (1) BaseMessagePromptTemplate, (2) BaseMessage, (3) 2-tuple of\u001b[39;00m\n\u001b[1;32m    907\u001b[0m \u001b[38;5;124;03m              (message type, template); e.g., (\"human\", \"{user_input}\"),\u001b[39;00m\n\u001b[1;32m    908\u001b[0m \u001b[38;5;124;03m              (4) 2-tuple of (message class, template), (5) a string which is\u001b[39;00m\n\u001b[1;32m    909\u001b[0m \u001b[38;5;124;03m              shorthand for (\"human\", template); e.g., \"{user_input}\".\u001b[39;00m\n\u001b[1;32m    910\u001b[0m \u001b[38;5;124;03m        template_format: format of the template. Defaults to \"f-string\".\u001b[39;00m\n\u001b[1;32m    911\u001b[0m \u001b[38;5;124;03m        input_variables: A list of the names of the variables whose values are\u001b[39;00m\n\u001b[1;32m    912\u001b[0m \u001b[38;5;124;03m            required as inputs to the prompt.\u001b[39;00m\n\u001b[1;32m    913\u001b[0m \u001b[38;5;124;03m        optional_variables: A list of the names of the variables for placeholder\u001b[39;00m\n\u001b[1;32m    914\u001b[0m \u001b[38;5;124;03m            or MessagePlaceholder that are optional.\u001b[39;00m\n\u001b[1;32m    915\u001b[0m \u001b[38;5;124;03m            These variables are auto inferred from the prompt and user need not\u001b[39;00m\n\u001b[1;32m    916\u001b[0m \u001b[38;5;124;03m            provide them.\u001b[39;00m\n\u001b[1;32m    917\u001b[0m \u001b[38;5;124;03m        partial_variables: A dictionary of the partial variables the prompt\u001b[39;00m\n\u001b[1;32m    918\u001b[0m \u001b[38;5;124;03m            template carries. Partial variables populate the template so that you\u001b[39;00m\n\u001b[1;32m    919\u001b[0m \u001b[38;5;124;03m            don't need to pass them in every time you call the prompt.\u001b[39;00m\n\u001b[1;32m    920\u001b[0m \u001b[38;5;124;03m        validate_template: Whether to validate the template.\u001b[39;00m\n\u001b[1;32m    921\u001b[0m \u001b[38;5;124;03m        input_types: A dictionary of the types of the variables the prompt template\u001b[39;00m\n\u001b[1;32m    922\u001b[0m \u001b[38;5;124;03m            expects. If not provided, all variables are assumed to be strings.\u001b[39;00m\n\u001b[1;32m    923\u001b[0m \n\u001b[1;32m    924\u001b[0m \u001b[38;5;124;03m    Returns:\u001b[39;00m\n\u001b[1;32m    925\u001b[0m \u001b[38;5;124;03m        A chat prompt template.\u001b[39;00m\n\u001b[1;32m    926\u001b[0m \n\u001b[1;32m    927\u001b[0m \u001b[38;5;124;03m    Examples:\u001b[39;00m\n\u001b[1;32m    928\u001b[0m \u001b[38;5;124;03m        Instantiation from a list of message templates:\u001b[39;00m\n\u001b[1;32m    929\u001b[0m \n\u001b[1;32m    930\u001b[0m \u001b[38;5;124;03m        .. code-block:: python\u001b[39;00m\n\u001b[1;32m    931\u001b[0m \n\u001b[1;32m    932\u001b[0m \u001b[38;5;124;03m            template = ChatPromptTemplate([\u001b[39;00m\n\u001b[1;32m    933\u001b[0m \u001b[38;5;124;03m                (\"human\", \"Hello, how are you?\"),\u001b[39;00m\n\u001b[1;32m    934\u001b[0m \u001b[38;5;124;03m                (\"ai\", \"I'm doing well, thanks!\"),\u001b[39;00m\n\u001b[1;32m    935\u001b[0m \u001b[38;5;124;03m                (\"human\", \"That's good to hear.\"),\u001b[39;00m\n\u001b[1;32m    936\u001b[0m \u001b[38;5;124;03m            ])\u001b[39;00m\n\u001b[1;32m    937\u001b[0m \n\u001b[0;32m--> 938\u001b[0m \u001b[38;5;124;03m        Instantiation from mixed message formats:\u001b[39;00m\n\u001b[1;32m    939\u001b[0m \n\u001b[1;32m    940\u001b[0m \u001b[38;5;124;03m        .. code-block:: python\u001b[39;00m\n\u001b[1;32m    941\u001b[0m \n\u001b[1;32m    942\u001b[0m \u001b[38;5;124;03m            template = ChatPromptTemplate([\u001b[39;00m\n\u001b[1;32m    943\u001b[0m \u001b[38;5;124;03m                SystemMessage(content=\"hello\"),\u001b[39;00m\n\u001b[1;32m    944\u001b[0m \u001b[38;5;124;03m                (\"human\", \"Hello, how are you?\"),\u001b[39;00m\n\u001b[1;32m    945\u001b[0m \u001b[38;5;124;03m            ])\u001b[39;00m\n\u001b[1;32m    946\u001b[0m \n\u001b[1;32m    947\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m    948\u001b[0m     _messages \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    949\u001b[0m         _convert_to_message_template(message, template_format)\n\u001b[1;32m    950\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m message \u001b[38;5;129;01min\u001b[39;00m messages\n\u001b[1;32m    951\u001b[0m     ]\n\u001b[1;32m    953\u001b[0m     \u001b[38;5;66;03m# Automatically infer input variables from messages\u001b[39;00m\n",
            "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/langchain_core/prompts/chat.py:1431\u001b[0m, in \u001b[0;36m_convert_to_message_template\u001b[0;34m(message, template_format)\u001b[0m\n\u001b[1;32m   1429\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(message, \u001b[38;5;28mdict\u001b[39m):\n\u001b[1;32m   1430\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mset\u001b[39m(message\u001b[38;5;241m.\u001b[39mkeys()) \u001b[38;5;241m!=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m}:\n\u001b[0;32m-> 1431\u001b[0m         msg \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   1432\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected dict to have exact keys \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m and \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1433\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m Got: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmessage\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1434\u001b[0m         )\n\u001b[1;32m   1435\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[1;32m   1436\u001b[0m     message \u001b[38;5;241m=\u001b[39m (message[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m], message[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
            "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/langchain_core/prompts/chat.py:1330\u001b[0m, in \u001b[0;36m_create_template_from_message_type\u001b[0;34m(message_type, template, template_format)\u001b[0m\n\u001b[1;32m   1322\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_create_template_from_message_type\u001b[39m(\n\u001b[1;32m   1323\u001b[0m     message_type: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m   1324\u001b[0m     template: Union[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mlist\u001b[39m],\n\u001b[1;32m   1325\u001b[0m     template_format: PromptTemplateFormat \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mf-string\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1326\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m BaseMessagePromptTemplate:\n\u001b[1;32m   1327\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Create a message prompt template from a message type and template string.\u001b[39;00m\n\u001b[1;32m   1328\u001b[0m \n\u001b[1;32m   1329\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m-> 1330\u001b[0m \u001b[38;5;124;03m        message_type: str the type of the message template (e.g., \"human\", \"ai\", etc.)\u001b[39;00m\n\u001b[1;32m   1331\u001b[0m \u001b[38;5;124;03m        template: str the template string.\u001b[39;00m\n\u001b[1;32m   1332\u001b[0m \u001b[38;5;124;03m        template_format: format of the template. Defaults to \"f-string\".\u001b[39;00m\n\u001b[1;32m   1333\u001b[0m \n\u001b[1;32m   1334\u001b[0m \u001b[38;5;124;03m    Returns:\u001b[39;00m\n\u001b[1;32m   1335\u001b[0m \u001b[38;5;124;03m        a message prompt template of the appropriate type.\u001b[39;00m\n\u001b[1;32m   1336\u001b[0m \n\u001b[1;32m   1337\u001b[0m \u001b[38;5;124;03m    Raises:\u001b[39;00m\n\u001b[1;32m   1338\u001b[0m \u001b[38;5;124;03m        ValueError: If unexpected message type.\u001b[39;00m\n\u001b[1;32m   1339\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m   1340\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m message_type \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhuman\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m   1341\u001b[0m         message: BaseMessagePromptTemplate \u001b[38;5;241m=\u001b[39m HumanMessagePromptTemplate\u001b[38;5;241m.\u001b[39mfrom_template(\n\u001b[1;32m   1342\u001b[0m             template, template_format\u001b[38;5;241m=\u001b[39mtemplate_format\n\u001b[1;32m   1343\u001b[0m         )\n",
            "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/langchain_core/prompts/chat.py:516\u001b[0m, in \u001b[0;36mfrom_template\u001b[0;34m(cls, template, template_format, partial_variables, **kwargs)\u001b[0m\n\u001b[1;32m    510\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m template_format \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjinja2\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    511\u001b[0m     msg \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    512\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjinja2 is unsafe and is not supported for templates \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    513\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexpressed as dicts. Please use \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mf-string\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m or \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmustache\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    514\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mformat.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    515\u001b[0m     )\n\u001b[0;32m--> 516\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[1;32m    517\u001b[0m data_template_obj \u001b[38;5;241m=\u001b[39m DictPromptTemplate(\n\u001b[1;32m    518\u001b[0m     template\u001b[38;5;241m=\u001b[39mcast(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdict[str, Any]\u001b[39m\u001b[38;5;124m\"\u001b[39m, tmpl),\n\u001b[1;32m    519\u001b[0m     template_format\u001b[38;5;241m=\u001b[39mtemplate_format,\n\u001b[1;32m    520\u001b[0m )\n\u001b[1;32m    521\u001b[0m prompt\u001b[38;5;241m.\u001b[39mappend(data_template_obj)\n",
            "\u001b[0;31mValueError\u001b[0m: Invalid template: input_variables=['columns'] input_types={} partial_variables={} template='\\n{{ columns }}\\n\\n{% raw %}\\n<<< # Domain Identification Prompt (ReAct\\xa0+\\xa0Reflexion style)\\n\\n---\\n## System message (immutable)\\n```\\nYou are a *domain‑identification agent*.\\nInput: a JSON array of objects, each object having exactly two keys:\\n  • \"column\": string – the column name\\n  • \"dtype\"  : string – a coarse data type such as \"numeric\", \"categorical\", \"date\", \"text\".\\n\\nGoal: return a ranked list of candidate knowledge domains *plus* the domain‑specific concepts / jargon that are *not already present* verbatim in the column list.\\n\\nUse a ReAct loop:\\n 1. **Think** – reason about what real‑world domains typically contain variables like these dtypes / names.\\n 2. **Act**   – (optional) call tools such as `search_examples(domain)` to recall external hints.\\n 3. **Reflect** – after a tentative answer, invoke the *Evaluator* to critique whether any proposed concept is merely an existing column name. If so, revise.\\n\\nReturn JSON with this exact schema:\\n{\\n  \"domains\": [\\n    {\\n      \"name\"        : string,          # e.g. \"Finance\"\\n      \"confidence\"  : number 0‑1,\\n      \"concepts\"    : [string,...]    # at least 3 unique jargon terms NOT identical (case‑insensitive) to any column name\\n    },\\n    ...\\n  ]\\n}\\n\\nAlways produce **exactly 5** domain objects.  Order by descending confidence.\\n```\\n\\n---\\n## Few‑shot exemplars (abbreviated)\\n\\n> ### Example 1\\n> **Input**  \\n> ```json\\n> [{\"column\": \"loan_amount\", \"dtype\": \"numeric\"}, {\"column\": \"interest_rate\", \"dtype\": \"numeric\"}, {\"column\": \"term_months\", \"dtype\": \"numeric\"}]\\n> ```\\n> **Thought**: Numeric loan variables → Finance or Banking.\\n> **Reflection**: Concepts must not repeat column names.\\n> **Answer**  \\n> ```json\\n> {\"domains\":[{\"name\":\"Banking\",\"confidence\":0.9,\"concepts\":[\"amortization\",\"principal\",\"APR\"]}, …]}\\n> ```\\n\\n### Example 2\\n**Input**\\n```json\\n[\\n  {\"column\": \"age\", \"dtype\": \"numeric\"},\\n  {\"column\": \"height_cm\", \"dtype\": \"numeric\"},\\n  {\"column\": \"weight_kg\", \"dtype\": \"numeric\"},\\n  {\"column\": \"blood_pressure\", \"dtype\": \"numeric\"},\\n  {\"column\": \"cholesterol_level\", \"dtype\": \"numeric\"}\\n]\\n```\\n**Think**: Vital‑sign style metrics suggest Healthcare / Clinical / Physiology domains.\\n\\n**Reflect** *(Evaluator)*: Ensure jargon isn’t merely “age”, “height”, etc. Swap in higher‑level concepts.\\n\\n**Answer**\\n```json\\n{\\n  \"domains\": [\\n    {\\n      \"name\": \"Healthcare\",\\n      \"confidence\": 0.88,\\n      \"concepts\": [\"BMI\", \"systolic\", \"diastolic\"]\\n    },\\n    {\\n      \"name\": \"Exercise Science\",\\n      \"confidence\": 0.6,\\n      \"concepts\": [\"VO2max\", \"basal_metabolic_rate\", \"cardiorespiratory_fitness\"]\\n    },\\n    {\\n      \"name\": \"Nutrition\",\\n      \"confidence\": 0.55,\\n      \"concepts\": [\"macronutrient\", \"lipid_profile\", \"HDL\"]\\n    },\\n    {\\n      \"name\": \"Public Health\",\\n      \"confidence\": 0.42,\\n      \"concepts\": [\"epidemiology\", \"risk_factor\", \"population_health\"]\\n    },\\n    {\\n      \"name\": \"Gerontology\",\\n      \"confidence\": 0.25,\\n      \"concepts\": [\"frailty_index\", \"chronological_age\", \"longevity\"]\\n    }\\n  ]\\n}\\n```\\n\\n >>>\\n{% endraw %}\\n' template_format='jinja2'"
          ]
        }
      ],
      "source": [
        "# ────────────────────────────────────────────────────────────────\n",
        "# 0.  Imports  (LangChain 0.1.x series)\n",
        "# ────────────────────────────────────────────────────────────────\n",
        "from langchain_openai import ChatOpenAI            # ⇐ chat wrapper (0.1+)\n",
        "from langchain.prompts import ChatPromptTemplate\n",
        "from langchain.chains import LLMChain\n",
        "\n",
        "import os, json\n",
        "from dotenv import load_dotenv\n",
        "load_dotenv()                                      # expects OPENAI_API_KEY\n",
        "\n",
        "# ────────────────────────────────────────────────────────────────\n",
        "# 1.  Read the prompt body that lives in a text file\n",
        "# ────────────────────────────────────────────────────────────────\n",
        "prompt_path = Path(\"domain_detector_prompt.txt\")\n",
        "detector_body = prompt_path.read_text(encoding=\"utf-8\")\n",
        "\n",
        "# ────────────────────────────────────────────────────────────────\n",
        "# 2.  Build a Jinja-2 template.\n",
        "#     • first line             : our ONLY real variable  {{ columns }}\n",
        "#     • everything afterwards  : wrapped in  {% raw %} … {% endraw %}\n",
        "# ────────────────────────────────────────────────────────────────\n",
        "USER_TMPL = f\"\"\"\n",
        "{{{{ columns }}}}\n",
        "\n",
        "{{% raw %}}\n",
        "{detector_body}\n",
        "{{% endraw %}}\n",
        "\"\"\"\n",
        "\n",
        "user_prompt = PromptTemplate(\n",
        "    input_variables=[\"columns\"],   # <- we fill just this\n",
        "    template=USER_TMPL,\n",
        "    template_format=\"jinja2\",\n",
        ")\n",
        "\n",
        "chat_prompt = ChatPromptTemplate.from_messages(\n",
        "    [(\"user\", user_prompt)]\n",
        ")\n",
        "\n",
        "# ────────────────────────────────────────────────────────────────\n",
        "# 3.  Instantiate the chat model\n",
        "# ────────────────────────────────────────────────────────────────\n",
        "llm = ChatOpenAI(\n",
        "    model_name=\"gpt-4o-mini\",\n",
        "    temperature=0,\n",
        ")\n",
        "\n",
        "# ────────────────────────────────────────────────────────────────\n",
        "# 4.  Example schema to feed into the prompt\n",
        "# ────────────────────────────────────────────────────────────────\n",
        "schema = [\n",
        "    {\"column\": \"Quarter\",            \"dtype\": \"text\"},\n",
        "    {\"column\": \"number_Customers\",   \"dtype\": \"text\"},\n",
        "    {\"column\": \"Total_Transactions\", \"dtype\": \"text\"},\n",
        "    {\"column\": \"Revenue\",            \"dtype\": \"text\"},\n",
        "    {\"column\": \"Profit\",             \"dtype\": \"text\"},\n",
        "]\n",
        "\n",
        "# format() does the Jinja substitution\n",
        "final_prompt = chat_prompt.format(\n",
        "    columns=json.dumps(schema, indent=2)\n",
        ")\n",
        "\n",
        "# ────────────────────────────────────────────────────────────────\n",
        "# 5.  Call the LLM\n",
        "# ────────────────────────────────────────────────────────────────\n",
        "response = llm.invoke(final_prompt)\n",
        "print(response.content)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "content='Hi! How can I assist you today?' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 10, 'prompt_tokens': 10, 'total_tokens': 20, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_0392822090', 'id': 'chatcmpl-BPwuvafPNAGmMvRAV3eolYK3ZqH6p', 'finish_reason': 'stop', 'logprobs': None} id='run-da211950-02ad-474d-bbe2-5ed2490c8578-0' usage_metadata={'input_tokens': 10, 'output_tokens': 10, 'total_tokens': 20, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
          ]
        }
      ],
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "model = ChatOpenAI(model_name=\"gpt-4o-mini\", temperature=0)\n",
        "print(model.invoke(\"Say hi!\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "############################################################################\n",
        "# 2. Wiki tools with simple file-cache\n",
        "############################################################################\n",
        "CACHE = shelve.open(\"wiki_cache.db\")\n",
        "\n",
        "class WikiSearchTool(BaseTool):\n",
        "    name, description = \"wikipedia_search\", \"search <query> on en.wikipedia\"\n",
        "    def _run(self, query):\n",
        "        url = \"https://en.wikipedia.org/w/api.php\"\n",
        "        params = {\"action\":\"query\",\"list\":\"search\",\"srsearch\":query,\"format\":\"json\"}\n",
        "        key   = f\"search::{query}\"\n",
        "        if key not in CACHE:\n",
        "            CACHE[key] = requests.get(url, params=params).json()\n",
        "        return CACHE[key][\"query\"][\"search\"][:5]\n",
        "\n",
        "class WikiExtractTool(BaseTool):\n",
        "    name, description = \"wikipedia_extract\", \"extract <pageid> <heading_keyword> text\"\n",
        "    def _run(self, pageid_heading):\n",
        "        pageid, heading = pageid_heading.split(maxsplit=1)\n",
        "        key   = f\"extract::{pageid}::{heading}\"\n",
        "        if key not in CACHE:\n",
        "            url = \"https://en.wikipedia.org/w/api.php\"\n",
        "            params = {\"action\":\"parse\",\"pageid\":pageid,\"prop\":\"wikitext\",\"format\":\"json\"}\n",
        "            CACHE[key] = requests.get(url, params=params).json()\n",
        "        # very naïve heading filter:\n",
        "        return CACHE[key][\"parse\"][\"wikitext\"][\"*\"]\n",
        "\n",
        "############################################################################\n",
        "# 3. Initialize the ReAct agent\n",
        "############################################################################\n",
        "tools   = [WikiSearchTool(), WikiExtractTool()]\n",
        "react_prompt = PromptTemplate.from_file(\"formula_retrieval_prompt.txt\")\n",
        "agent   = initialize_agent(\n",
        "            tools=tools,\n",
        "            llm=OpenAI(model=\"gpt-4o-mini\"),\n",
        "            agent=AgentType.REACT_DESCRIPTION,\n",
        "            prompt=react_prompt,\n",
        "            verbose=True,\n",
        "          )\n",
        "\n",
        "retrieval_input = {\n",
        "    \"domain\":   domain_info[\"domains\"][0][\"name\"],\n",
        "    \"concepts\": domain_info[\"concepts\"]\n",
        "}\n",
        "formulas_json = agent.run(json.dumps(retrieval_input, indent=2))\n",
        "print(formulas_json)\n",
        "############################################################################"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
